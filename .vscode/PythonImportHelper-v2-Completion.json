[
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "scripts.eval.run_prompt_regression",
        "description": "scripts.eval.run_prompt_regression",
        "isExtraImport": true,
        "detail": "scripts.eval.run_prompt_regression",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "shlex",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shlex",
        "description": "shlex",
        "detail": "shlex",
        "documentation": {}
    },
    {
        "label": "lldb",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "lldb",
        "description": "lldb",
        "detail": "lldb",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Set",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "unquote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "traceback",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "traceback",
        "description": "traceback",
        "detail": "traceback",
        "documentation": {}
    },
    {
        "label": "dataclasses",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "dataclasses",
        "description": "dataclasses",
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "asdict",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "asdict",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "asdict",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "load_redaction_patterns",
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "isExtraImport": true,
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "load_telemetry_schema",
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "isExtraImport": true,
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "redact_event",
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "isExtraImport": true,
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "redact_value",
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "isExtraImport": true,
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "stable_dumps",
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "isExtraImport": true,
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "validate_event_schema",
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "isExtraImport": true,
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "# noqa: E402\n    load_redaction_patterns",
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "isExtraImport": true,
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "load_telemetry_schema",
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "isExtraImport": true,
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "redact_event",
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "isExtraImport": true,
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "stable_dumps",
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "isExtraImport": true,
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "validate_event_schema",
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "isExtraImport": true,
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "load_redaction_patterns",
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "isExtraImport": true,
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "load_telemetry_schema",
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "isExtraImport": true,
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "redact_event",
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "isExtraImport": true,
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "stable_dumps",
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "isExtraImport": true,
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "validate_event_schema",
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "isExtraImport": true,
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "# noqa: E402\n    load_redaction_patterns",
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "isExtraImport": true,
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "load_telemetry_schema",
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "isExtraImport": true,
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "redact_event",
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "isExtraImport": true,
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "stable_dumps",
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "isExtraImport": true,
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "validate_event_schema",
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "isExtraImport": true,
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "load_dataset",
        "importPath": "datasets",
        "description": "datasets",
        "isExtraImport": true,
        "detail": "datasets",
        "documentation": {}
    },
    {
        "label": "load_dataset",
        "importPath": "datasets",
        "description": "datasets",
        "isExtraImport": true,
        "detail": "datasets",
        "documentation": {}
    },
    {
        "label": "load_dataset",
        "importPath": "datasets",
        "description": "datasets",
        "isExtraImport": true,
        "detail": "datasets",
        "documentation": {}
    },
    {
        "label": "load_dataset",
        "importPath": "datasets",
        "description": "datasets",
        "isExtraImport": true,
        "detail": "datasets",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "AutoTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoModelForCausalLM",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "BitsAndBytesConfig",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoConfig",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoModelForCausalLM",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoModelForCausalLM",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoModelForCausalLM",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "TrainingArguments",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "get_linear_schedule_with_warmup",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoModelForCausalLM",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForLanguageModeling",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "Trainer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "TrainingArguments",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForSeq2Seq",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForLanguageModeling",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForSeq2Seq",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForLanguageModeling",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForSeq2Seq",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForLanguageModeling",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForSeq2Seq",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForLanguageModeling",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForSeq2Seq",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForLanguageModeling",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForSeq2Seq",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForLanguageModeling",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForSeq2Seq",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForLanguageModeling",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForSeq2Seq",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForLanguageModeling",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForSeq2Seq",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForLanguageModeling",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForSeq2Seq",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForLanguageModeling",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForSeq2Seq",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForLanguageModeling",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForSeq2Seq",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForLanguageModeling",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForSeq2Seq",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForLanguageModeling",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForSeq2Seq",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForLanguageModeling",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForSeq2Seq",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DataCollatorForLanguageModeling",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "PeftModel",
        "importPath": "peft",
        "description": "peft",
        "isExtraImport": true,
        "detail": "peft",
        "documentation": {}
    },
    {
        "label": "PeftModel",
        "importPath": "peft",
        "description": "peft",
        "isExtraImport": true,
        "detail": "peft",
        "documentation": {}
    },
    {
        "label": "LoraConfig",
        "importPath": "peft",
        "description": "peft",
        "isExtraImport": true,
        "detail": "peft",
        "documentation": {}
    },
    {
        "label": "get_peft_model",
        "importPath": "peft",
        "description": "peft",
        "isExtraImport": true,
        "detail": "peft",
        "documentation": {}
    },
    {
        "label": "PeftModel",
        "importPath": "peft",
        "description": "peft",
        "isExtraImport": true,
        "detail": "peft",
        "documentation": {}
    },
    {
        "label": "LoraConfig",
        "importPath": "peft",
        "description": "peft",
        "isExtraImport": true,
        "detail": "peft",
        "documentation": {}
    },
    {
        "label": "get_peft_model",
        "importPath": "peft",
        "description": "peft",
        "isExtraImport": true,
        "detail": "peft",
        "documentation": {}
    },
    {
        "label": "prepare_model_for_kbit_training",
        "importPath": "peft",
        "description": "peft",
        "isExtraImport": true,
        "detail": "peft",
        "documentation": {}
    },
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "coremltools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "coremltools",
        "description": "coremltools",
        "detail": "coremltools",
        "documentation": {}
    },
    {
        "label": "coremltools.optimize",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "coremltools.optimize",
        "description": "coremltools.optimize",
        "detail": "coremltools.optimize",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "login",
        "importPath": "huggingface_hub",
        "description": "huggingface_hub",
        "isExtraImport": true,
        "detail": "huggingface_hub",
        "documentation": {}
    },
    {
        "label": "Cache",
        "importPath": "transformers.cache_utils",
        "description": "transformers.cache_utils",
        "isExtraImport": true,
        "detail": "transformers.cache_utils",
        "documentation": {}
    },
    {
        "label": "ast",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ast",
        "description": "ast",
        "detail": "ast",
        "documentation": {}
    },
    {
        "label": "importlib.util",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "importlib.util",
        "description": "importlib.util",
        "detail": "importlib.util",
        "documentation": {}
    },
    {
        "label": "inspect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inspect",
        "description": "inspect",
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "platform",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "platform",
        "description": "platform",
        "detail": "platform",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "textwrap",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "textwrap",
        "description": "textwrap",
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "AdamW",
        "importPath": "torch.optim",
        "description": "torch.optim",
        "isExtraImport": true,
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "SFTTrainer",
        "importPath": "trl",
        "description": "trl",
        "isExtraImport": true,
        "detail": "trl",
        "documentation": {}
    },
    {
        "label": "tempfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tempfile",
        "description": "tempfile",
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "zipfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "zipfile",
        "description": "zipfile",
        "detail": "zipfile",
        "documentation": {}
    },
    {
        "label": "concurrent.futures",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "fnmatch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "fnmatch",
        "description": "fnmatch",
        "detail": "fnmatch",
        "documentation": {}
    },
    {
        "label": "json,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json.",
        "description": "json.",
        "detail": "json.",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "AutoModelForCausalLM",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "BCOConfig",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "BCOTrainer",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "BaseImageProcessor",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "BaseTrainer",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "CLF_NAME",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "DPODataCollatorWithPadding",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "DataCollator",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "EvalLoopOutput",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "F",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "FeatureExtractionMixin",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "LogisticRegression",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "PartialState",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "PeftModel",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedTokenizerBase",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "ProcessorMixin",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "RUNNING_NAME",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "RunningMoments",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "SequentialSampler",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "TrainerCallback",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "TrainingArguments",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "_process_tokens",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "_tokenize",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "autocast",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "create_reference_model",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "disable_dropout_in_model",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "has_length",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "inspect",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "is_comet_available",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "is_joblib_available",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "is_peft_available",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "is_sklearn_available",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "is_wandb_available",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "itemgetter",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "joblib",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "log_table_to_comet_experiment",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "maybe_apply_chat_template",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "maybe_extract_prompt",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "maybe_unpair_preference_dataset",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "np",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "pad_to_length",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "pd",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "peft_module_casting_to_bf16",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_deepspeed",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_model_for_kbit_training",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "selective_log_softmax",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "textwrap",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "warnings",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "F",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "PeftModel",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "is_peft_available",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.bco_trainer",
        "description": "trl.trainer.bco_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.bco_trainer",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "Version",
        "importPath": "packaging.version",
        "description": "packaging.version",
        "isExtraImport": true,
        "detail": "packaging.version",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "ParallelMode",
        "importPath": "transformers.training_args",
        "description": "transformers.training_args",
        "isExtraImport": true,
        "detail": "transformers.training_args",
        "documentation": {}
    },
    {
        "label": "ParallelMode",
        "importPath": "transformers.training_args",
        "description": "transformers.training_args",
        "isExtraImport": true,
        "detail": "transformers.training_args",
        "documentation": {}
    },
    {
        "label": "ParallelMode",
        "importPath": "transformers.training_args",
        "description": "transformers.training_args",
        "isExtraImport": true,
        "detail": "transformers.training_args",
        "documentation": {}
    },
    {
        "label": "ParallelMode",
        "importPath": "transformers.training_args",
        "description": "transformers.training_args",
        "isExtraImport": true,
        "detail": "transformers.training_args",
        "documentation": {}
    },
    {
        "label": "ParallelMode",
        "importPath": "transformers.training_args",
        "description": "transformers.training_args",
        "isExtraImport": true,
        "detail": "transformers.training_args",
        "documentation": {}
    },
    {
        "label": "ParallelMode",
        "importPath": "transformers.training_args",
        "description": "transformers.training_args",
        "isExtraImport": true,
        "detail": "transformers.training_args",
        "documentation": {}
    },
    {
        "label": "ParallelMode",
        "importPath": "transformers.training_args",
        "description": "transformers.training_args",
        "isExtraImport": true,
        "detail": "transformers.training_args",
        "documentation": {}
    },
    {
        "label": "ParallelMode",
        "importPath": "transformers.training_args",
        "description": "transformers.training_args",
        "isExtraImport": true,
        "detail": "transformers.training_args",
        "documentation": {}
    },
    {
        "label": "ParallelMode",
        "importPath": "transformers.training_args",
        "description": "transformers.training_args",
        "isExtraImport": true,
        "detail": "transformers.training_args",
        "documentation": {}
    },
    {
        "label": "ParallelMode",
        "importPath": "transformers.training_args",
        "description": "transformers.training_args",
        "isExtraImport": true,
        "detail": "transformers.training_args",
        "documentation": {}
    },
    {
        "label": "ParallelMode",
        "importPath": "transformers.training_args",
        "description": "transformers.training_args",
        "isExtraImport": true,
        "detail": "transformers.training_args",
        "documentation": {}
    },
    {
        "label": "ParallelMode",
        "importPath": "transformers.training_args",
        "description": "transformers.training_args",
        "isExtraImport": true,
        "detail": "transformers.training_args",
        "documentation": {}
    },
    {
        "label": "ParallelMode",
        "importPath": "transformers.training_args",
        "description": "transformers.training_args",
        "isExtraImport": true,
        "detail": "transformers.training_args",
        "documentation": {}
    },
    {
        "label": "ParallelMode",
        "importPath": "transformers.training_args",
        "description": "transformers.training_args",
        "isExtraImport": true,
        "detail": "transformers.training_args",
        "documentation": {}
    },
    {
        "label": "ParallelMode",
        "importPath": "transformers.training_args",
        "description": "transformers.training_args",
        "isExtraImport": true,
        "detail": "transformers.training_args",
        "documentation": {}
    },
    {
        "label": "functools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "functools",
        "description": "functools",
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "MethodType",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "MethodType",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "MethodType",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "MethodType",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "MethodType",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "MethodType",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "MethodType",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "MethodType",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "MethodType",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "MethodType",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "MethodType",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "MethodType",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "MethodType",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "MethodType",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "MethodType",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "AutoModelForCausalLM",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "BaseImageProcessor",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "BaseTrainer",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "CPOConfig",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "CPOTrainer",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "DPODataCollatorWithPadding",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "DataCollator",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "EvalLoopOutput",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "F",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "FeatureExtractionMixin",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "PartialState",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "PeftModel",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedTokenizerBase",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "ProcessorMixin",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "TrainerCallback",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "add_bos_token_if_needed",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "add_eos_token_if_needed",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "autocast",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "disable_dropout_in_model",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "inspect",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_comet_available",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_peft_available",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_torch_fx_proxy",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_wandb_available",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "log_table_to_comet_experiment",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "maybe_apply_chat_template",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "maybe_extract_prompt",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "np",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "pad_to_length",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "pd",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "peft_module_casting_to_bf16",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_model_for_kbit_training",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "selective_log_softmax",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "textwrap",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "warnings",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "F",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "PeftModel",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_peft_available",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.cpo_trainer",
        "description": "trl.trainer.cpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.cpo_trainer",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "AutoProcessor",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "BaseImageProcessor",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "BaseTrainer",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "DPOConfig",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "DPOTrainer",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "DataCollator",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "DataCollatorForPreference",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "EvalLoopOutput",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "F",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "FDivergenceConstants",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "FDivergenceType",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "FeatureExtractionMixin",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "IterableDataset",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "MODEL_FOR_IMAGE_TEXT_TO_TEXT_MAPPING_NAMES",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "PartialState",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "PeftConfig",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "PeftModel",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedTokenizerBase",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "ProcessorMixin",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "RunningMoments",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "SyncRefModelCallback",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "TrainerCallback",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "autocast",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "cap_exp",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "create_model_from_path",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "create_reference_model",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "disable_dropout_in_model",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "empty_cache",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "flush_left",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "flush_right",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "get_peft_model",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "inspect",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_comet_available",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_liger_kernel_available",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_mlflow_available",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_peft_available",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_wandb_available",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "log_table_to_comet_experiment",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "maybe_apply_chat_template",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "maybe_extract_prompt",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "pad",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "pad_to_length",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "pd",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "peft_module_casting_to_bf16",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_deepspeed",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_fsdp",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_model_for_kbit_training",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "selective_log_softmax",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "shift_tokens_right",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "textwrap",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "warnings",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "F",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "PeftModel",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_peft_available",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.dpo_trainer",
        "description": "trl.trainer.dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.dpo_trainer",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "AutoModelForCausalLM",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "BaseImageProcessor",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "DataCollator",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "DataCollatorForChatML",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "EvalPrediction",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "F",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "FeatureExtractionMixin",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "GKDConfig",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "GKDTrainer",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "GenerationConfig",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "PeftConfig",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedTokenizerBase",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "ProcessorMixin",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "SFTTrainer",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "TrainerCallback",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "disable_dropout_in_model",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "empty_cache",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_deepspeed",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "textwrap",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "unwrap_model_for_generation",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "warnings",
        "importPath": "trl.trainer.gkd_trainer",
        "description": "trl.trainer.gkd_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.gkd_trainer",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "AutoConfig",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "AutoModelForSequenceClassification",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "AutoProcessor",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "AutoTokenizer",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "BaseTrainer",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "FSDP",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "GRPOConfig",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "GRPOTrainer",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "GenerationConfig",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "IterableDataset",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "PeftConfig",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedTokenizerBase",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "ProcessorMixin",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "RepeatSampler",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "RewardFunc",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "Sampler",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "SyncRefModelCallback",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "TrainerCallback",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "VLLMClient",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "_ForwardRedirection",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "apply_chat_template",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "broadcast_object_list",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "datasets",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "disable_dropout_in_model",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "ensure_master_addr_port",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "entropy_from_logits",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "gather",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "gather_object",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "identity",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "inspect",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_conversational",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_datasets_available",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_flash_attn_2_available",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_liger_kernel_available",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_peft_model",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_rich_available",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_vllm_available",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "maybe_apply_chat_template",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "nanmax",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "nanmin",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "nanstd",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "pad",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_deepspeed",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_fsdp",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_multimodal_messages",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_peft_model",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "print_prompt_completions_sample",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "profiling_context",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "profiling_decorator",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "seed_worker",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "selective_log_softmax",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "set_seed",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "shuffle_sequence_dict",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "split_pixel_values_by_grid",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "split_tensor_dict",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "textwrap",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "transformers",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "unsplit_pixel_values_by_grid",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "unwrap_model_for_generation",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "gather",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "gather_object",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_conversational",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "nanmax",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "nanmin",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "nanstd",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "pad",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "FSDP",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "apply_chat_template",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "broadcast_object_list",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "gather",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "gather_object",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_flash_attn_2_available",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "maybe_apply_chat_template",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "pad",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_multimodal_messages",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "profiling_context",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "transformers",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "unwrap_model_for_generation",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "entropy_from_logits",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "pad",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "selective_log_softmax",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "transformers",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "profiling_decorator",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "shuffle_sequence_dict",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "split_pixel_values_by_grid",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "split_tensor_dict",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "unsplit_pixel_values_by_grid",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "FSDP",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "FSDP",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "GRPOTrainer",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "gather",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "nanmax",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "nanmin",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.grpo_trainer",
        "description": "trl.trainer.grpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.grpo_trainer",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "AutoModelForCausalLM",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "BaseImageProcessor",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "BaseTrainer",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "DPODataCollatorWithPadding",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "DataCollator",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "EvalLoopOutput",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "F",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "FeatureExtractionMixin",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "KTOConfig",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "KTOTrainer",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "PartialState",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "PeftModel",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedTokenizerBase",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "ProcessorMixin",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "SequentialSampler",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "TrainerCallback",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "TrainingArguments",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "_get_kl_dataset",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "_process_tokens",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "_tokenize",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "autocast",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "concatenate_datasets",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "create_reference_model",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "disable_dropout_in_model",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "has_length",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "inspect",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "is_comet_available",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "is_liger_kernel_available",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "is_peft_available",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "is_wandb_available",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "itemgetter",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "log_table_to_comet_experiment",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "maybe_apply_chat_template",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "maybe_extract_prompt",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "maybe_unpair_preference_dataset",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "np",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "pad_to_length",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "pd",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "peft_module_casting_to_bf16",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_deepspeed",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_model_for_kbit_training",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "selective_log_softmax",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "textwrap",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "warnings",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "F",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "PeftModel",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "is_peft_available",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.kto_trainer",
        "description": "trl.trainer.kto_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.kto_trainer",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "BaseImageProcessor",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "BasePairwiseJudge",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "EvalPrediction",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "F",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "FeatureExtractionMixin",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "GeometricMixtureWrapper",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "IterableDataset",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "NashMDConfig",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "NashMDTrainer",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "OnlineDPOTrainer",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "OptimizerNames",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "PeftModel",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedTokenizerBase",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "ProcessorMixin",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "SIMPLE_CHAT_TEMPLATE",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "TrainerCallback",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "empty_cache",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "get_reward",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "is_conversational",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "is_peft_available",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "jinja2",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "maybe_apply_chat_template",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "selective_log_softmax",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "textwrap",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "truncate_right",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "unwrap_model_for_generation",
        "importPath": "trl.trainer.nash_md_trainer",
        "description": "trl.trainer.nash_md_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.nash_md_trainer",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "AutoModelForCausalLM",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "BaseImageProcessor",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "BaseTrainer",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "DPODataCollatorWithPadding",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "DataCollator",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "EvalLoopOutput",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "F",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "FeatureExtractionMixin",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "ORPOConfig",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "ORPOTrainer",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "PartialState",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "PeftModel",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedTokenizerBase",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "ProcessorMixin",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "TrainerCallback",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "add_bos_token_if_needed",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "add_eos_token_if_needed",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "autocast",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "disable_dropout_in_model",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "inspect",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_comet_available",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_peft_available",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_torch_fx_proxy",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_torch_xla_available",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_wandb_available",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "log_table_to_comet_experiment",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "maybe_apply_chat_template",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "maybe_extract_prompt",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "np",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "pad_to_length",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "pd",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "peft_module_casting_to_bf16",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_model_for_kbit_training",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "selective_log_softmax",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "textwrap",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "warnings",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "F",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "PeftModel",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_peft_available",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.orpo_trainer",
        "description": "trl.trainer.orpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.orpo_trainer",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "AutoModelForCausalLM",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "AutoModelForSequenceClassification",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "AutoTokenizer",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "BasePairwiseJudge",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "BaseTrainer",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "DPODataCollatorWithPadding",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "DataCollator",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "EvalPrediction",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "F",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "FSDP",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "GenerationConfig",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "IterableDataset",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "MODEL_FOR_IMAGE_TEXT_TO_TEXT_MAPPING_NAMES",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "OnlineDPOConfig",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "OnlineDPOTrainer",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "OptimizerNames",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "PeftConfig",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedTokenizerBase",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "ProcessorMixin",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "RewardFunc",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "SIMPLE_CHAT_TEMPLATE",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "Trainer",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "TrainerCallback",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "VLLMClient",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "apply_chat_template",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "broadcast_object_list",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "create_reference_model",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "disable_dropout_in_model",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "empty_cache",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "ensure_master_addr_port",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "gather_object",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_conversational",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_flash_attn_2_available",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_peft_model",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_vllm_available",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "jinja2",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "maybe_apply_chat_template",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "pad",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_deepspeed",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_fsdp",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_peft_model",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "profiling_context",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "re",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "seed_worker",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "textwrap",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "truncate_right",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "unwrap_model_for_generation",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "version",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "warnings",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "F",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "apply_chat_template",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_conversational",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "re",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "F",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "FSDP",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_peft_model",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "re",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "version",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "F",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "Trainer",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "re",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "F",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "FSDP",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "re",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "F",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "FSDP",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "re",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.online_dpo_trainer",
        "description": "trl.trainer.online_dpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.online_dpo_trainer",
        "documentation": {}
    },
    {
        "label": "Accelerator",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "BaseImageProcessor",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "BaseTrainer",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "CallbackHandler",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CALLBACKS",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "DEFAULT_PROGRESS_CALLBACK",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "DataCollatorWithPadding",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "ExportableState",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "FeatureExtractionMixin",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "GenerationConfig",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "INVALID_LOGPROB",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "OnlineTrainerState",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "PPOConfig",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "PPOTrainer",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "PeftConfig",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "PeftModel",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "PolicyAndValueWrapper",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedTokenizerBase",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "PrinterCallback",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "ProcessorMixin",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "TrainerCallback",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "TrainerControl",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "batch_generation",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "broadcast",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "create_reference_model",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "disable_dropout_in_model",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "empty_cache",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "exact_div",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "first_true_indices",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "forward",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "gather_object",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "gc",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "get_peft_model",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "get_reporting_integration_callbacks",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "get_reward",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "is_peft_available",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "is_rich_available",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "log_table_to_comet_experiment",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "masked_mean",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "masked_whiten",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "math",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "np",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "pd",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "peft_module_casting_to_bf16",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_deepspeed",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "print_rich_table",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "selective_log_softmax",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "textwrap",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "truncate_response",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "unwrap_model_for_generation",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "warnings",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "PeftModel",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "is_peft_available",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.ppo_trainer",
        "description": "trl.trainer.ppo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.ppo_trainer",
        "documentation": {}
    },
    {
        "label": "BaseImageProcessor",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "BaseTrainer",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "DataCollator",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "DataCollatorForTokenClassification",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "EvalPrediction",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "FeatureExtractionMixin",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "PRMConfig",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "PRMTrainer",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "PartialState",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedTokenizerBase",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "ProcessorMixin",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "TrainerCallback",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "chain",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "compute_accuracy",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "disable_dropout_in_model",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "features",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_peft_model",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "textwrap",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "warnings",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.prm_trainer",
        "description": "trl.trainer.prm_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.prm_trainer",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "AutoConfig",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "AutoModelForSequenceClassification",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "AutoProcessor",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "AutoTokenizer",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "BaseTrainer",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "FSDP",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "GenerationConfig",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "IterableDataset",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "PeftConfig",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedTokenizerBase",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "ProcessorMixin",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "RLOOConfig",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "RLOOTrainer",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "RepeatSampler",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "RewardFunc",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "Sampler",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "SyncRefModelCallback",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "TrainerCallback",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "VLLMClient",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "apply_chat_template",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "broadcast_object_list",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "datasets",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "disable_dropout_in_model",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "ensure_master_addr_port",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "entropy_from_logits",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "gather",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "gather_object",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "identity",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "inspect",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "is_conversational",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "is_datasets_available",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "is_flash_attn_2_available",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "is_peft_model",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "is_rich_available",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "is_vllm_available",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "maybe_apply_chat_template",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "nanmax",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "nanmin",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "nanstd",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "pad",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_deepspeed",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_fsdp",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_multimodal_messages",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_peft_model",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "print_prompt_completions_sample",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "profiling_context",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "profiling_decorator",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "seed_worker",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "selective_log_softmax",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "set_seed",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "shuffle_sequence_dict",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "split_pixel_values_by_grid",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "split_tensor_dict",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "textwrap",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "transformers",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "unsplit_pixel_values_by_grid",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "unwrap_model_for_generation",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "warnings",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "FSDP",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "apply_chat_template",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "broadcast_object_list",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "gather",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "gather_object",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "is_flash_attn_2_available",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "maybe_apply_chat_template",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "pad",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_multimodal_messages",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "profiling_context",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "transformers",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "unwrap_model_for_generation",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "FSDP",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "gather",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "is_peft_model",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "nullcontext",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "profiling_decorator",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "profiling_decorator",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "shuffle_sequence_dict",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "split_pixel_values_by_grid",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "split_tensor_dict",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "unsplit_pixel_values_by_grid",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "FSDP",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "FSDP",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.rloo_trainer",
        "description": "trl.trainer.rloo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.rloo_trainer",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "AutoModelForSequenceClassification",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "AutoTokenizer",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "BaseTrainer",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "DataCollator",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "DataCollatorForPreference",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "EvalPrediction",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "IterableDataset",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "PartialState",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "PeftConfig",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedTokenizerBase",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "RewardConfig",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "RewardTrainer",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "TrainerCallback",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "clone_chat_template",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "contextlib",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "disable_dropout_in_model",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "get_act_offloading_ctx_manager",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "is_conversational",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "pad",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_peft_model",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "re",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "remove_none_values",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "suppress_from_pretrained_warning",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "transformers",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "re",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.reward_trainer",
        "description": "trl.trainer.reward_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.reward_trainer",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "AutoProcessor",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "BaseTrainer",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "DataCollator",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "DataCollatorForLanguageModeling",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "DataCollatorForVisionLanguageModeling",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "EvalPrediction",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "FLASH_ATTENTION_VARIANTS",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "IterableDataset",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "PeftConfig",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedTokenizerBase",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "ProcessorMixin",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "SFTConfig",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "SFTTrainer",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "TrainerCallback",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "TrainingArguments",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "clone_chat_template",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "contextlib",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "create_model_from_path",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "dft_loss",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "get_act_offloading_ctx_manager",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "is_conversational",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "pack_dataset",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "pad",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "prepare_peft_model",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "selective_log_softmax",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "DataCollator",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "DataCollatorForLanguageModeling",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "IterableDataset",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "pack_dataset",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "pad",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "os",
        "importPath": "trl.trainer.sft_trainer",
        "description": "trl.trainer.sft_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.sft_trainer",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "BaseImageProcessor",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "BasePairwiseJudge",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "EvalPrediction",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "F",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "FeatureExtractionMixin",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "IterableDataset",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "OnlineDPOTrainer",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "OptimizerNames",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "PeftModel",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedModel",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "PreTrainedTokenizerBase",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "ProcessorMixin",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "SIMPLE_CHAT_TEMPLATE",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "TrainerCallback",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "XPOConfig",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "XPOTrainer",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "empty_cache",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "get_reward",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_conversational",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "is_peft_available",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "jinja2",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "maybe_apply_chat_template",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "selective_log_softmax",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "textwrap",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "torch",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "truncate_right",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "unwrap_model_for_generation",
        "importPath": "trl.trainer.xpo_trainer",
        "description": "trl.trainer.xpo_trainer",
        "isExtraImport": true,
        "detail": "trl.trainer.xpo_trainer",
        "documentation": {}
    },
    {
        "label": "load_outputs",
        "kind": 2,
        "importPath": "eval.export_equivalence",
        "description": "eval.export_equivalence",
        "peekOfCode": "def load_outputs(path: Path) -> dict:\n    outputs = {}\n    with path.open(\"r\", encoding=\"utf-8\") as handle:\n        for line in handle:\n            if not line.strip():\n                continue\n            entry = json.loads(line)\n            entry_id = entry.get(\"id\")\n            if not entry_id:\n                raise ValueError(f\"Missing id in {path}\")",
        "detail": "eval.export_equivalence",
        "documentation": {}
    },
    {
        "label": "logits_max_diff",
        "kind": 2,
        "importPath": "eval.export_equivalence",
        "description": "eval.export_equivalence",
        "peekOfCode": "def logits_max_diff(a: list, b: list) -> float:\n    if len(a) != len(b):\n        return float(\"inf\")\n    return max(abs(x - y) for x, y in zip(a, b)) if a else 0.0\ndef json_valid(text: str) -> bool:\n    try:\n        json.loads(text)\n        return True\n    except json.JSONDecodeError:\n        return False",
        "detail": "eval.export_equivalence",
        "documentation": {}
    },
    {
        "label": "json_valid",
        "kind": 2,
        "importPath": "eval.export_equivalence",
        "description": "eval.export_equivalence",
        "peekOfCode": "def json_valid(text: str) -> bool:\n    try:\n        json.loads(text)\n        return True\n    except json.JSONDecodeError:\n        return False\ndef main() -> None:\n    parser = argparse.ArgumentParser(\n        description=\"Validate CoreML/MLX export equivalence against Python outputs.\"\n    )",
        "detail": "eval.export_equivalence",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "eval.export_equivalence",
        "description": "eval.export_equivalence",
        "peekOfCode": "def main() -> None:\n    parser = argparse.ArgumentParser(\n        description=\"Validate CoreML/MLX export equivalence against Python outputs.\"\n    )\n    parser.add_argument(\"--python-output\", required=True)\n    parser.add_argument(\"--coreml-output\", required=True)\n    parser.add_argument(\"--logits-tolerance\", type=float, default=1e-3)\n    args = parser.parse_args()\n    py_outputs = load_outputs(Path(args.python_output))\n    core_outputs = load_outputs(Path(args.coreml_output))",
        "detail": "eval.export_equivalence",
        "documentation": {}
    },
    {
        "label": "REFUSAL_PATTERN",
        "kind": 5,
        "importPath": "eval.export_equivalence",
        "description": "eval.export_equivalence",
        "peekOfCode": "REFUSAL_PATTERN = re.compile(\n    r\"\\b(can't|cannot|won't|unable to|not able to|refuse|decline)\\b\",\n    re.IGNORECASE,\n)\ndef load_outputs(path: Path) -> dict:\n    outputs = {}\n    with path.open(\"r\", encoding=\"utf-8\") as handle:\n        for line in handle:\n            if not line.strip():\n                continue",
        "detail": "eval.export_equivalence",
        "documentation": {}
    },
    {
        "label": "load_documents",
        "kind": 2,
        "importPath": "eval.retrieval_eval",
        "description": "eval.retrieval_eval",
        "peekOfCode": "def load_documents(directory: Path) -> list[dict]:\n    docs = []\n    for path in sorted(directory.glob(\"**/*\")):\n        if path.is_dir():\n            continue\n        text = path.read_text(encoding=\"utf-8\", errors=\"ignore\").strip()\n        if not text:\n            continue\n        docs.append({\"id\": path.relative_to(directory).as_posix(), \"text\": text})\n    return docs",
        "detail": "eval.retrieval_eval",
        "documentation": {}
    },
    {
        "label": "run_chunking",
        "kind": 2,
        "importPath": "eval.retrieval_eval",
        "description": "eval.retrieval_eval",
        "peekOfCode": "def run_chunking(documents: list[dict], options: dict, timeout_s: int) -> dict:\n    payload = json.dumps({\"documents\": documents, \"options\": options})\n    try:\n        result = subprocess.run(\n            [\"node\", \"eval/chunk_text.mjs\"],\n            input=payload,\n            text=True,\n            capture_output=True,\n            check=False,\n            timeout=timeout_s,",
        "detail": "eval.retrieval_eval",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "eval.retrieval_eval",
        "description": "eval.retrieval_eval",
        "peekOfCode": "def main() -> None:\n    parser = argparse.ArgumentParser(\n        description=\"Evaluate retrieval chunking stability and distribution.\"\n    )\n    parser.add_argument(\"--documents\", required=True)\n    parser.add_argument(\"--max-chars\", type=int, default=12000)\n    parser.add_argument(\"--overlap\", type=int, default=200)\n    parser.add_argument(\"--min-docs\", type=int, default=20)\n    parser.add_argument(\"--timeout\", type=int, default=30)\n    args = parser.parse_args()",
        "detail": "eval.retrieval_eval",
        "documentation": {}
    },
    {
        "label": "_Known",
        "kind": 6,
        "importPath": "node_modules.flatted.python.flatted",
        "description": "node_modules.flatted.python.flatted",
        "peekOfCode": "class _Known:\n    def __init__(self):\n        self.key = []\n        self.value = []\nclass _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0",
        "detail": "node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "_String",
        "kind": 6,
        "importPath": "node_modules.flatted.python.flatted",
        "description": "node_modules.flatted.python.flatted",
        "peekOfCode": "class _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0\n    for _ in value:\n        keys.append(i)\n        i += 1\n    return keys",
        "detail": "node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "parse",
        "kind": 2,
        "importPath": "node_modules.flatted.python.flatted",
        "description": "node_modules.flatted.python.flatted",
        "peekOfCode": "def parse(value, *args, **kwargs):\n    json = _json.loads(value, *args, **kwargs)\n    wrapped = []\n    for value in json:\n        wrapped.append(_wrap(value))\n    input = []\n    for value in wrapped:\n        if isinstance(value, _String):\n            input.append(value.value)\n        else:",
        "detail": "node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "node_modules.flatted.python.flatted",
        "description": "node_modules.flatted.python.flatted",
        "peekOfCode": "def stringify(value, *args, **kwargs):\n    known = _Known()\n    input = []\n    output = []\n    i = int(_index(known, input, value))\n    while i < len(input):\n        output.append(_transform(known, input, input[i]))\n        i += 1\n    return _json.dumps(output, *args, **kwargs)",
        "detail": "node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "current_thread",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def current_thread(debugger):\n  return debugger.GetSelectedTarget().GetProcess().GetSelectedThread()\ndef current_frame(debugger):\n  return current_thread(debugger).GetSelectedFrame()\ndef no_arg_cmd(debugger, cmd, print_error=True):\n  cast_to_void_expr = '(void) {}'.format(cmd)\n  evaluate_result = current_frame(debugger).EvaluateExpression(cast_to_void_expr)\n  # When a void function is called the return value type is 0x1001 which\n  # is specified in http://tiny.cc/bigskz. This does not indicate\n  # an error so we check for that value below.",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "current_frame",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def current_frame(debugger):\n  return current_thread(debugger).GetSelectedFrame()\ndef no_arg_cmd(debugger, cmd, print_error=True):\n  cast_to_void_expr = '(void) {}'.format(cmd)\n  evaluate_result = current_frame(debugger).EvaluateExpression(cast_to_void_expr)\n  # When a void function is called the return value type is 0x1001 which\n  # is specified in http://tiny.cc/bigskz. This does not indicate\n  # an error so we check for that value below.\n  kNoResult = 0x1001\n  result = evaluate_result.GetError()",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "no_arg_cmd",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def no_arg_cmd(debugger, cmd, print_error=True):\n  cast_to_void_expr = '(void) {}'.format(cmd)\n  evaluate_result = current_frame(debugger).EvaluateExpression(cast_to_void_expr)\n  # When a void function is called the return value type is 0x1001 which\n  # is specified in http://tiny.cc/bigskz. This does not indicate\n  # an error so we check for that value below.\n  kNoResult = 0x1001\n  result = evaluate_result.GetError()\n  is_success = not result.fail or result.value == kNoResult\n  if not is_success:",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "ptr_arg_cmd",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def ptr_arg_cmd(debugger, name, param, cmd, fields=[], print_error=True):\n  if not param:\n    print(\"'{}' requires an argument\".format(name))\n    return (False, None, \"\")\n  value = current_frame(debugger).EvaluateExpression(param)\n  error = value.GetError()\n  if error.fail:\n    print(\"Error evaluating {}\\n{}\".format(param, error))\n    return (False, error, \"\")\n  # Proceed, ignoring visualizers if they are enabled.",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "print_handle",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def print_handle(debugger, command_name, param, print_func):\n  value = current_frame(debugger).EvaluateExpression(param)\n  error = value.GetError()\n  if error.fail:\n    print(\"Error evaluating {}\\n{}\".format(param, error))\n    return (False, error, \"\")\n  # Attempt to print, ignoring visualizers if they are enabled\n  result = print_func(value.GetNonSyntheticValue())\n  if not result[0]:\n    print(\"{} cannot print a value of type {}\".format(command_name,",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "print_direct",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def print_direct(debugger, command_name, value):\n  CMD = \"_v8_internal_Print_Object((v8::internal::Address*)({}))\"\n  return no_arg_cmd(debugger, CMD.format(value))\ndef print_indirect(debugger, command_name, value):\n  CMD = \"_v8_internal_Print_Object(*(v8::internal::Address**)({}))\"\n  return no_arg_cmd(debugger, CMD.format(value))\nV8_LLDB_COMMANDS = []\ndef lldbCommand(fn):\n  V8_LLDB_COMMANDS.append(fn.__name__)\n  return fn",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "print_indirect",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def print_indirect(debugger, command_name, value):\n  CMD = \"_v8_internal_Print_Object(*(v8::internal::Address**)({}))\"\n  return no_arg_cmd(debugger, CMD.format(value))\nV8_LLDB_COMMANDS = []\ndef lldbCommand(fn):\n  V8_LLDB_COMMANDS.append(fn.__name__)\n  return fn\n#####################\n# lldb commands.    #\n#####################",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "lldbCommand",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def lldbCommand(fn):\n  V8_LLDB_COMMANDS.append(fn.__name__)\n  return fn\n#####################\n# lldb commands.    #\n#####################\n@lldbCommand\ndef job(debugger, param, *args):\n  \"\"\"Print a v8 heap object\"\"\"\n  CMD = \"_v8_internal_Print_Object((void*)({}))\"",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "job",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def job(debugger, param, *args):\n  \"\"\"Print a v8 heap object\"\"\"\n  CMD = \"_v8_internal_Print_Object((void*)({}))\"\n  # Allow for Tagged<T>, containing a ptr_.\n  ptr_arg_cmd(debugger, 'job', param, CMD, [\".ptr_\"])\n@lldbCommand\ndef jh(debugger, param, *args):\n  \"\"\"Print v8::internal::(Maybe)?(Direct|Indirect)?Handle value\"\"\"\n  def print_func(value):\n    # Indirect handles contain a location_.",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "jh",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def jh(debugger, param, *args):\n  \"\"\"Print v8::internal::(Maybe)?(Direct|Indirect)?Handle value\"\"\"\n  def print_func(value):\n    # Indirect handles contain a location_.\n    field = value.GetValueForExpressionPath(\".location_\")\n    if field.IsValid():\n      return print_indirect(debugger, 'jh', field.value)\n    # With v8_enable_direct_handle=true, direct handles contain a obj_.\n    field = value.GetValueForExpressionPath(\".obj_\")\n    if field.IsValid():",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "jlh",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def jlh(debugger, param, *args):\n  \"\"\"Print v8::(Maybe)?Local value\"\"\"\n  def print_func(value):\n    # After https://crrev.com/c/4335544, v8::MaybeLocal contains a local_.\n    field = value.GetValueForExpressionPath(\".local_\")\n    if field.IsValid():\n      value = field\n    # After https://crrev.com/c/4335544, v8::Local contains a location_.\n    field = value.GetValueForExpressionPath(\".location_\")\n    if field.IsValid():",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "jl",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def jl(debugger, param, *args):\n  \"\"\"Print v8::Local handle value\"\"\"\n  return jlh(debugger, param, *args)\n@lldbCommand\ndef jco(debugger, param, *args):\n  \"\"\"Print the code object at the given pc (default: current pc)\"\"\"\n  CMD = \"_v8_internal_Print_Code((void*)({}))\"\n  if not param:\n    param = str(current_frame(debugger).FindRegister(\"pc\").value)\n  no_arg_cmd(debugger, CMD.format(param))",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "jco",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def jco(debugger, param, *args):\n  \"\"\"Print the code object at the given pc (default: current pc)\"\"\"\n  CMD = \"_v8_internal_Print_Code((void*)({}))\"\n  if not param:\n    param = str(current_frame(debugger).FindRegister(\"pc\").value)\n  no_arg_cmd(debugger, CMD.format(param))\n@lldbCommand\ndef jdh(debugger, param, *args):\n  \"\"\"Print JSDispatchEntry object in the JSDispatchTable with the given dispatch handle\"\"\"\n  CMD = \"_v8_internal_Print_Dispatch_Handle((uint32_t)({}))\"",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "jdh",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def jdh(debugger, param, *args):\n  \"\"\"Print JSDispatchEntry object in the JSDispatchTable with the given dispatch handle\"\"\"\n  CMD = \"_v8_internal_Print_Dispatch_Handle((uint32_t)({}))\"\n  # Allow for JSDispatchHandle, containing a value_.\n  ptr_arg_cmd(debugger, 'jdh', param, CMD, [\".value_\"])\n@lldbCommand\ndef jca(debugger, param, *args):\n  \"\"\"Print a v8 Code object assembly code from an internal code address\"\"\"\n  param = shlex.split(param)\n  if not param:",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "jca",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def jca(debugger, param, *args):\n  \"\"\"Print a v8 Code object assembly code from an internal code address\"\"\"\n  param = shlex.split(param)\n  if not param:\n    obj = str(current_frame(debugger).FindRegister(\"pc\").value)\n  else:\n    obj = param[0]\n  range_limit = param[1] if len(param) > 1 else 30\n  CMD = \"_v8_internal_Print_OnlyCode((void*)({}), (size_t)({}))\"\n  no_arg_cmd(debugger, CMD.format(obj, range_limit))",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "jtt",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def jtt(debugger, param, *args):\n  \"\"\"Print the complete transition tree starting at the given v8 map\"\"\"\n  CMD = \"_v8_internal_Print_TransitionTree((void*)({}), false)\"\n  # Allow for Tagged<T>, containing a ptr_.\n  ptr_arg_cmd(debugger, 'jtt', param, CMD, [\".ptr_\"])\n@lldbCommand\ndef jttr(debugger, param, *args):\n  \"\"\"Print the complete transition tree starting at the root map of the given v8 map\"\"\"\n  CMD = \"_v8_internal_Print_TransitionTree((void*)({}), true)\"\n  # Allow for Tagged<T>, containing a ptr_.",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "jttr",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def jttr(debugger, param, *args):\n  \"\"\"Print the complete transition tree starting at the root map of the given v8 map\"\"\"\n  CMD = \"_v8_internal_Print_TransitionTree((void*)({}), true)\"\n  # Allow for Tagged<T>, containing a ptr_.\n  ptr_arg_cmd(debugger, 'jttr', param, CMD, [\".ptr_\"])\n@lldbCommand\ndef jst(debugger, *args):\n  \"\"\"Print the current JavaScript stack trace\"\"\"\n  no_arg_cmd(debugger, \"_v8_internal_Print_StackTrace()\")\n@lldbCommand",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "jst",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def jst(debugger, *args):\n  \"\"\"Print the current JavaScript stack trace\"\"\"\n  no_arg_cmd(debugger, \"_v8_internal_Print_StackTrace()\")\n@lldbCommand\ndef pn(debugger, param, *args):\n  \"\"\"Print a v8 TurboFan graph node\"\"\"\n  CMD = \"_v8_internal_Node_Print((void*)({}))\"\n  # Allow for Tagged<T>, containing a ptr_.\n  ptr_arg_cmd(debugger, 'pn', param, CMD, [\".ptr_\"])\n@lldbCommand",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "pn",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def pn(debugger, param, *args):\n  \"\"\"Print a v8 TurboFan graph node\"\"\"\n  CMD = \"_v8_internal_Node_Print((void*)({}))\"\n  # Allow for Tagged<T>, containing a ptr_.\n  ptr_arg_cmd(debugger, 'pn', param, CMD, [\".ptr_\"])\n@lldbCommand\ndef jss(debugger, *args):\n  \"\"\"Skip the jitted stack on x64 to where we entered JS last\"\"\"\n  frame = current_frame(debugger)\n  js_entry_sp = frame.EvaluateExpression(",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "jss",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def jss(debugger, *args):\n  \"\"\"Skip the jitted stack on x64 to where we entered JS last\"\"\"\n  frame = current_frame(debugger)\n  js_entry_sp = frame.EvaluateExpression(\n      \"v8::internal::Isolate::Current()->thread_local_top()->js_entry_sp_;\") \\\n       .GetValue()\n  sizeof_void = frame.EvaluateExpression(\"sizeof(void*)\").GetValue()\n  rbp = frame.FindRegister(\"rbp\")\n  rsp = frame.FindRegister(\"rsp\")\n  pc = frame.FindRegister(\"pc\")",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "jfci",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def jfci(debugger, param, *args):\n  \"\"\"Print v8::FunctionCallbackInfo<T>& info\"\"\"\n  CMD = \"_v8_internal_Print_FunctionCallbackInfo((void*)(&{}))\"\n  if not param:\n    print(\"'jfci' requires an argument\")\n  else:\n    no_arg_cmd(debugger, CMD.format(param))\n@lldbCommand\ndef jpci(debugger, param, *args):\n  \"\"\"Print v8::PropertyCallbackInfo<T>& info\"\"\"",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "jpci",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def jpci(debugger, param, *args):\n  \"\"\"Print v8::PropertyCallbackInfo<T>& info\"\"\"\n  CMD = \"_v8_internal_Print_PropertyCallbackInfo((void*)(&{}))\"\n  if not param:\n    print(\"'jpci' requires an argument\")\n  else:\n    no_arg_cmd(debugger, CMD.format(param))\n# Print whether the object is marked, the mark-bit cell and index. The address\n# of the cell is handy for reverse debugging to check when the object was\n# marked/unmarked.",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "jomb",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def jomb(debugger, param, *args):\n  \"\"\"Print whether the object is marked, the markbit cell and index\"\"\"\n  CMD = \"_v8_internal_Print_Object_MarkBit((void*)({}))\"\n  # Allow for Tagged<T>, containing a ptr_.\n  ptr_arg_cmd(debugger, 'jomb', param, CMD, [\".ptr_\"])\n@lldbCommand\ndef bta(debugger, *args):\n  \"\"\"Print stack trace with assertion scopes\"\"\"\n  func_name_re = re.compile(\"([^(<]+)(?:\\(.+\\))?\")\n  assert_re = re.compile(",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "bta",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def bta(debugger, *args):\n  \"\"\"Print stack trace with assertion scopes\"\"\"\n  func_name_re = re.compile(\"([^(<]+)(?:\\(.+\\))?\")\n  assert_re = re.compile(\n      \"^v8::internal::Per\\w+AssertType::(\\w+)_ASSERT, (false|true)>\")\n  thread = current_thread(debugger)\n  for frame in thread:\n    functionSignature = frame.GetDisplayFunctionName()\n    if functionSignature is None:\n      continue",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "setup_source_map_for_relative_paths",
        "kind": 2,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "def setup_source_map_for_relative_paths(debugger):\n  # Copied from Chromium's tools/lldb/lldbinit.py.\n  # When relative paths are used for debug symbols, lldb cannot find source\n  # files. Set up a source map to point to V8's root.\n  this_dir = os.path.dirname(os.path.abspath(__file__))\n  source_dir = os.path.join(this_dir, os.pardir)\n  debugger.HandleCommand(\n    'settings set target.source-map ../.. ' + source_dir)\ndef __lldb_init_module(debugger, dict):\n  setup_source_map_for_relative_paths(debugger)",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "V8_LLDB_COMMANDS",
        "kind": 5,
        "importPath": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "description": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "peekOfCode": "V8_LLDB_COMMANDS = []\ndef lldbCommand(fn):\n  V8_LLDB_COMMANDS.append(fn.__name__)\n  return fn\n#####################\n# lldb commands.    #\n#####################\n@lldbCommand\ndef job(debugger, param, *args):\n  \"\"\"Print a v8 heap object\"\"\"",
        "detail": "node_modules.node.node_modules.node-linux-x64.share.doc.node.lldb_commands",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "scripts.ci.build_report",
        "description": "scripts.ci.build_report",
        "peekOfCode": "def parse_args():\n    p = argparse.ArgumentParser(description=\"Generate CI build reports\")\n    p.add_argument(\"--log\", required=True, help=\"Path to xcodebuild.log\")\n    p.add_argument(\"--xcresult\", required=True, help=\"Path to .xcresult bundle\")\n    p.add_argument(\"--out\", default=\"REPORT.md\", help=\"Output human report path\")\n    p.add_argument(\"--agent\", default=\"report_agent.md\", help=\"Output agent report path\")\n    return p.parse_args()\ndef parse_log(path: Path):\n    errors, warnings = [], []\n    try:",
        "detail": "scripts.ci.build_report",
        "documentation": {}
    },
    {
        "label": "parse_log",
        "kind": 2,
        "importPath": "scripts.ci.build_report",
        "description": "scripts.ci.build_report",
        "peekOfCode": "def parse_log(path: Path):\n    errors, warnings = [], []\n    try:\n        with path.open(errors=\"ignore\") as f:\n            for line in f:\n                low = line.lower().strip()\n                if \"error:\" in low:\n                    errors.append(line.strip())\n                elif \"warning:\" in low:\n                    warnings.append(line.strip())",
        "detail": "scripts.ci.build_report",
        "documentation": {}
    },
    {
        "label": "parse_xcresult",
        "kind": 2,
        "importPath": "scripts.ci.build_report",
        "description": "scripts.ci.build_report",
        "peekOfCode": "def parse_xcresult(path: Path):\n    if not path.exists():\n        return []\n    try:\n        out = _run_xcresulttool(path)\n        data = json.loads(out)\n    except Exception as e:  # xcresulttool missing or parse error\n        return [f\"(xcresult parse failed: {e})\"]\n    issues = []\n    def walk(obj):",
        "detail": "scripts.ci.build_report",
        "documentation": {}
    },
    {
        "label": "write_human_report",
        "kind": 2,
        "importPath": "scripts.ci.build_report",
        "description": "scripts.ci.build_report",
        "peekOfCode": "def write_human_report(out_path: Path, log_path: Path, xc_path: Path, errors, warnings, xc_issues):\n    with out_path.open(\"w\") as f:\n        f.write(\"# iOS CI Report\\n\\n\")\n        f.write(f\"- Workflow log: {log_path}\\n\")\n        f.write(f\"- Result bundle: {xc_path}\\n\\n\")\n        f.write(\"## Errors\\n\")\n        if errors:\n            f.write(\"\\n\".join(f\"- {e}\" for e in errors[:100]))\n            if len(errors) > 100:\n                f.write(f\"\\n... ({len(errors)-100} more)\\n\")",
        "detail": "scripts.ci.build_report",
        "documentation": {}
    },
    {
        "label": "write_agent_report",
        "kind": 2,
        "importPath": "scripts.ci.build_report",
        "description": "scripts.ci.build_report",
        "peekOfCode": "def write_agent_report(out_path: Path, errors, warnings, xc_issues):\n    with out_path.open(\"w\") as f:\n        f.write(\"# agent_report\\n\")\n        f.write(f\"errors_count={len(errors)}\\n\")\n        f.write(f\"warnings_count={len(warnings)}\\n\")\n        f.write(f\"xcresult_issues_count={len(xc_issues)}\\n\")\n        if errors:\n            f.write(\"first_error=\" + errors[0].replace(\"|\", \"/\") + \"\\n\")\n        if warnings:\n            f.write(\"first_warning=\" + warnings[0].replace(\"|\", \"/\") + \"\\n\")",
        "detail": "scripts.ci.build_report",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.ci.build_report",
        "description": "scripts.ci.build_report",
        "peekOfCode": "def main():\n    args = parse_args()\n    log_path = Path(args.log)\n    xc_path = Path(args.xcresult)\n    errors, warnings = parse_log(log_path)\n    xc_issues = parse_xcresult(xc_path)\n    write_human_report(Path(args.out), log_path, xc_path, errors, warnings, xc_issues)\n    write_agent_report(Path(args.agent), errors, warnings, xc_issues)\n    print(f\" Reports generated: {args.out}, {args.agent}\")\nif __name__ == \"__main__\":",
        "detail": "scripts.ci.build_report",
        "documentation": {}
    },
    {
        "label": "LEGACY_UNSUPPORTED_TOKENS",
        "kind": 5,
        "importPath": "scripts.ci.build_report",
        "description": "scripts.ci.build_report",
        "peekOfCode": "LEGACY_UNSUPPORTED_TOKENS = (\n    \"unknown option\",\n    \"unrecognized option\",\n    \"invalid option\",\n    \"invalid argument\",\n    \"not supported\",\n    \"no longer supported\",\n    \"unsupported option\",\n    \"does not support\",\n    \"has been removed\",",
        "detail": "scripts.ci.build_report",
        "documentation": {}
    },
    {
        "label": "_LEGACY_SUPPORT_STATE",
        "kind": 5,
        "importPath": "scripts.ci.build_report",
        "description": "scripts.ci.build_report",
        "peekOfCode": "_LEGACY_SUPPORT_STATE = None\ndef parse_args():\n    p = argparse.ArgumentParser(description=\"Generate CI build reports\")\n    p.add_argument(\"--log\", required=True, help=\"Path to xcodebuild.log\")\n    p.add_argument(\"--xcresult\", required=True, help=\"Path to .xcresult bundle\")\n    p.add_argument(\"--out\", default=\"REPORT.md\", help=\"Output human report path\")\n    p.add_argument(\"--agent\", default=\"report_agent.md\", help=\"Output agent report path\")\n    return p.parse_args()\ndef parse_log(path: Path):\n    errors, warnings = [], []",
        "detail": "scripts.ci.build_report",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.ci.emit_ios_diagnostics_summary",
        "description": "scripts.ci.emit_ios_diagnostics_summary",
        "peekOfCode": "def main() -> int:\n    parser = argparse.ArgumentParser(description=__doc__)\n    parser.add_argument(\"--label\", default=\"iOS build\")\n    parser.add_argument(\"--env-log\", default=\"build/diagnostics/environment.log\")\n    parser.add_argument(\"--error-log\", default=\"build/diagnostics/xcodebuild-errors.log\")\n    parser.add_argument(\"--derived-log\", default=\"build/diagnostics/derived-data.txt\")\n    parser.add_argument(\"--unified-log\", default=\"build/diagnostics/unified-xcodebuild.log\")\n    parser.add_argument(\"--artifact-path\", default=\"build/diagnostics\")\n    parser.add_argument(\"--result-json\", action=\"append\", default=[])\n    parser.add_argument(\"--env-limit\", type=int, default=40)",
        "detail": "scripts.ci.emit_ios_diagnostics_summary",
        "documentation": {}
    },
    {
        "label": "fail",
        "kind": 2,
        "importPath": "scripts.ci.guard_eval_symbiosis",
        "description": "scripts.ci.guard_eval_symbiosis",
        "peekOfCode": "def fail(msg: str) -> None:\n    print(f\"[guard] {msg}\", file=sys.stderr)\n    sys.exit(1)\ndef main() -> None:\n    if not FORWARDER.exists():\n        fail(\"eval/run_prompt_regression.py does not exist\")\n    if not TARGET.exists():\n        fail(\"scripts/eval/run_prompt_regression.py does not exist\")\n    text = FORWARDER.read_text(encoding=\"utf-8\")\n    if \"scripts.eval.run_prompt_regression\" not in text:",
        "detail": "scripts.ci.guard_eval_symbiosis",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.ci.guard_eval_symbiosis",
        "description": "scripts.ci.guard_eval_symbiosis",
        "peekOfCode": "def main() -> None:\n    if not FORWARDER.exists():\n        fail(\"eval/run_prompt_regression.py does not exist\")\n    if not TARGET.exists():\n        fail(\"scripts/eval/run_prompt_regression.py does not exist\")\n    text = FORWARDER.read_text(encoding=\"utf-8\")\n    if \"scripts.eval.run_prompt_regression\" not in text:\n        fail(\n            \"eval/run_prompt_regression.py must forward to \"\n            \"scripts/eval/run_prompt_regression.py\"",
        "detail": "scripts.ci.guard_eval_symbiosis",
        "documentation": {}
    },
    {
        "label": "FORWARDER",
        "kind": 5,
        "importPath": "scripts.ci.guard_eval_symbiosis",
        "description": "scripts.ci.guard_eval_symbiosis",
        "peekOfCode": "FORWARDER = Path(\"eval/run_prompt_regression.py\")\nTARGET = Path(\"scripts/eval/run_prompt_regression.py\")\ndef fail(msg: str) -> None:\n    print(f\"[guard] {msg}\", file=sys.stderr)\n    sys.exit(1)\ndef main() -> None:\n    if not FORWARDER.exists():\n        fail(\"eval/run_prompt_regression.py does not exist\")\n    if not TARGET.exists():\n        fail(\"scripts/eval/run_prompt_regression.py does not exist\")",
        "detail": "scripts.ci.guard_eval_symbiosis",
        "documentation": {}
    },
    {
        "label": "TARGET",
        "kind": 5,
        "importPath": "scripts.ci.guard_eval_symbiosis",
        "description": "scripts.ci.guard_eval_symbiosis",
        "peekOfCode": "TARGET = Path(\"scripts/eval/run_prompt_regression.py\")\ndef fail(msg: str) -> None:\n    print(f\"[guard] {msg}\", file=sys.stderr)\n    sys.exit(1)\ndef main() -> None:\n    if not FORWARDER.exists():\n        fail(\"eval/run_prompt_regression.py does not exist\")\n    if not TARGET.exists():\n        fail(\"scripts/eval/run_prompt_regression.py does not exist\")\n    text = FORWARDER.read_text(encoding=\"utf-8\")",
        "detail": "scripts.ci.guard_eval_symbiosis",
        "documentation": {}
    },
    {
        "label": "iter_paths",
        "kind": 2,
        "importPath": "scripts.ci.guard_symbiosis_output",
        "description": "scripts.ci.guard_symbiosis_output",
        "peekOfCode": "def iter_paths(report: dict) -> Iterable[str]:\n    for snippet in report.get(\"prompt_snippets\", []):\n        file_path = snippet.get(\"file\")\n        if file_path:\n            yield file_path\n    for cluster in report.get(\"prompt_drift_clusters\", []):\n        for file_path in cluster.get(\"files\", []):\n            if file_path:\n                yield file_path\n    for entries in report.get(\"where_to_search\", {}).values():",
        "detail": "scripts.ci.guard_symbiosis_output",
        "documentation": {}
    },
    {
        "label": "is_forbidden",
        "kind": 2,
        "importPath": "scripts.ci.guard_symbiosis_output",
        "description": "scripts.ci.guard_symbiosis_output",
        "peekOfCode": "def is_forbidden(path: str) -> bool:\n    path_lower = path.lower()\n    if path.startswith(FORBIDDEN_PREFIXES):\n        return True\n    return any(token in path_lower for token in FORBIDDEN_SUBSTRINGS)\ndef main() -> int:\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--report\", required=True, help=\"Path to symbiosis report JSON\")\n    args = parser.parse_args()\n    report_path = Path(args.report)",
        "detail": "scripts.ci.guard_symbiosis_output",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.ci.guard_symbiosis_output",
        "description": "scripts.ci.guard_symbiosis_output",
        "peekOfCode": "def main() -> int:\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--report\", required=True, help=\"Path to symbiosis report JSON\")\n    args = parser.parse_args()\n    report_path = Path(args.report)\n    if not report_path.exists():\n        print(f\"[guard] Missing report: {report_path}\", file=sys.stderr)\n        return 1\n    report = json.loads(report_path.read_text(encoding=\"utf-8\"))\n    offenders = sorted({p for p in iter_paths(report) if is_forbidden(p)})",
        "detail": "scripts.ci.guard_symbiosis_output",
        "documentation": {}
    },
    {
        "label": "FORBIDDEN_PREFIXES",
        "kind": 5,
        "importPath": "scripts.ci.guard_symbiosis_output",
        "description": "scripts.ci.guard_symbiosis_output",
        "peekOfCode": "FORBIDDEN_PREFIXES = (\"reports/\", \"runs/\")\nFORBIDDEN_SUBSTRINGS = (\"symbiosis\", \"prompt-regression\")\ndef iter_paths(report: dict) -> Iterable[str]:\n    for snippet in report.get(\"prompt_snippets\", []):\n        file_path = snippet.get(\"file\")\n        if file_path:\n            yield file_path\n    for cluster in report.get(\"prompt_drift_clusters\", []):\n        for file_path in cluster.get(\"files\", []):\n            if file_path:",
        "detail": "scripts.ci.guard_symbiosis_output",
        "documentation": {}
    },
    {
        "label": "FORBIDDEN_SUBSTRINGS",
        "kind": 5,
        "importPath": "scripts.ci.guard_symbiosis_output",
        "description": "scripts.ci.guard_symbiosis_output",
        "peekOfCode": "FORBIDDEN_SUBSTRINGS = (\"symbiosis\", \"prompt-regression\")\ndef iter_paths(report: dict) -> Iterable[str]:\n    for snippet in report.get(\"prompt_snippets\", []):\n        file_path = snippet.get(\"file\")\n        if file_path:\n            yield file_path\n    for cluster in report.get(\"prompt_drift_clusters\", []):\n        for file_path in cluster.get(\"files\", []):\n            if file_path:\n                yield file_path",
        "detail": "scripts.ci.guard_symbiosis_output",
        "documentation": {}
    },
    {
        "label": "load_outputs",
        "kind": 2,
        "importPath": "scripts.eval.export_equivalence",
        "description": "scripts.eval.export_equivalence",
        "peekOfCode": "def load_outputs(path: Path) -> dict:\n    if not path.exists():\n        raise FileNotFoundError(f\"Output file not found: {path}\")\n    with path.open(\"r\", encoding=\"utf-8\") as handle:\n        return json.load(handle)\ndef compare_logits(reference: list[float], candidate: list[float]) -> dict:\n    if len(reference) != len(candidate):\n        raise ValueError(\"Logit lengths do not match\")\n    deltas = [abs(r - c) for r, c in zip(reference, candidate)]\n    return {",
        "detail": "scripts.eval.export_equivalence",
        "documentation": {}
    },
    {
        "label": "compare_logits",
        "kind": 2,
        "importPath": "scripts.eval.export_equivalence",
        "description": "scripts.eval.export_equivalence",
        "peekOfCode": "def compare_logits(reference: list[float], candidate: list[float]) -> dict:\n    if len(reference) != len(candidate):\n        raise ValueError(\"Logit lengths do not match\")\n    deltas = [abs(r - c) for r, c in zip(reference, candidate)]\n    return {\n        \"max_delta\": max(deltas) if deltas else 0,\n        \"mean_delta\": sum(deltas) / len(deltas) if deltas else 0,\n        \"rmse\": math.sqrt(sum(d * d for d in deltas) / len(deltas))\n        if deltas\n        else 0,",
        "detail": "scripts.eval.export_equivalence",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.eval.export_equivalence",
        "description": "scripts.eval.export_equivalence",
        "peekOfCode": "def main() -> None:\n    parser = argparse.ArgumentParser(\n        description=\"Compare reference and candidate export outputs.\"\n    )\n    parser.add_argument(\"--reference\", required=True)\n    parser.add_argument(\"--candidate\", required=True)\n    parser.add_argument(\"--max-delta\", type=float, default=0.15)\n    args = parser.parse_args()\n    reference = load_outputs(Path(args.reference))\n    candidate = load_outputs(Path(args.candidate))",
        "detail": "scripts.eval.export_equivalence",
        "documentation": {}
    },
    {
        "label": "load_pairs",
        "kind": 2,
        "importPath": "scripts.eval.retrieval_eval",
        "description": "scripts.eval.retrieval_eval",
        "peekOfCode": "def load_pairs(path: Path) -> list[dict]:\n    with path.open(\"r\", encoding=\"utf-8\") as handle:\n        return [json.loads(line) for line in handle if line.strip()]\ndef load_retrieval_events(path: Path) -> dict[str, list[dict]]:\n    events: dict[str, list[dict]] = defaultdict(list)\n    duplicates = 0\n    with path.open(\"r\", encoding=\"utf-8\") as handle:\n        for line in handle:\n            if not line.strip():\n                continue",
        "detail": "scripts.eval.retrieval_eval",
        "documentation": {}
    },
    {
        "label": "load_retrieval_events",
        "kind": 2,
        "importPath": "scripts.eval.retrieval_eval",
        "description": "scripts.eval.retrieval_eval",
        "peekOfCode": "def load_retrieval_events(path: Path) -> dict[str, list[dict]]:\n    events: dict[str, list[dict]] = defaultdict(list)\n    duplicates = 0\n    with path.open(\"r\", encoding=\"utf-8\") as handle:\n        for line in handle:\n            if not line.strip():\n                continue\n            event = json.loads(line)\n            if event.get(\"event_type\") != \"retrieval\":\n                continue",
        "detail": "scripts.eval.retrieval_eval",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.eval.retrieval_eval",
        "description": "scripts.eval.retrieval_eval",
        "peekOfCode": "def main() -> None:\n    parser = argparse.ArgumentParser(description=\"Evaluate retrieval recall@k.\")\n    parser.add_argument(\"--pairs\", required=True)\n    parser.add_argument(\"--telemetry\", required=True)\n    parser.add_argument(\"--k\", type=int, default=3)\n    args = parser.parse_args()\n    pairs = load_pairs(Path(args.pairs))\n    telemetry = load_retrieval_events(Path(args.telemetry))\n    total = 0\n    hits = 0",
        "detail": "scripts.eval.retrieval_eval",
        "documentation": {}
    },
    {
        "label": "empty_sarif",
        "kind": 2,
        "importPath": "scripts.eval.run_prompt_regression",
        "description": "scripts.eval.run_prompt_regression",
        "peekOfCode": "def empty_sarif() -> Dict[str, Any]:\n    return {\n        \"version\": \"2.1.0\",\n        \"$schema\": \"https://json.schemastore.org/sarif-2.1.0.json\",\n        \"runs\": [\n            {\n                \"tool\": {\n                    \"driver\": {\n                        \"name\": \"offLLM Prompt Regression\",\n                        \"informationUri\": \"https://github.com/ales27pm/offLLM-1\",",
        "detail": "scripts.eval.run_prompt_regression",
        "documentation": {}
    },
    {
        "label": "add_sarif_error",
        "kind": 2,
        "importPath": "scripts.eval.run_prompt_regression",
        "description": "scripts.eval.run_prompt_regression",
        "peekOfCode": "def add_sarif_error(sarif: Dict[str, Any], message: str) -> None:\n    sarif[\"runs\"][0][\"results\"].append(\n        {\n            \"level\": \"error\",\n            \"message\": {\"text\": message},\n        }\n    )\n# -------------------------\n# Template resolution\n# -------------------------",
        "detail": "scripts.eval.run_prompt_regression",
        "documentation": {}
    },
    {
        "label": "resolve_template",
        "kind": 2,
        "importPath": "scripts.eval.run_prompt_regression",
        "description": "scripts.eval.run_prompt_regression",
        "peekOfCode": "def resolve_template(user_template: str | None) -> Path:\n    if user_template:\n        p = Path(user_template)\n        if not p.exists():\n            raise FileNotFoundError(f\"Template not found: {p}\")\n        return p\n    # Auto-selection order\n    candidates = [\n        Path(\"scripts/offllm_symbiosis_advisor_v6.py\"),\n        Path(\"scripts/offllm_symbiosis_advisor_v5.py\"),",
        "detail": "scripts.eval.run_prompt_regression",
        "documentation": {}
    },
    {
        "label": "run_regression",
        "kind": 2,
        "importPath": "scripts.eval.run_prompt_regression",
        "description": "scripts.eval.run_prompt_regression",
        "peekOfCode": "def run_regression(template: Path) -> Dict[str, Any]:\n    \"\"\"\n    Replace this stub with your real regression logic if needed.\n    This version preserves existing behaviour while making failures explicit.\n    \"\"\"\n    # Minimal example: single passing check\n    return {\n        \"summary\": {\"total\": 1, \"passed\": 1, \"failed\": 0},\n        \"results\": [\n            {",
        "detail": "scripts.eval.run_prompt_regression",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.eval.run_prompt_regression",
        "description": "scripts.eval.run_prompt_regression",
        "peekOfCode": "def main() -> int:\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--template\", help=\"Path to prompt template\")\n    parser.add_argument(\"--report-out\", required=True)\n    parser.add_argument(\"--sarif-out\", required=True)\n    args = parser.parse_args()\n    report_path = Path(args.report_out)\n    sarif_path = Path(args.sarif_out)\n    report_path.parent.mkdir(parents=True, exist_ok=True)\n    sarif_path.parent.mkdir(parents=True, exist_ok=True)",
        "detail": "scripts.eval.run_prompt_regression",
        "documentation": {}
    },
    {
        "label": "run_model_mode",
        "kind": 2,
        "importPath": "scripts.eval.run_prompt_regression",
        "description": "scripts.eval.run_prompt_regression",
        "peekOfCode": "def run_model_mode(args: argparse.Namespace) -> None:\n    prompt_paths = (args.prompts or []) + (args.golden or [])\n    if not prompt_paths:\n        raise ValueError(\"At least one --prompts (or --golden) path is required\")\n    if not args.model_cmd:\n        raise ValueError(\"--model-cmd is required for model-based regression\")\n    cases = load_cases(prompt_paths)\n    failures = []\n    sarif_results = []\n    rules = [",
        "detail": "scripts.eval.run_prompt_regression",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.eval.run_prompt_regression",
        "description": "scripts.eval.run_prompt_regression",
        "peekOfCode": "def main() -> None:\n    args = parse_args()\n    if args.model_cmd or args.prompts or args.golden:\n        run_model_mode(args)\n    else:\n        run_registry_mode(args)\nif __name__ == \"__main__\":\n    raise SystemExit(main())",
        "detail": "scripts.eval.run_prompt_regression",
        "documentation": {}
    },
    {
        "label": "load_json",
        "kind": 2,
        "importPath": "scripts.eval.write_eval_summary",
        "description": "scripts.eval.write_eval_summary",
        "peekOfCode": "def load_json(path: Path) -> dict[str, Any]:\n    if not path.exists():\n        raise FileNotFoundError(f\"Input not found: {path}\")\n    with path.open(\"r\", encoding=\"utf-8\") as handle:\n        return json.load(handle)\ndef require_fields(payload: dict[str, Any], fields: set[str], label: str) -> None:\n    missing = [field for field in fields if field not in payload]\n    if missing:\n        raise ValueError(f\"{label} missing required fields: {missing}\")\ndef compare_metric(",
        "detail": "scripts.eval.write_eval_summary",
        "documentation": {}
    },
    {
        "label": "require_fields",
        "kind": 2,
        "importPath": "scripts.eval.write_eval_summary",
        "description": "scripts.eval.write_eval_summary",
        "peekOfCode": "def require_fields(payload: dict[str, Any], fields: set[str], label: str) -> None:\n    missing = [field for field in fields if field not in payload]\n    if missing:\n        raise ValueError(f\"{label} missing required fields: {missing}\")\ndef compare_metric(\n    name: str, current: float | int | bool, baseline: float | int | bool\n) -> dict[str, Any]:\n    if name in HIGHER_IS_BETTER:\n        regressed = current < baseline\n    elif name in LOWER_IS_BETTER:",
        "detail": "scripts.eval.write_eval_summary",
        "documentation": {}
    },
    {
        "label": "compare_metric",
        "kind": 2,
        "importPath": "scripts.eval.write_eval_summary",
        "description": "scripts.eval.write_eval_summary",
        "peekOfCode": "def compare_metric(\n    name: str, current: float | int | bool, baseline: float | int | bool\n) -> dict[str, Any]:\n    if name in HIGHER_IS_BETTER:\n        regressed = current < baseline\n    elif name in LOWER_IS_BETTER:\n        regressed = current > baseline\n    else:\n        regressed = current != baseline\n    return {",
        "detail": "scripts.eval.write_eval_summary",
        "documentation": {}
    },
    {
        "label": "build_summary",
        "kind": 2,
        "importPath": "scripts.eval.write_eval_summary",
        "description": "scripts.eval.write_eval_summary",
        "peekOfCode": "def build_summary(\n    prompt_regression: dict[str, Any],\n    tool_json: dict[str, Any],\n    retrieval: dict[str, Any],\n    latency: dict[str, Any],\n    memory: dict[str, Any],\n    baseline: dict[str, Any] | None,\n) -> dict[str, Any]:\n    require_fields(prompt_regression, {\"passed\", \"failures\"}, \"prompt_regression\")\n    require_fields(tool_json, {\"valid_rate\"}, \"tool_json\")",
        "detail": "scripts.eval.write_eval_summary",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.eval.write_eval_summary",
        "description": "scripts.eval.write_eval_summary",
        "peekOfCode": "def main() -> None:\n    parser = argparse.ArgumentParser(\n        description=\"Write eval summary and enforce regression gating.\"\n    )\n    parser.add_argument(\"--prompt-regression\", required=True)\n    parser.add_argument(\"--tool-json\", required=True)\n    parser.add_argument(\"--retrieval\", required=True)\n    parser.add_argument(\"--latency\", required=True)\n    parser.add_argument(\"--memory\", required=True)\n    parser.add_argument(\"--baseline\", default=None)",
        "detail": "scripts.eval.write_eval_summary",
        "documentation": {}
    },
    {
        "label": "HIGHER_IS_BETTER",
        "kind": 5,
        "importPath": "scripts.eval.write_eval_summary",
        "description": "scripts.eval.write_eval_summary",
        "peekOfCode": "HIGHER_IS_BETTER = {\"mrr\", \"ndcg\", \"valid_rate\", \"passed\"}\nLOWER_IS_BETTER = {\"p95_latency_ms\", \"peak_memory_mb\"}\ndef load_json(path: Path) -> dict[str, Any]:\n    if not path.exists():\n        raise FileNotFoundError(f\"Input not found: {path}\")\n    with path.open(\"r\", encoding=\"utf-8\") as handle:\n        return json.load(handle)\ndef require_fields(payload: dict[str, Any], fields: set[str], label: str) -> None:\n    missing = [field for field in fields if field not in payload]\n    if missing:",
        "detail": "scripts.eval.write_eval_summary",
        "documentation": {}
    },
    {
        "label": "LOWER_IS_BETTER",
        "kind": 5,
        "importPath": "scripts.eval.write_eval_summary",
        "description": "scripts.eval.write_eval_summary",
        "peekOfCode": "LOWER_IS_BETTER = {\"p95_latency_ms\", \"peak_memory_mb\"}\ndef load_json(path: Path) -> dict[str, Any]:\n    if not path.exists():\n        raise FileNotFoundError(f\"Input not found: {path}\")\n    with path.open(\"r\", encoding=\"utf-8\") as handle:\n        return json.load(handle)\ndef require_fields(payload: dict[str, Any], fields: set[str], label: str) -> None:\n    missing = [field for field in fields if field not in payload]\n    if missing:\n        raise ValueError(f\"{label} missing required fields: {missing}\")",
        "detail": "scripts.eval.write_eval_summary",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.mlops.generate_retrieval_pairs",
        "description": "scripts.mlops.generate_retrieval_pairs",
        "peekOfCode": "def main() -> None:\n    parser = argparse.ArgumentParser(\n        description=\"Generate contrastive retrieval pairs from telemetry logs.\"\n    )\n    parser.add_argument(\"--telemetry\", required=True)\n    parser.add_argument(\"--output\", required=True)\n    parser.add_argument(\"--max-negatives\", type=int, default=4)\n    args = parser.parse_args()\n    telemetry_path = Path(args.telemetry)\n    if not telemetry_path.exists():",
        "detail": "scripts.mlops.generate_retrieval_pairs",
        "documentation": {}
    },
    {
        "label": "load_manifest",
        "kind": 2,
        "importPath": "scripts.mlops.harvest_fr",
        "description": "scripts.mlops.harvest_fr",
        "peekOfCode": "def load_manifest(path: str) -> dict:\n    if not os.path.isfile(path):\n        raise FileNotFoundError(f\"Manifest not found: {path}\")\n    with open(path, \"r\", encoding=\"utf-8\") as handle:\n        return json.load(handle)\ndef stream_source_records(source: dict) -> Iterable[Dict[str, str]]:\n    dataset = load_dataset(\n        source[\"dataset\"],\n        source.get(\"subset\"),\n        split=source.get(\"split\", \"train\"),",
        "detail": "scripts.mlops.harvest_fr",
        "documentation": {}
    },
    {
        "label": "stream_source_records",
        "kind": 2,
        "importPath": "scripts.mlops.harvest_fr",
        "description": "scripts.mlops.harvest_fr",
        "peekOfCode": "def stream_source_records(source: dict) -> Iterable[Dict[str, str]]:\n    dataset = load_dataset(\n        source[\"dataset\"],\n        source.get(\"subset\"),\n        split=source.get(\"split\", \"train\"),\n        streaming=True,\n    )\n    text_field = source.get(\"text_field\", \"text\")\n    for record in dataset:\n        text = record.get(text_field)",
        "detail": "scripts.mlops.harvest_fr",
        "documentation": {}
    },
    {
        "label": "harvest_sources",
        "kind": 2,
        "importPath": "scripts.mlops.harvest_fr",
        "description": "scripts.mlops.harvest_fr",
        "peekOfCode": "def harvest_sources(\n    manifest: dict,\n    output_path: str,\n    max_records: int,\n    min_chars: int,\n    selected_sources: list[str],\n) -> None:\n    sources = manifest.get(\"sources\", [])\n    if selected_sources:\n        sources = [s for s in sources if s[\"name\"] in selected_sources]",
        "detail": "scripts.mlops.harvest_fr",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.mlops.harvest_fr",
        "description": "scripts.mlops.harvest_fr",
        "peekOfCode": "def main() -> None:\n    parser = argparse.ArgumentParser(\n        description=\"Harvest French text data from HF datasets using a manifest.\"\n    )\n    parser.add_argument(\n        \"--manifest\",\n        default=os.path.join(\n            os.path.dirname(__file__), \"sources_fr_manifest.json\"\n        ),\n    )",
        "detail": "scripts.mlops.harvest_fr",
        "documentation": {}
    },
    {
        "label": "TextDataset",
        "kind": 6,
        "importPath": "scripts.mlops.llm2vec_train",
        "description": "scripts.mlops.llm2vec_train",
        "peekOfCode": "class TextDataset(Dataset):\n    def __init__(self, texts: List[str]):\n        self.texts = [t for t in texts if isinstance(t, str) and t.strip()]\n    def __len__(self) -> int:\n        return len(self.texts)\n    def __getitem__(self, idx: int) -> str:\n        return self.texts[idx]\ndef _random_token_window(input_ids: torch.Tensor, max_len: int) -> torch.Tensor:\n    # input_ids: (seq,)\n    seq_len = int(input_ids.numel())",
        "detail": "scripts.mlops.llm2vec_train",
        "documentation": {}
    },
    {
        "label": "Embedder",
        "kind": 6,
        "importPath": "scripts.mlops.llm2vec_train",
        "description": "scripts.mlops.llm2vec_train",
        "peekOfCode": "class Embedder(nn.Module):\n    def __init__(self, base_model: nn.Module, hidden_size: int, proj_dim: int):\n        super().__init__()\n        self.base_model = base_model\n        self.proj = nn.Linear(hidden_size, proj_dim, bias=False)\n    @staticmethod\n    def mean_pool(last_hidden: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n        # last_hidden: (B, T, H), attention_mask: (B, T)\n        mask = attention_mask.unsqueeze(-1).to(last_hidden.dtype)  # (B,T,1)\n        summed = (last_hidden * mask).sum(dim=1)",
        "detail": "scripts.mlops.llm2vec_train",
        "documentation": {}
    },
    {
        "label": "info_nce",
        "kind": 2,
        "importPath": "scripts.mlops.llm2vec_train",
        "description": "scripts.mlops.llm2vec_train",
        "peekOfCode": "def info_nce(z1: torch.Tensor, z2: torch.Tensor, temperature: float) -> torch.Tensor:\n    # z1,z2: (B,D), normalized\n    logits = (z1 @ z2.t()) / temperature  # (B,B)\n    labels = torch.arange(z1.size(0), device=z1.device)\n    loss_a = F.cross_entropy(logits, labels)\n    loss_b = F.cross_entropy(logits.t(), labels)\n    return 0.5 * (loss_a + loss_b)\ndef main() -> int:\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"--base_model\", required=True)",
        "detail": "scripts.mlops.llm2vec_train",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.mlops.llm2vec_train",
        "description": "scripts.mlops.llm2vec_train",
        "peekOfCode": "def main() -> int:\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"--base_model\", required=True)\n    ap.add_argument(\"--base_model_revision\", default=None)\n    ap.add_argument(\"--lora_dir\", required=True)\n    ap.add_argument(\"--output_dir\", required=True)\n    # These are what your pipeline passes (previously unrecognized)\n    ap.add_argument(\"--epochs\", type=int, default=1)\n    ap.add_argument(\"--batch_size\", type=int, default=1)\n    ap.add_argument(\"--lr\", type=float, default=2e-5)",
        "detail": "scripts.mlops.llm2vec_train",
        "documentation": {}
    },
    {
        "label": "normalize_sft",
        "kind": 2,
        "importPath": "scripts.mlops.normalize_datasets",
        "description": "scripts.mlops.normalize_datasets",
        "peekOfCode": "def normalize_sft(record: dict) -> dict:\n    required = {\"instruction\", \"expected_answer\"}\n    missing = required - record.keys()\n    if missing:\n        raise ValueError(f\"Missing required keys for SFT: {missing}\")\n    return {\n        \"instruction\": (record.get(\"instruction\") or \"\").strip(),\n        \"context\": record.get(\"context\") or \"\",\n        \"tool_schema\": record.get(\"tool_schema\") or \"\",\n        \"expected_tool_call\": record.get(\"expected_tool_call\") or {},",
        "detail": "scripts.mlops.normalize_datasets",
        "documentation": {}
    },
    {
        "label": "normalize_pretrain",
        "kind": 2,
        "importPath": "scripts.mlops.normalize_datasets",
        "description": "scripts.mlops.normalize_datasets",
        "peekOfCode": "def normalize_pretrain(record: dict) -> dict:\n    text = record.get(\"text\") or record.get(\"content\")\n    if not text:\n        raise ValueError(\"Missing 'text' content for pretrain normalization\")\n    if not isinstance(text, str):\n        raise ValueError(\"Expected 'text' to be a string\")\n    return {\n        \"text\": text.strip(),\n        \"metadata\": {k: v for k, v in record.items() if k not in {\"text\", \"content\"}},\n    }",
        "detail": "scripts.mlops.normalize_datasets",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.mlops.normalize_datasets",
        "description": "scripts.mlops.normalize_datasets",
        "peekOfCode": "def main() -> None:\n    parser = argparse.ArgumentParser(description=\"Normalize dataset JSONL files.\")\n    parser.add_argument(\"--input\", required=True)\n    parser.add_argument(\"--output\", required=True)\n    parser.add_argument(\n        \"--mode\",\n        choices=[\"sft\", \"pretrain\"],\n        required=True,\n        help=\"Normalization mode to apply.\",\n    )",
        "detail": "scripts.mlops.normalize_datasets",
        "documentation": {}
    },
    {
        "label": "FileSignals",
        "kind": 6,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "class FileSignals:\n    path: str\n    ext: str\n    size: int\n    sha1: str\n    markers: dict[str, int]\n    imports: list[str]\n    exports: list[str]\n    contains_todo: bool\nIMPORT_RE_PY = re.compile(",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "SearchMap",
        "kind": 6,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "class SearchMap:\n    prompts: list[str]\n    tools: list[str]\n    telemetry: list[str]\n    rag: list[str]\n    eval: list[str]\n    ios: list[str]\n    security: list[str]\n@dataclass\nclass RefactorFinding:",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "RefactorFinding",
        "kind": 6,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "class RefactorFinding:\n    title: str\n    severity: str  # low/med/high\n    why: str\n    where: list[str]\n    suggested_actions: list[str]\n@dataclass\nclass FineTuneAxis:\n    axis: str\n    goal: str",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "FineTuneAxis",
        "kind": 6,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "class FineTuneAxis:\n    axis: str\n    goal: str\n    dataset_sources: list[str]\n    evals: list[str]\n    notes: str\n@dataclass\nclass SymbiosisPlan:\n    generated_at: str\n    repo_root: str",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "SymbiosisPlan",
        "kind": 6,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "class SymbiosisPlan:\n    generated_at: str\n    repo_root: str\n    repo_fingerprint: str\n    totals: dict[str, Any]\n    search_map: SearchMap\n    refactor_findings: list[RefactorFinding]\n    finetune_axes: list[FineTuneAxis]\ndef fingerprint_repo(repo_root: Path, file_sigs: list[FileSignals]) -> str:\n    # deterministic fingerprint from sorted (path, sha1)",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "sha1_bytes",
        "kind": 2,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def sha1_bytes(b: bytes) -> str:\n    h = hashlib.sha1()\n    h.update(b)\n    return h.hexdigest()\ndef safe_read_text(path: Path, limit_bytes: int = DEFAULT_LIMIT_BYTES) -> str:\n    try:\n        data = path.read_bytes()\n    except Exception:\n        return \"\"\n    if len(data) > limit_bytes:",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "safe_read_text",
        "kind": 2,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def safe_read_text(path: Path, limit_bytes: int = DEFAULT_LIMIT_BYTES) -> str:\n    try:\n        data = path.read_bytes()\n    except Exception:\n        return \"\"\n    if len(data) > limit_bytes:\n        data = data[:limit_bytes]\n    try:\n        return data.decode(\"utf-8\", errors=\"replace\")\n    except Exception:",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "rel",
        "kind": 2,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def rel(repo_root: Path, p: Path) -> str:\n    try:\n        return str(p.relative_to(repo_root))\n    except Exception:\n        return str(p)\ndef is_probably_binary(path: Path) -> bool:\n    ext = path.suffix.lower()\n    if ext in BINARY_EXTS:\n        return True\n    return False",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "is_probably_binary",
        "kind": 2,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def is_probably_binary(path: Path) -> bool:\n    ext = path.suffix.lower()\n    if ext in BINARY_EXTS:\n        return True\n    return False\ndef walk_repo(repo_root: Path, max_files: int) -> list[Path]:\n    out: list[Path] = []\n    for root, dirs, files in os.walk(repo_root):\n        # prune\n        dirs[:] = [d for d in dirs if d not in SKIP_DIR_NAMES]",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "walk_repo",
        "kind": 2,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def walk_repo(repo_root: Path, max_files: int) -> list[Path]:\n    out: list[Path] = []\n    for root, dirs, files in os.walk(repo_root):\n        # prune\n        dirs[:] = [d for d in dirs if d not in SKIP_DIR_NAMES]\n        for fn in files:\n            p = Path(root) / fn\n            if len(out) >= max_files:\n                return out\n            out.append(p)",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "count_markers",
        "kind": 2,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def count_markers(text: str, markers: list[str]) -> int:\n    low = text.lower()\n    n = 0\n    for m in markers:\n        n += low.count(m.lower())\n    return n\ndef extract_imports_exports(path: Path, text: str) -> tuple[list[str], list[str]]:\n    ext = path.suffix.lower()\n    imports: list[str] = []\n    exports: list[str] = []",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "extract_imports_exports",
        "kind": 2,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def extract_imports_exports(path: Path, text: str) -> tuple[list[str], list[str]]:\n    ext = path.suffix.lower()\n    imports: list[str] = []\n    exports: list[str] = []\n    if ext == \".py\":\n        for a, b in IMPORT_RE_PY.findall(text):\n            mod = a or b\n            if mod:\n                imports.append(mod)\n    elif ext in {\".js\", \".ts\", \".tsx\", \".jsx\"}:",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "signals_for_file",
        "kind": 2,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def signals_for_file(\n    repo_root: Path, p: Path, limit_bytes: int\n) -> Optional[FileSignals]:\n    try:\n        st = p.stat()\n    except Exception:\n        return None\n    if p.is_dir():\n        return None\n    if is_probably_binary(p):",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "fingerprint_repo",
        "kind": 2,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def fingerprint_repo(repo_root: Path, file_sigs: list[FileSignals]) -> str:\n    # deterministic fingerprint from sorted (path, sha1)\n    h = hashlib.sha1()\n    for fs in sorted(file_sigs, key=lambda x: x.path):\n        h.update(fs.path.encode(\"utf-8\"))\n        h.update(fs.sha1.encode(\"utf-8\"))\n    return h.hexdigest()\ndef top_paths(file_sigs: list[FileSignals], key: str, k: int = 20) -> list[str]:\n    scored = [\n        (fs.markers.get(key, 0), fs.path)",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "top_paths",
        "kind": 2,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def top_paths(file_sigs: list[FileSignals], key: str, k: int = 20) -> list[str]:\n    scored = [\n        (fs.markers.get(key, 0), fs.path)\n        for fs in file_sigs\n        if fs.markers.get(key, 0) > 0\n    ]\n    scored.sort(reverse=True)\n    return [p for _, p in scored[:k]]\ndef build_search_map(file_sigs: list[FileSignals]) -> SearchMap:\n    return SearchMap(",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "build_search_map",
        "kind": 2,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def build_search_map(file_sigs: list[FileSignals]) -> SearchMap:\n    return SearchMap(\n        prompts=top_paths(file_sigs, \"prompts\", 35),\n        tools=top_paths(file_sigs, \"tools\", 35),\n        telemetry=top_paths(file_sigs, \"telemetry\", 35),\n        rag=top_paths(file_sigs, \"rag\", 35),\n        eval=top_paths(file_sigs, \"eval\", 35),\n        ios=top_paths(file_sigs, \"ios\", 35),\n        security=top_paths(file_sigs, \"security\", 35),\n    )",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "find_dup_candidates",
        "kind": 2,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def find_dup_candidates(\n    file_sigs: list[FileSignals], key: str, min_hits: int = 3\n) -> dict[str, list[str]]:\n    # quick-and-dirty \"duplication smell\": many files with the same marker set > threshold\n    buckets: dict[str, list[str]] = {}\n    for fs in file_sigs:\n        if fs.markers.get(key, 0) >= min_hits:\n            bucket_key = f\"{key}:{min_hits}\"\n            buckets.setdefault(bucket_key, []).append(fs.path)\n    return buckets",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "build_refactor_findings",
        "kind": 2,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def build_refactor_findings(\n    repo_root: Path, file_sigs: list[FileSignals], search: SearchMap\n) -> list[RefactorFinding]:\n    findings: list[RefactorFinding] = []\n    # 1) Prompt & tool surfaces: encourage single schema & versioned templates\n    if len(search.prompts) > 0:\n        findings.append(\n            RefactorFinding(\n                title=\"Unify prompt surfaces into versioned templates\",\n                severity=\"high\",",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "build_finetune_axes",
        "kind": 2,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def build_finetune_axes(search: SearchMap) -> list[FineTuneAxis]:\n    # This is deterministic but still \"policy\"it suggests a rational alignment.\n    axes: list[FineTuneAxis] = []\n    axes.append(\n        FineTuneAxis(\n            axis=\"Tool calling & JSON robustness\",\n            goal=\"Valid tool JSON, correct tool selection, safe refusal when schema cannot be satisfied.\",\n            dataset_sources=(\n                [\"telemetry: tool_calls + outcomes\"]\n                + ([\"code: tool schemas + handlers\"] if search.tools else [])",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "write_markdown",
        "kind": 2,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def write_markdown(plan: SymbiosisPlan, out_md: Path) -> None:\n    sm = plan.search_map\n    lines: list[str] = []\n    lines.append(\"# offLLM Symbiosis Report\\n\")\n    lines.append(f\"- Generated: **{plan.generated_at}**\")\n    lines.append(f\"- Repo root: `{plan.repo_root}`\")\n    lines.append(f\"- Repo fingerprint: `{plan.repo_fingerprint}`\")\n    lines.append(\"\")\n    lines.append(\"## Totals\")\n    for k, v in plan.totals.items():",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def main() -> int:\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"--repo-root\", required=True, help=\"Path to repo root\")\n    ap.add_argument(\"--out-dir\", required=True, help=\"Output directory\")\n    ap.add_argument(\"--max-files\", type=int, default=20000)\n    ap.add_argument(\"--limit-bytes\", type=int, default=DEFAULT_LIMIT_BYTES)\n    args = ap.parse_args()\n    repo_root = Path(args.repo_root).resolve()\n    out_dir = Path(args.out_dir).resolve()\n    out_dir.mkdir(parents=True, exist_ok=True)",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "TEXT_EXTS",
        "kind": 5,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "TEXT_EXTS = {\n    \".py\",\n    \".js\",\n    \".ts\",\n    \".tsx\",\n    \".jsx\",\n    \".md\",\n    \".json\",\n    \".yml\",\n    \".yaml\",",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "BINARY_EXTS",
        "kind": 5,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "BINARY_EXTS = {\n    \".png\",\n    \".jpg\",\n    \".jpeg\",\n    \".gif\",\n    \".webp\",\n    \".mp4\",\n    \".mov\",\n    \".zip\",\n    \".a\",",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "SKIP_DIR_NAMES",
        "kind": 5,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "SKIP_DIR_NAMES = {\n    \".git\",\n    \".hg\",\n    \".svn\",\n    \"__pycache__\",\n    \".venv\",\n    \"venv\",\n    \"node_modules\",\n    \"Pods\",\n    \"build\",",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "DEFAULT_LIMIT_BYTES",
        "kind": 5,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "DEFAULT_LIMIT_BYTES = 1_500_000  # avoid slurping giant files\ndef sha1_bytes(b: bytes) -> str:\n    h = hashlib.sha1()\n    h.update(b)\n    return h.hexdigest()\ndef safe_read_text(path: Path, limit_bytes: int = DEFAULT_LIMIT_BYTES) -> str:\n    try:\n        data = path.read_bytes()\n    except Exception:\n        return \"\"",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "PROMPT_MARKERS",
        "kind": 5,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "PROMPT_MARKERS = [\n    \"SYSTEM_PROMPT\",\n    \"system prompt\",\n    \"You are\",\n    \"### Instruction\",\n    \"### Response\",\n    \"prompt_template\",\n    \"PROMPT_TEMPLATE\",\n    \"few-shot\",\n    \"chain-of-thought\",",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "TOOL_MARKERS",
        "kind": 5,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "TOOL_MARKERS = [\n    \"tool\",\n    \"tools\",\n    \"tool_call\",\n    \"call_tool\",\n    \"ToolHandler\",\n    \"ToolParser\",\n    \"function_call\",\n    \"schema\",\n    \"jsonschema\",",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "TELEMETRY_MARKERS",
        "kind": 5,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "TELEMETRY_MARKERS = [\n    \"telemetry\",\n    \"trace\",\n    \"span\",\n    \"opentelemetry\",\n    \"metrics\",\n    \"prometheus\",\n    \"statsd\",\n    \"sentry\",\n    \"event_name\",",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "RAG_MARKERS",
        "kind": 5,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "RAG_MARKERS = [\n    \"embedding\",\n    \"vector\",\n    \"hnsw\",\n    \"faiss\",\n    \"pgvector\",\n    \"retrieval\",\n    \"rerank\",\n    \"reranker\",\n    \"chunk\",",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "EVAL_MARKERS",
        "kind": 5,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "EVAL_MARKERS = [\n    \"eval\",\n    \"evaluation\",\n    \"benchmark\",\n    \"golden\",\n    \"regression\",\n    \"score\",\n    \"accuracy\",\n    \"mmlu\",\n    \"truthful\",",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "IOS_MARKERS",
        "kind": 5,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "IOS_MARKERS = [\n    \"CoreML\",\n    \"coreml\",\n    \"mlmodel\",\n    \"MLModel\",\n    \"mlx\",\n    \"Metal\",\n    \"ANE\",\n    \"Xcode\",\n    \"xcworkspace\",",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "SECURITY_MARKERS",
        "kind": 5,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "SECURITY_MARKERS = [\n    \"sanitize\",\n    \"redact\",\n    \"secret\",\n    \"token\",\n    \"apikey\",\n    \"api_key\",\n    \"PII\",\n    \"prompt injection\",\n    \"injection\",",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "IMPORT_RE_PY",
        "kind": 5,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "IMPORT_RE_PY = re.compile(\n    r\"^\\s*(?:from\\s+([a-zA-Z0-9_\\.]+)\\s+import|import\\s+([a-zA-Z0-9_\\.]+))\",\n    re.M,\n)\nIMPORT_RE_JS = re.compile(r\"^\\s*import\\s+.*?\\s+from\\s+['\\\"]([^'\\\"]+)['\\\"]\\s*;?\", re.M)\nREQUIRE_RE_JS = re.compile(r\"require\\(\\s*['\\\"]([^'\\\"]+)['\\\"]\\s*\\)\")\nEXPORT_RE_JS = re.compile(r\"^\\s*export\\s+(?:default\\s+)?\", re.M)\ndef count_markers(text: str, markers: list[str]) -> int:\n    low = text.lower()\n    n = 0",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "IMPORT_RE_JS",
        "kind": 5,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "IMPORT_RE_JS = re.compile(r\"^\\s*import\\s+.*?\\s+from\\s+['\\\"]([^'\\\"]+)['\\\"]\\s*;?\", re.M)\nREQUIRE_RE_JS = re.compile(r\"require\\(\\s*['\\\"]([^'\\\"]+)['\\\"]\\s*\\)\")\nEXPORT_RE_JS = re.compile(r\"^\\s*export\\s+(?:default\\s+)?\", re.M)\ndef count_markers(text: str, markers: list[str]) -> int:\n    low = text.lower()\n    n = 0\n    for m in markers:\n        n += low.count(m.lower())\n    return n\ndef extract_imports_exports(path: Path, text: str) -> tuple[list[str], list[str]]:",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "REQUIRE_RE_JS",
        "kind": 5,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "REQUIRE_RE_JS = re.compile(r\"require\\(\\s*['\\\"]([^'\\\"]+)['\\\"]\\s*\\)\")\nEXPORT_RE_JS = re.compile(r\"^\\s*export\\s+(?:default\\s+)?\", re.M)\ndef count_markers(text: str, markers: list[str]) -> int:\n    low = text.lower()\n    n = 0\n    for m in markers:\n        n += low.count(m.lower())\n    return n\ndef extract_imports_exports(path: Path, text: str) -> tuple[list[str], list[str]]:\n    ext = path.suffix.lower()",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "EXPORT_RE_JS",
        "kind": 5,
        "importPath": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "description": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "peekOfCode": "EXPORT_RE_JS = re.compile(r\"^\\s*export\\s+(?:default\\s+)?\", re.M)\ndef count_markers(text: str, markers: list[str]) -> int:\n    low = text.lower()\n    n = 0\n    for m in markers:\n        n += low.count(m.lower())\n    return n\ndef extract_imports_exports(path: Path, text: str) -> tuple[list[str], list[str]]:\n    ext = path.suffix.lower()\n    imports: list[str] = []",
        "detail": "scripts.mlops.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "scan_jsonl",
        "kind": 2,
        "importPath": "scripts.mlops.scan_internal",
        "description": "scripts.mlops.scan_internal",
        "peekOfCode": "def scan_jsonl(path: Path, max_samples: int) -> dict:\n    stats = {\n        \"path\": str(path),\n        \"bytes\": path.stat().st_size,\n        \"records\": 0,\n        \"avg_text_length\": 0,\n        \"keys\": Counter(),\n        \"sample\": [],\n    }\n    total_length = 0",
        "detail": "scripts.mlops.scan_internal",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.mlops.scan_internal",
        "description": "scripts.mlops.scan_internal",
        "peekOfCode": "def main() -> None:\n    parser = argparse.ArgumentParser(description=\"Scan internal dataset files.\")\n    parser.add_argument(\"--data-dir\", required=True)\n    parser.add_argument(\"--output\", required=True)\n    parser.add_argument(\"--max-samples\", type=int, default=3)\n    args = parser.parse_args()\n    data_dir = Path(args.data_dir)\n    if not data_dir.exists():\n        raise FileNotFoundError(f\"Data directory not found: {data_dir}\")\n    reports = []",
        "detail": "scripts.mlops.scan_internal",
        "documentation": {}
    },
    {
        "label": "load_redaction_patterns",
        "kind": 2,
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "peekOfCode": "def load_redaction_patterns() -> dict[str, re.Pattern]:\n    patterns_path = (\n        Path(__file__).resolve().parents[2] / \"schemas\" / \"redaction_patterns.json\"\n    )\n    with patterns_path.open(\"r\", encoding=\"utf-8\") as handle:\n        raw = json.load(handle)\n    return {\n        \"email\": re.compile(raw[\"email\"], re.IGNORECASE),\n        \"phone\": re.compile(raw[\"phone\"]),\n        \"token\": re.compile(raw[\"token\"]),",
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "redact_string",
        "kind": 2,
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "peekOfCode": "def redact_string(value: str, patterns: dict[str, re.Pattern]) -> str:\n    result = patterns[\"email\"].sub(\"[REDACTED_EMAIL]\", value)\n    result = patterns[\"phone\"].sub(\"[REDACTED_PHONE]\", result)\n    result = patterns[\"bearer\"].sub(\"Bearer [REDACTED]\", result)\n    result = patterns[\"token\"].sub(\"[REDACTED_TOKEN]\", result)\n    result = patterns[\"secret\"].sub(\"[REDACTED_SECRET]\", result)\n    if len(result) > MAX_VALUE_LENGTH:\n        result = f\"{result[:MAX_VALUE_LENGTH]}[TRUNCATED]\"\n    return result\ndef redact_value(value: Any, patterns: dict[str, re.Pattern]) -> Any:",
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "redact_value",
        "kind": 2,
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "peekOfCode": "def redact_value(value: Any, patterns: dict[str, re.Pattern]) -> Any:\n    if value is None:\n        return value\n    if isinstance(value, str):\n        return redact_string(value, patterns)\n    if isinstance(value, (int, float, bool)):\n        return value\n    if isinstance(value, list):\n        return [redact_value(item, patterns) for item in value]\n    if isinstance(value, dict):",
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "stable_dumps",
        "kind": 2,
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "peekOfCode": "def stable_dumps(payload: Any) -> str:\n    return json.dumps(payload, ensure_ascii=False, sort_keys=True)\ndef load_telemetry_schema() -> dict:\n    schema_path = Path(__file__).resolve().parents[2] / \"schemas\" / \"telemetry_event.schema.json\"\n    with schema_path.open(\"r\", encoding=\"utf-8\") as handle:\n        return json.load(handle)\ndef _matches_type(value: Any, expected: Any) -> bool:\n    if isinstance(expected, list):\n        return any(_matches_type(value, entry) for entry in expected)\n    if expected == \"string\":",
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "load_telemetry_schema",
        "kind": 2,
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "peekOfCode": "def load_telemetry_schema() -> dict:\n    schema_path = Path(__file__).resolve().parents[2] / \"schemas\" / \"telemetry_event.schema.json\"\n    with schema_path.open(\"r\", encoding=\"utf-8\") as handle:\n        return json.load(handle)\ndef _matches_type(value: Any, expected: Any) -> bool:\n    if isinstance(expected, list):\n        return any(_matches_type(value, entry) for entry in expected)\n    if expected == \"string\":\n        return isinstance(value, str)\n    if expected == \"number\":",
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "validate_event_schema",
        "kind": 2,
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "peekOfCode": "def validate_event_schema(event: dict, schema: dict) -> list[str]:\n    errors: list[str] = []\n    required = schema.get(\"required\", [])\n    properties = schema.get(\"properties\", {})\n    for field in required:\n        if field not in event:\n            errors.append(f\"missing required field: {field}\")\n            continue\n        expected_type = properties.get(field, {}).get(\"type\")\n        if expected_type and not _matches_type(event.get(field), expected_type):",
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "redact_event",
        "kind": 2,
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "peekOfCode": "def redact_event(event: dict, patterns: dict[str, re.Pattern]) -> dict:\n    redacted = redact_value(event, patterns)\n    if isinstance(redacted, dict):\n        redacted[\"redaction_applied\"] = stable_dumps(redacted) != stable_dumps(event)\n    return redacted\ndef main() -> None:\n    parser = argparse.ArgumentParser(\n        description=\"Redact telemetry JSONL and validate against the schema.\"\n    )\n    parser.add_argument(\"--input\", required=True)",
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "peekOfCode": "def main() -> None:\n    parser = argparse.ArgumentParser(\n        description=\"Redact telemetry JSONL and validate against the schema.\"\n    )\n    parser.add_argument(\"--input\", required=True)\n    parser.add_argument(\"--output\", required=True)\n    parser.add_argument(\n        \"--strict\",\n        action=\"store_true\",\n        help=\"Fail if any event fails schema validation.\",",
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "MAX_VALUE_LENGTH",
        "kind": 5,
        "importPath": "scripts.mlops.telemetry_redaction",
        "description": "scripts.mlops.telemetry_redaction",
        "peekOfCode": "MAX_VALUE_LENGTH = 2000\ndef load_redaction_patterns() -> dict[str, re.Pattern]:\n    patterns_path = (\n        Path(__file__).resolve().parents[2] / \"schemas\" / \"redaction_patterns.json\"\n    )\n    with patterns_path.open(\"r\", encoding=\"utf-8\") as handle:\n        raw = json.load(handle)\n    return {\n        \"email\": re.compile(raw[\"email\"], re.IGNORECASE),\n        \"phone\": re.compile(raw[\"phone\"]),",
        "detail": "scripts.mlops.telemetry_redaction",
        "documentation": {}
    },
    {
        "label": "build_retrieval_triples",
        "kind": 2,
        "importPath": "scripts.mlops.telemetry_to_retrieval_triples",
        "description": "scripts.mlops.telemetry_to_retrieval_triples",
        "peekOfCode": "def build_retrieval_triples(path: Path, strict_schema: bool) -> list[dict]:\n    patterns = load_redaction_patterns()\n    schema = load_telemetry_schema()\n    triples = []\n    invalid_events = 0\n    with path.open(\"r\", encoding=\"utf-8\") as handle:\n        for line in handle:\n            if not line.strip():\n                continue\n            event = json.loads(line)",
        "detail": "scripts.mlops.telemetry_to_retrieval_triples",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.mlops.telemetry_to_retrieval_triples",
        "description": "scripts.mlops.telemetry_to_retrieval_triples",
        "peekOfCode": "def main() -> None:\n    parser = argparse.ArgumentParser(\n        description=\"Generate retrieval triples from telemetry JSONL.\"\n    )\n    parser.add_argument(\"--telemetry\", required=True)\n    parser.add_argument(\"--output\", required=True)\n    parser.add_argument(\"--max-records\", type=int, default=500000)\n    parser.add_argument(\n        \"--strict\",\n        action=\"store_true\",",
        "detail": "scripts.mlops.telemetry_to_retrieval_triples",
        "documentation": {}
    },
    {
        "label": "REPO_ROOT",
        "kind": 5,
        "importPath": "scripts.mlops.telemetry_to_retrieval_triples",
        "description": "scripts.mlops.telemetry_to_retrieval_triples",
        "peekOfCode": "REPO_ROOT = Path(__file__).resolve().parents[2]\nsys.path.insert(0, str(REPO_ROOT))\nfrom scripts.mlops.telemetry_redaction import (  # noqa: E402\n    load_redaction_patterns,\n    load_telemetry_schema,\n    redact_event,\n    stable_dumps,\n    validate_event_schema,\n)\ndef build_retrieval_triples(path: Path, strict_schema: bool) -> list[dict]:",
        "detail": "scripts.mlops.telemetry_to_retrieval_triples",
        "documentation": {}
    },
    {
        "label": "load_tool_schema",
        "kind": 2,
        "importPath": "scripts.mlops.telemetry_to_sft",
        "description": "scripts.mlops.telemetry_to_sft",
        "peekOfCode": "def load_tool_schema(path: str) -> str:\n    if not path:\n        return \"\"\n    if not os.path.isfile(path):\n        raise FileNotFoundError(f\"Tool schema not found: {path}\")\n    with open(path, \"r\", encoding=\"utf-8\") as handle:\n        return handle.read().strip()\ndef normalize_event_type(event: dict, strict_schema: bool) -> Optional[str]:\n    event_type = event.get(\"event_type\") or event.get(\"event\")\n    if not event_type:",
        "detail": "scripts.mlops.telemetry_to_sft",
        "documentation": {}
    },
    {
        "label": "normalize_event_type",
        "kind": 2,
        "importPath": "scripts.mlops.telemetry_to_sft",
        "description": "scripts.mlops.telemetry_to_sft",
        "peekOfCode": "def normalize_event_type(event: dict, strict_schema: bool) -> Optional[str]:\n    event_type = event.get(\"event_type\") or event.get(\"event\")\n    if not event_type:\n        if strict_schema:\n            raise ValueError(\"Telemetry event missing event_type\")\n        return None\n    return event_type\ndef parse_events(path: Path, strict_schema: bool) -> dict:\n    grouped = defaultdict(lambda: {\"tool_calls\": []})\n    patterns = load_redaction_patterns()",
        "detail": "scripts.mlops.telemetry_to_sft",
        "documentation": {}
    },
    {
        "label": "parse_events",
        "kind": 2,
        "importPath": "scripts.mlops.telemetry_to_sft",
        "description": "scripts.mlops.telemetry_to_sft",
        "peekOfCode": "def parse_events(path: Path, strict_schema: bool) -> dict:\n    grouped = defaultdict(lambda: {\"tool_calls\": []})\n    patterns = load_redaction_patterns()\n    schema = load_telemetry_schema()\n    missing_event_type = 0\n    missing_prompt_hash = 0\n    invalid_schema = 0\n    with path.open(\"r\", encoding=\"utf-8\") as handle:\n        for line in handle:\n            if not line.strip():",
        "detail": "scripts.mlops.telemetry_to_sft",
        "documentation": {}
    },
    {
        "label": "build_records",
        "kind": 2,
        "importPath": "scripts.mlops.telemetry_to_sft",
        "description": "scripts.mlops.telemetry_to_sft",
        "peekOfCode": "def build_records(grouped: dict, tool_schema: str) -> list[dict]:\n    records = []\n    for prompt_hash in sorted(grouped.keys()):\n        data = grouped[prompt_hash]\n        instruction = data.get(\"instruction\")\n        expected_answer = data.get(\"expected_answer\")\n        if not instruction or not expected_answer:\n            continue\n        tool_calls = data.get(\"tool_calls\", [])\n        tool_calls_sorted = sorted(",
        "detail": "scripts.mlops.telemetry_to_sft",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.mlops.telemetry_to_sft",
        "description": "scripts.mlops.telemetry_to_sft",
        "peekOfCode": "def main() -> None:\n    parser = argparse.ArgumentParser(\n        description=\"Convert telemetry JSONL into SFT-ready JSONL.\"\n    )\n    parser.add_argument(\"--telemetry\", required=True)\n    parser.add_argument(\"--output\", required=True)\n    parser.add_argument(\"--tool-schema\", default=\"\")\n    parser.add_argument(\n        \"--strict-schema\",\n        action=\"store_true\",",
        "detail": "scripts.mlops.telemetry_to_sft",
        "documentation": {}
    },
    {
        "label": "load_tool_schema",
        "kind": 2,
        "importPath": "scripts.mlops.telemetry_to_tool_calls",
        "description": "scripts.mlops.telemetry_to_tool_calls",
        "peekOfCode": "def load_tool_schema(tool_name: str) -> dict:\n    schema_path = (\n        Path(__file__).resolve().parents[2]\n        / \"schemas\"\n        / \"tools\"\n        / f\"{tool_name}.schema.json\"\n    )\n    if not schema_path.exists():\n        raise FileNotFoundError(f\"Tool schema not found: {schema_path}\")\n    with schema_path.open(\"r\", encoding=\"utf-8\") as handle:",
        "detail": "scripts.mlops.telemetry_to_tool_calls",
        "documentation": {}
    },
    {
        "label": "validate_tool_args",
        "kind": 2,
        "importPath": "scripts.mlops.telemetry_to_tool_calls",
        "description": "scripts.mlops.telemetry_to_tool_calls",
        "peekOfCode": "def validate_tool_args(tool_name: str, args: Any) -> list[str]:\n    if not isinstance(args, dict):\n        return [f\"{tool_name} args must be an object\"]\n    schema = load_tool_schema(tool_name)\n    errors: list[str] = []\n    properties = schema.get(\"properties\", {})\n    required = schema.get(\"required\", [])\n    for field in required:\n        if field not in args:\n            errors.append(f\"{tool_name} missing required field: {field}\")",
        "detail": "scripts.mlops.telemetry_to_tool_calls",
        "documentation": {}
    },
    {
        "label": "build_tool_call_records",
        "kind": 2,
        "importPath": "scripts.mlops.telemetry_to_tool_calls",
        "description": "scripts.mlops.telemetry_to_tool_calls",
        "peekOfCode": "def build_tool_call_records(path: Path, strict_schema: bool) -> list[dict]:\n    patterns = load_redaction_patterns()\n    schema = load_telemetry_schema()\n    records = []\n    invalid_events = 0\n    invalid_tools = 0\n    with path.open(\"r\", encoding=\"utf-8\") as handle:\n        for line in handle:\n            if not line.strip():\n                continue",
        "detail": "scripts.mlops.telemetry_to_tool_calls",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.mlops.telemetry_to_tool_calls",
        "description": "scripts.mlops.telemetry_to_tool_calls",
        "peekOfCode": "def main() -> None:\n    parser = argparse.ArgumentParser(\n        description=\"Generate tool call traces from telemetry JSONL.\"\n    )\n    parser.add_argument(\"--telemetry\", required=True)\n    parser.add_argument(\"--output\", required=True)\n    parser.add_argument(\"--max-records\", type=int, default=500000)\n    parser.add_argument(\n        \"--strict\",\n        action=\"store_true\",",
        "detail": "scripts.mlops.telemetry_to_tool_calls",
        "documentation": {}
    },
    {
        "label": "REPO_ROOT",
        "kind": 5,
        "importPath": "scripts.mlops.telemetry_to_tool_calls",
        "description": "scripts.mlops.telemetry_to_tool_calls",
        "peekOfCode": "REPO_ROOT = Path(__file__).resolve().parents[2]\nsys.path.insert(0, str(REPO_ROOT))\nfrom scripts.mlops.telemetry_redaction import (  # noqa: E402\n    load_redaction_patterns,\n    load_telemetry_schema,\n    redact_event,\n    stable_dumps,\n    validate_event_schema,\n)\ndef load_tool_schema(tool_name: str) -> dict:",
        "detail": "scripts.mlops.telemetry_to_tool_calls",
        "documentation": {}
    },
    {
        "label": "sha256_file",
        "kind": 2,
        "importPath": "scripts.mlops.verify_export_manifest",
        "description": "scripts.mlops.verify_export_manifest",
        "peekOfCode": "def sha256_file(path: Path) -> str:\n    hasher = hashlib.sha256()\n    with path.open(\"rb\") as handle:\n        for chunk in iter(lambda: handle.read(1024 * 1024), b\"\"):\n            hasher.update(chunk)\n    return hasher.hexdigest()\ndef sha256_directory(path: Path) -> str:\n    hasher = hashlib.sha256()\n    files = sorted([p for p in path.rglob(\"*\") if p.is_file()])\n    for file_path in files:",
        "detail": "scripts.mlops.verify_export_manifest",
        "documentation": {}
    },
    {
        "label": "sha256_directory",
        "kind": 2,
        "importPath": "scripts.mlops.verify_export_manifest",
        "description": "scripts.mlops.verify_export_manifest",
        "peekOfCode": "def sha256_directory(path: Path) -> str:\n    hasher = hashlib.sha256()\n    files = sorted([p for p in path.rglob(\"*\") if p.is_file()])\n    for file_path in files:\n        rel_path = file_path.relative_to(path).as_posix()\n        file_hash = sha256_file(file_path)\n        hasher.update(rel_path.encode(\"utf-8\"))\n        hasher.update(file_hash.encode(\"utf-8\"))\n    return hasher.hexdigest()\ndef resolve_commit_sha(repo_root: Path) -> str:",
        "detail": "scripts.mlops.verify_export_manifest",
        "documentation": {}
    },
    {
        "label": "resolve_commit_sha",
        "kind": 2,
        "importPath": "scripts.mlops.verify_export_manifest",
        "description": "scripts.mlops.verify_export_manifest",
        "peekOfCode": "def resolve_commit_sha(repo_root: Path) -> str:\n    result = subprocess.run(\n        [\"git\", \"rev-parse\", \"HEAD\"],\n        cwd=repo_root,\n        capture_output=True,\n        text=True,\n        check=False,\n    )\n    if result.returncode != 0:\n        raise RuntimeError(result.stderr.strip() or \"Unable to resolve git SHA\")",
        "detail": "scripts.mlops.verify_export_manifest",
        "documentation": {}
    },
    {
        "label": "verify_manifest",
        "kind": 2,
        "importPath": "scripts.mlops.verify_export_manifest",
        "description": "scripts.mlops.verify_export_manifest",
        "peekOfCode": "def verify_manifest(\n    manifest: dict[str, Any], repo_root: Path, model_override: Path | None\n) -> dict[str, Any]:\n    errors = []\n    commit_sha = manifest.get(\"commit_sha\")\n    if commit_sha != resolve_commit_sha(repo_root):\n        errors.append(\"commit_sha does not match repository HEAD\")\n    model_path = Path(manifest.get(\"model_path\", \"\"))\n    if not model_path.exists():\n        errors.append(f\"model_path not found: {model_path}\")",
        "detail": "scripts.mlops.verify_export_manifest",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.mlops.verify_export_manifest",
        "description": "scripts.mlops.verify_export_manifest",
        "peekOfCode": "def main() -> None:\n    parser = argparse.ArgumentParser(\n        description=\"Verify export/manifest.json against repo and artifacts.\"\n    )\n    parser.add_argument(\"--manifest\", required=True)\n    parser.add_argument(\"--model-path\", default=None)\n    args = parser.parse_args()\n    manifest_path = Path(args.manifest)\n    if not manifest_path.exists():\n        raise FileNotFoundError(f\"Manifest not found: {manifest_path}\")",
        "detail": "scripts.mlops.verify_export_manifest",
        "documentation": {}
    },
    {
        "label": "sha256_file",
        "kind": 2,
        "importPath": "scripts.mlops.write_export_manifest",
        "description": "scripts.mlops.write_export_manifest",
        "peekOfCode": "def sha256_file(path: Path) -> str:\n    hasher = hashlib.sha256()\n    with path.open(\"rb\") as handle:\n        for chunk in iter(lambda: handle.read(1024 * 1024), b\"\"):\n            hasher.update(chunk)\n    return hasher.hexdigest()\ndef sha256_directory(path: Path) -> str:\n    hasher = hashlib.sha256()\n    files = sorted([p for p in path.rglob(\"*\") if p.is_file()])\n    for file_path in files:",
        "detail": "scripts.mlops.write_export_manifest",
        "documentation": {}
    },
    {
        "label": "sha256_directory",
        "kind": 2,
        "importPath": "scripts.mlops.write_export_manifest",
        "description": "scripts.mlops.write_export_manifest",
        "peekOfCode": "def sha256_directory(path: Path) -> str:\n    hasher = hashlib.sha256()\n    files = sorted([p for p in path.rglob(\"*\") if p.is_file()])\n    for file_path in files:\n        rel_path = file_path.relative_to(path).as_posix()\n        file_hash = sha256_file(file_path)\n        hasher.update(rel_path.encode(\"utf-8\"))\n        hasher.update(file_hash.encode(\"utf-8\"))\n    return hasher.hexdigest()\ndef resolve_commit_sha(repo_root: Path) -> str:",
        "detail": "scripts.mlops.write_export_manifest",
        "documentation": {}
    },
    {
        "label": "resolve_commit_sha",
        "kind": 2,
        "importPath": "scripts.mlops.write_export_manifest",
        "description": "scripts.mlops.write_export_manifest",
        "peekOfCode": "def resolve_commit_sha(repo_root: Path) -> str:\n    result = subprocess.run(\n        [\"git\", \"rev-parse\", \"HEAD\"],\n        cwd=repo_root,\n        capture_output=True,\n        text=True,\n        check=False,\n    )\n    if result.returncode != 0:\n        raise RuntimeError(result.stderr.strip() or \"Unable to resolve git SHA\")",
        "detail": "scripts.mlops.write_export_manifest",
        "documentation": {}
    },
    {
        "label": "build_manifest",
        "kind": 2,
        "importPath": "scripts.mlops.write_export_manifest",
        "description": "scripts.mlops.write_export_manifest",
        "peekOfCode": "def build_manifest(datasets: list[Path], model_path: Path, repo_root: Path) -> dict:\n    dataset_hashes = {}\n    for dataset in datasets:\n        dataset_hashes[dataset.as_posix()] = sha256_file(dataset)\n    if model_path.is_dir():\n        model_hash = sha256_directory(model_path)\n    else:\n        model_hash = sha256_file(model_path)\n    return {\n        \"commit_sha\": resolve_commit_sha(repo_root),",
        "detail": "scripts.mlops.write_export_manifest",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.mlops.write_export_manifest",
        "description": "scripts.mlops.write_export_manifest",
        "peekOfCode": "def main() -> None:\n    parser = argparse.ArgumentParser(\n        description=\"Write export/manifest.json for training outputs.\"\n    )\n    parser.add_argument(\"--datasets\", action=\"append\", required=True)\n    parser.add_argument(\"--model-path\", required=True)\n    parser.add_argument(\"--output\", default=\"export/manifest.json\")\n    args = parser.parse_args()\n    repo_root = Path(__file__).resolve().parents[2]\n    datasets = [Path(dataset) for dataset in args.datasets]",
        "detail": "scripts.mlops.write_export_manifest",
        "documentation": {}
    },
    {
        "label": "SliceUpdateKeyValueCache",
        "kind": 6,
        "importPath": "scripts.convert_to_coreml",
        "description": "scripts.convert_to_coreml",
        "peekOfCode": "class SliceUpdateKeyValueCache(Cache):\n    def __init__(self, *, shape, dtype=torch.float32):\n        super().__init__()\n        self.register_buffer(\"k\", torch.zeros(shape, dtype=dtype))\n        self.register_buffer(\"v\", torch.zeros(shape, dtype=dtype))\n        self.register_buffer(\n            \"_current_length\",\n            torch.zeros(shape[0], dtype=torch.int32),\n            persistent=False,\n        )",
        "detail": "scripts.convert_to_coreml",
        "documentation": {}
    },
    {
        "label": "convert",
        "kind": 2,
        "importPath": "scripts.convert_to_coreml",
        "description": "scripts.convert_to_coreml",
        "peekOfCode": "def convert(\n    hf_model_path: str,\n    out_prefix: str,\n    artifacts_path: str = \"coreml_artifacts.json\",\n    hf_token: str | None = None,\n    manifest_path: str | None = None,\n):\n    if manifest_path:\n        subprocess.run(\n            [",
        "detail": "scripts.convert_to_coreml",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.merge_lora",
        "description": "scripts.merge_lora",
        "peekOfCode": "def main() -> None:\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--base_model\", required=True)\n    parser.add_argument(\"--lora_dir\", required=True)\n    parser.add_argument(\"--output_dir\", required=True)\n    args = parser.parse_args()\n    base_model = AutoModelForCausalLM.from_pretrained(\n        args.base_model,\n        torch_dtype=\"auto\",\n    )",
        "detail": "scripts.merge_lora",
        "documentation": {}
    },
    {
        "label": "PipelineConfig",
        "kind": 6,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "class PipelineConfig:\n    \"\"\"Main configuration for the entire pipeline.\"\"\"\n    repo_root: Path\n    run_id: str\n    run_dir: Path\n    # Model configuration\n    base_model: str = \"cognitivecomputations/Dolphin3.0-Llama3.2-3B\"\n    base_model_revision: str | None = None\n    # Dataset configuration\n    datasets_dir: Path | None = None",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "ScanConfig",
        "kind": 6,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "class ScanConfig:\n    \"\"\"Configuration for repository scanning.\"\"\"\n    repo_root: Path\n    run_id: str\n    out_base: Path = Path(\"runs/scad/focused\")\n    top_n_per_category: int = 8\n    max_targets: int = 45\n    diff_target: str = \"\"\n    emit_datasets: bool = True\n    blame: bool = False",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "TrainCfg",
        "kind": 6,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "class TrainCfg:\n    \"\"\"Configuration for LLM2Vec training.\"\"\"\n    base_model: str\n    revision: str | None = None\n    adapter_dir: str | None = None\n    corpus_jsonl: str = \"\"\n    out: str = \"\"\n    max_steps: int = 1200\n    warmup_steps: int = 50\n    lr: float = 1e-4",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "PySymbol",
        "kind": 6,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "class PySymbol:\n    kind: str  # function/class/async_function\n    name: str\n    qualname: str\n    start_line: int\n    end_line: int\n    doc: str\n    signals: Dict[str, int]\n    calls: List[str]\n@dataclass",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "CommandSpec",
        "kind": 6,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "class CommandSpec:\n    path: str\n    parser_var: str\n    args: List[Dict[str, Any]]\n@dataclass\nclass EnvVarUse:\n    name: str\n    kind: str\n    line: int\n    context: str",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "EnvVarUse",
        "kind": 6,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "class EnvVarUse:\n    name: str\n    kind: str\n    line: int\n    context: str\n@dataclass\nclass Callsite:\n    category: str\n    path: str\n    line: int",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "Callsite",
        "kind": 6,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "class Callsite:\n    category: str\n    path: str\n    line: int\n    context: str\nclass RepositoryScanner:\n    \"\"\"SCAD: Static Code Analysis for Documentation and dataset generation.\"\"\"\n    IGNORE_DIRS = {\n        \".git\",\n        \".hg\",",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "RepositoryScanner",
        "kind": 6,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "class RepositoryScanner:\n    \"\"\"SCAD: Static Code Analysis for Documentation and dataset generation.\"\"\"\n    IGNORE_DIRS = {\n        \".git\",\n        \".hg\",\n        \".svn\",\n        \"node_modules\",\n        \".venv\",\n        \"venv\",\n        \"__pycache__\",",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "DatasetBuilder",
        "kind": 6,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "class DatasetBuilder:\n    \"\"\"Build training datasets from various sources.\"\"\"\n    @staticmethod\n    def build_french_datasets(out_dir: Path) -> Dict[str, Path]:\n        \"\"\"Build French language datasets.\"\"\"\n        datasets_dir = Path(\"datasets\")\n        output = {}\n        for name in [\"combined_instruct.jsonl\", \"combined_retrieval.jsonl\"]:\n            src = datasets_dir / name\n            if src.exists():",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "SFTTrainerWrapper",
        "kind": 6,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "class SFTTrainerWrapper:\n    \"\"\"Wrapper for supervised fine-tuning with LoRA.\"\"\"\n    @staticmethod\n    def train(config: PipelineConfig, dataset_path: Path) -> Path:\n        \"\"\"Train a model with SFT using LoRA.\"\"\"\n        set_seed(42)\n        out_dir = config.run_dir / \"sft\"\n        out_dir.mkdir(parents=True, exist_ok=True)\n        # Load tokenizer and model\n        tokenizer = AutoTokenizer.from_pretrained(",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "UnslothTrainerWrapper",
        "kind": 6,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "class UnslothTrainerWrapper:\n    \"\"\"Wrapper for supervised fine-tuning with Unsloth.\"\"\"\n    @staticmethod\n    def train(\n        config: PipelineConfig,\n        dataset_path: Path,\n        output_dir: Path,\n        max_steps: int,\n    ) -> Path:\n        if not _module_available(\"unsloth\"):",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "LLM2VecTrainer",
        "kind": 6,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "class LLM2VecTrainer:\n    \"\"\"Train embedding-capable models using MNTP + SimCSE.\"\"\"\n    def __init__(self, config: TrainCfg):\n        self.config = config\n    def train(self) -> Dict[str, Any]:\n        \"\"\"Main training loop for LLM2Vec.\"\"\"\n        set_seed(self.config.seed)\n        out_dir = Path(self.config.out)\n        out_dir.mkdir(parents=True, exist_ok=True)\n        # Load model and tokenizer",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "MNTPDataCollator",
        "kind": 6,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "class MNTPDataCollator:\n    \"\"\"Data collator for Masked Next Token Prediction.\"\"\"\n    def __init__(self, tokenizer, mask_prob: float = 0.15, max_length: int = 512):\n        self.tok = tokenizer\n        self.mask_prob = mask_prob\n        self.max_length = max_length\n        if self.tok.mask_token_id is None:\n            self.tok.add_special_tokens({\"mask_token\": \"<mask>\"})\n    def __call__(self, texts: List[str]) -> Dict[str, torch.Tensor]:\n        enc = self.tok(",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "PipelineOrchestrator",
        "kind": 6,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "class PipelineOrchestrator:\n    \"\"\"Orchestrate the entire multi-stage pipeline.\"\"\"\n    def __init__(self, config: PipelineConfig):\n        self.config = resolve_pipeline_config(config)\n    def run(self, stages: List[str]) -> int:\n        \"\"\"Run specified stages of the pipeline.\"\"\"\n        if \"all\" in stages:\n            stages = [\n                \"full_scan\",\n                \"scan\",",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "TerminalUI",
        "kind": 6,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "class TerminalUI:\n    \"\"\"Simple terminal UI for pipeline interaction.\"\"\"\n    @staticmethod\n    def interactive() -> int:\n        \"\"\"Run interactive terminal UI.\"\"\"\n        print(\"\\n\" + \"=\" * 50)\n        print(\"offLLM End-to-End Pipeline\")\n        print(\"=\" * 50)\n        choices = {\n            \"1\": \"Run EVERYTHING (full scan  datasets  training  export)\",",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "resolve_pipeline_config",
        "kind": 2,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "def resolve_pipeline_config(config: PipelineConfig) -> PipelineConfig:\n    repo_root = config.repo_root.expanduser().resolve()\n    run_dir = config.run_dir.expanduser()\n    if not run_dir.is_absolute():\n        run_dir = repo_root / run_dir\n    datasets_dir = (config.datasets_dir or (run_dir / \"datasets\")).expanduser()\n    if not datasets_dir.is_absolute():\n        datasets_dir = repo_root / datasets_dir\n    telemetry_path = (config.telemetry_path or (datasets_dir / \"telemetry.jsonl\")).expanduser()\n    if not telemetry_path.is_absolute():",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "utc_now",
        "kind": 2,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "def utc_now() -> str:\n    return datetime.now(timezone.utc).isoformat()\ndef default_run_id() -> str:\n    return datetime.now().strftime(\"%Y%m%d_%H%M%S\")\ndef set_seed(seed: int) -> None:\n    random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\ndef git_commit(repo_root: Path) -> str | None:",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "default_run_id",
        "kind": 2,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "def default_run_id() -> str:\n    return datetime.now().strftime(\"%Y%m%d_%H%M%S\")\ndef set_seed(seed: int) -> None:\n    random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\ndef git_commit(repo_root: Path) -> str | None:\n    try:\n        out = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], cwd=str(repo_root))",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "set_seed",
        "kind": 2,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "def set_seed(seed: int) -> None:\n    random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\ndef git_commit(repo_root: Path) -> str | None:\n    try:\n        out = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], cwd=str(repo_root))\n        return out.decode(\"utf-8\").strip()\n    except Exception:",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "git_commit",
        "kind": 2,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "def git_commit(repo_root: Path) -> str | None:\n    try:\n        out = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], cwd=str(repo_root))\n        return out.decode(\"utf-8\").strip()\n    except Exception:\n        return None\ndef sha256_file(path: Path, chunk: int = 1024 * 1024) -> str:\n    h = hashlib.sha256()\n    with path.open(\"rb\") as f:\n        while True:",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "sha256_file",
        "kind": 2,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "def sha256_file(path: Path, chunk: int = 1024 * 1024) -> str:\n    h = hashlib.sha256()\n    with path.open(\"rb\") as f:\n        while True:\n            b = f.read(chunk)\n            if not b:\n                break\n            h.update(b)\n    return h.hexdigest()\ndef to_json_serializable(value: Any) -> Any:",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "to_json_serializable",
        "kind": 2,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "def to_json_serializable(value: Any) -> Any:\n    if isinstance(value, Path):\n        return str(value)\n    if dataclasses.is_dataclass(value):\n        return to_json_serializable(dataclasses.asdict(value))\n    if isinstance(value, dict):\n        return {str(key): to_json_serializable(val) for key, val in value.items()}\n    if isinstance(value, (list, tuple, set)):\n        return [to_json_serializable(item) for item in value]\n    return value",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "run_command",
        "kind": 2,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "def run_command(\n    command: List[str],\n    cwd: Optional[Path] = None,\n    env: Optional[Dict[str, str]] = None,\n) -> None:\n    printable = \" \".join(command)\n    print(f\"  Running: {printable}\")\n    subprocess.run(\n        command,\n        check=True,",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "build_sft_trainer_kwargs",
        "kind": 2,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "def build_sft_trainer_kwargs(\n    trainer_cls: type, tokenizer: Any, **kwargs: Any\n) -> Dict[str, Any]:\n    signature = inspect.signature(trainer_cls.__init__)\n    params = signature.parameters\n    trainer_kwargs = dict(kwargs)\n    max_seq_length = trainer_kwargs.pop(\"max_seq_length\", None)\n    if max_seq_length is not None:\n        if \"max_seq_length\" in params:\n            trainer_kwargs[\"max_seq_length\"] = max_seq_length",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "main_cli",
        "kind": 2,
        "importPath": "scripts.offllm_end_to_end_pipeline",
        "description": "scripts.offllm_end_to_end_pipeline",
        "peekOfCode": "def main_cli():\n    \"\"\"Command-line interface entry point.\"\"\"\n    parser = argparse.ArgumentParser(description=\"offLLM End-to-End Pipeline\")\n    parser.add_argument(\n        \"--stage\",\n        choices=[\n            \"full_scan\",\n            \"scan\",\n            \"internals\",\n            \"harvest\",",
        "detail": "scripts.offllm_end_to_end_pipeline",
        "documentation": {}
    },
    {
        "label": "FileHit",
        "kind": 6,
        "importPath": "scripts.offllm_symbiosis_advisor_v3",
        "description": "scripts.offllm_symbiosis_advisor_v3",
        "peekOfCode": "class FileHit:\n    path: str\n    ext: str\n    size_bytes: int\n    loc: int\n    keyword_hits: dict[str, int]\n    sha1: str\n@dataclass\nclass Hotspot:\n    topic: str",
        "detail": "scripts.offllm_symbiosis_advisor_v3",
        "documentation": {}
    },
    {
        "label": "Hotspot",
        "kind": 6,
        "importPath": "scripts.offllm_symbiosis_advisor_v3",
        "description": "scripts.offllm_symbiosis_advisor_v3",
        "peekOfCode": "class Hotspot:\n    topic: str\n    reason: str\n    files: list[str]\n@dataclass\nclass PlanSection:\n    title: str\n    bullets: list[str]\n    evidence: list[str]\n# -----------------------------",
        "detail": "scripts.offllm_symbiosis_advisor_v3",
        "documentation": {}
    },
    {
        "label": "PlanSection",
        "kind": 6,
        "importPath": "scripts.offllm_symbiosis_advisor_v3",
        "description": "scripts.offllm_symbiosis_advisor_v3",
        "peekOfCode": "class PlanSection:\n    title: str\n    bullets: list[str]\n    evidence: list[str]\n# -----------------------------\n# Helpers\n# -----------------------------\ndef _sha1_bytes(b: bytes) -> str:\n    import hashlib\n    h = hashlib.sha1()",
        "detail": "scripts.offllm_symbiosis_advisor_v3",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v3",
        "description": "scripts.offllm_symbiosis_advisor_v3",
        "peekOfCode": "def main(argv: list[str] | None = None) -> int:\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"--repo\", required=True, help=\"Path to repo folder or .zip\")\n    ap.add_argument(\"--out-dir\", default=\".\", help=\"Output directory\")\n    ap.add_argument(\n        \"--include-noncode\",\n        action=\"store_true\",\n        help=\"Scan all file extensions (slower, more noise)\",\n    )\n    args = ap.parse_args(argv)",
        "detail": "scripts.offllm_symbiosis_advisor_v3",
        "documentation": {}
    },
    {
        "label": "DEFAULT_EXCLUDES",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v3",
        "description": "scripts.offllm_symbiosis_advisor_v3",
        "peekOfCode": "DEFAULT_EXCLUDES = {\n    \".git\",\n    \".venv\",\n    \"venv\",\n    \"node_modules\",\n    \"Pods\",\n    \"DerivedData\",\n    \"build\",\n    \"dist\",\n    \".next\",",
        "detail": "scripts.offllm_symbiosis_advisor_v3",
        "documentation": {}
    },
    {
        "label": "SEARCH_SEEDS",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v3",
        "description": "scripts.offllm_symbiosis_advisor_v3",
        "peekOfCode": "SEARCH_SEEDS = [\n    \"scripts\",\n    \"src\",\n    \"app\",\n    \"packages\",\n    \"ios\",\n    \"android\",\n    \".github/workflows\",\n    \"configs\",\n    \"config\",",
        "detail": "scripts.offllm_symbiosis_advisor_v3",
        "documentation": {}
    },
    {
        "label": "CODE_EXTS",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v3",
        "description": "scripts.offllm_symbiosis_advisor_v3",
        "peekOfCode": "CODE_EXTS = {\n    \".py\",\n    \".js\",\n    \".ts\",\n    \".tsx\",\n    \".jsx\",\n    \".swift\",\n    \".m\",\n    \".mm\",\n    \".h\",",
        "detail": "scripts.offllm_symbiosis_advisor_v3",
        "documentation": {}
    },
    {
        "label": "MAX_READ_BYTES",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v3",
        "description": "scripts.offllm_symbiosis_advisor_v3",
        "peekOfCode": "MAX_READ_BYTES = 2_500_000  # 2.5MB; big enough for most code, avoids logs.\n# -----------------------------\n# Data model\n# -----------------------------\n@dataclass\nclass FileHit:\n    path: str\n    ext: str\n    size_bytes: int\n    loc: int",
        "detail": "scripts.offllm_symbiosis_advisor_v3",
        "documentation": {}
    },
    {
        "label": "FileSignals",
        "kind": 6,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "class FileSignals:\n    path: str\n    ext: str\n    size: int\n    sha1: str\n    markers: dict[str, int]\n    imports: list[str]\n    exports: list[str]\n    contains_todo: bool\nIMPORT_RE_PY = re.compile(r\"^\\s*(?:from\\s+([a-zA-Z0-9_\\.]+)\\s+import|import\\s+([a-zA-Z0-9_\\.]+))\", re.M)",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "SearchMap",
        "kind": 6,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "class SearchMap:\n    prompts: list[str]\n    tools: list[str]\n    telemetry: list[str]\n    rag: list[str]\n    eval: list[str]\n    ios: list[str]\n    security: list[str]\n@dataclass\nclass RefactorFinding:",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "RefactorFinding",
        "kind": 6,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "class RefactorFinding:\n    title: str\n    severity: str  # low/med/high\n    why: str\n    where: list[str]\n    suggested_actions: list[str]\n@dataclass\nclass FineTuneAxis:\n    axis: str\n    goal: str",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "FineTuneAxis",
        "kind": 6,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "class FineTuneAxis:\n    axis: str\n    goal: str\n    dataset_sources: list[str]\n    evals: list[str]\n    notes: str\n@dataclass\nclass SymbiosisPlan:\n    generated_at: str\n    repo_root: str",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "SymbiosisPlan",
        "kind": 6,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "class SymbiosisPlan:\n    generated_at: str\n    repo_root: str\n    repo_fingerprint: str\n    totals: dict[str, Any]\n    search_map: SearchMap\n    refactor_findings: list[RefactorFinding]\n    finetune_axes: list[FineTuneAxis]\ndef fingerprint_repo(repo_root: Path, file_sigs: list[FileSignals]) -> str:\n    # deterministic fingerprint from sorted (path, sha1)",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "sha1_bytes",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def sha1_bytes(b: bytes) -> str:\n    h = hashlib.sha1()\n    h.update(b)\n    return h.hexdigest()\ndef safe_read_text(path: Path, limit_bytes: int = DEFAULT_LIMIT_BYTES) -> str:\n    try:\n        data = path.read_bytes()\n    except Exception:\n        return \"\"\n    if len(data) > limit_bytes:",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "safe_read_text",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def safe_read_text(path: Path, limit_bytes: int = DEFAULT_LIMIT_BYTES) -> str:\n    try:\n        data = path.read_bytes()\n    except Exception:\n        return \"\"\n    if len(data) > limit_bytes:\n        data = data[:limit_bytes]\n    try:\n        return data.decode(\"utf-8\", errors=\"replace\")\n    except Exception:",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "rel",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def rel(repo_root: Path, p: Path) -> str:\n    try:\n        return str(p.relative_to(repo_root))\n    except Exception:\n        return str(p)\ndef is_probably_binary(path: Path) -> bool:\n    ext = path.suffix.lower()\n    if ext in BINARY_EXTS:\n        return True\n    return False",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "is_probably_binary",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def is_probably_binary(path: Path) -> bool:\n    ext = path.suffix.lower()\n    if ext in BINARY_EXTS:\n        return True\n    return False\ndef walk_repo(repo_root: Path, max_files: int) -> list[Path]:\n    out: list[Path] = []\n    for root, dirs, files in os.walk(repo_root):\n        # prune\n        dirs[:] = [d for d in dirs if d not in SKIP_DIR_NAMES]",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "walk_repo",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def walk_repo(repo_root: Path, max_files: int) -> list[Path]:\n    out: list[Path] = []\n    for root, dirs, files in os.walk(repo_root):\n        # prune\n        dirs[:] = [d for d in dirs if d not in SKIP_DIR_NAMES]\n        for fn in files:\n            p = Path(root) / fn\n            if len(out) >= max_files:\n                return out\n            out.append(p)",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "count_markers",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def count_markers(text: str, markers: list[str]) -> int:\n    low = text.lower()\n    n = 0\n    for m in markers:\n        n += low.count(m.lower())\n    return n\ndef extract_imports_exports(path: Path, text: str) -> tuple[list[str], list[str]]:\n    ext = path.suffix.lower()\n    imports: list[str] = []\n    exports: list[str] = []",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "extract_imports_exports",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def extract_imports_exports(path: Path, text: str) -> tuple[list[str], list[str]]:\n    ext = path.suffix.lower()\n    imports: list[str] = []\n    exports: list[str] = []\n    if ext == \".py\":\n        for a, b in IMPORT_RE_PY.findall(text):\n            mod = a or b\n            if mod:\n                imports.append(mod)\n    elif ext in {\".js\", \".ts\", \".tsx\", \".jsx\"}:",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "signals_for_file",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def signals_for_file(repo_root: Path, p: Path, limit_bytes: int) -> Optional[FileSignals]:\n    try:\n        st = p.stat()\n    except Exception:\n        return None\n    if p.is_dir():\n        return None\n    if is_probably_binary(p):\n        return None\n    ext = p.suffix.lower()",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "fingerprint_repo",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def fingerprint_repo(repo_root: Path, file_sigs: list[FileSignals]) -> str:\n    # deterministic fingerprint from sorted (path, sha1)\n    h = hashlib.sha1()\n    for fs in sorted(file_sigs, key=lambda x: x.path):\n        h.update(fs.path.encode(\"utf-8\"))\n        h.update(fs.sha1.encode(\"utf-8\"))\n    return h.hexdigest()\ndef top_paths(file_sigs: list[FileSignals], key: str, k: int = 20) -> list[str]:\n    scored = [(fs.markers.get(key, 0), fs.path) for fs in file_sigs if fs.markers.get(key, 0) > 0]\n    scored.sort(reverse=True)",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "top_paths",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def top_paths(file_sigs: list[FileSignals], key: str, k: int = 20) -> list[str]:\n    scored = [(fs.markers.get(key, 0), fs.path) for fs in file_sigs if fs.markers.get(key, 0) > 0]\n    scored.sort(reverse=True)\n    return [p for _, p in scored[:k]]\ndef build_search_map(file_sigs: list[FileSignals]) -> SearchMap:\n    return SearchMap(\n        prompts=top_paths(file_sigs, \"prompts\", 35),\n        tools=top_paths(file_sigs, \"tools\", 35),\n        telemetry=top_paths(file_sigs, \"telemetry\", 35),\n        rag=top_paths(file_sigs, \"rag\", 35),",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "build_search_map",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def build_search_map(file_sigs: list[FileSignals]) -> SearchMap:\n    return SearchMap(\n        prompts=top_paths(file_sigs, \"prompts\", 35),\n        tools=top_paths(file_sigs, \"tools\", 35),\n        telemetry=top_paths(file_sigs, \"telemetry\", 35),\n        rag=top_paths(file_sigs, \"rag\", 35),\n        eval=top_paths(file_sigs, \"eval\", 35),\n        ios=top_paths(file_sigs, \"ios\", 35),\n        security=top_paths(file_sigs, \"security\", 35),\n    )",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "find_dup_candidates",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def find_dup_candidates(file_sigs: list[FileSignals], key: str, min_hits: int = 3) -> dict[str, list[str]]:\n    # quick-and-dirty \"duplication smell\": many files with the same marker set > threshold\n    buckets: dict[str, list[str]] = {}\n    for fs in file_sigs:\n        if fs.markers.get(key, 0) >= min_hits:\n            bucket_key = f\"{key}:{min_hits}\"\n            buckets.setdefault(bucket_key, []).append(fs.path)\n    return buckets\ndef build_refactor_findings(repo_root: Path, file_sigs: list[FileSignals], search: SearchMap) -> list[RefactorFinding]:\n    findings: list[RefactorFinding] = []",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "build_refactor_findings",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def build_refactor_findings(repo_root: Path, file_sigs: list[FileSignals], search: SearchMap) -> list[RefactorFinding]:\n    findings: list[RefactorFinding] = []\n    # 1) Prompt & tool surfaces: encourage single schema & versioned templates\n    if len(search.prompts) > 0:\n        findings.append(RefactorFinding(\n            title=\"Unify prompt surfaces into versioned templates\",\n            severity=\"high\",\n            why=(\n                \"Multiple prompt definitions scattered across the repo tend to drift. \"\n                \"Drift breaks fine-tuning, evaluation, and runtime behaviour alignment.\"",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "build_finetune_axes",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def build_finetune_axes(search: SearchMap) -> list[FineTuneAxis]:\n    # This is deterministic but still \"policy\"it suggests a rational alignment.\n    axes: list[FineTuneAxis] = []\n    axes.append(FineTuneAxis(\n        axis=\"Tool calling & JSON robustness\",\n        goal=\"Valid tool JSON, correct tool selection, safe refusal when schema cannot be satisfied.\",\n        dataset_sources=(\n            [\"telemetry: tool_calls + outcomes\"] +\n            ([\"code: tool schemas + handlers\"] if search.tools else [])\n        ),",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "write_markdown",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def write_markdown(plan: SymbiosisPlan, out_md: Path) -> None:\n    sm = plan.search_map\n    lines: list[str] = []\n    lines.append(\"# offLLM Symbiosis Report\\n\")\n    lines.append(f\"- Generated: **{plan.generated_at}**\")\n    lines.append(f\"- Repo root: `{plan.repo_root}`\")\n    lines.append(f\"- Repo fingerprint: `{plan.repo_fingerprint}`\")\n    lines.append(\"\")\n    lines.append(\"## Totals\")\n    for k, v in plan.totals.items():",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "def main() -> int:\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"--repo-root\", required=True, help=\"Path to repo root\")\n    ap.add_argument(\"--out-dir\", required=True, help=\"Output directory\")\n    ap.add_argument(\"--max-files\", type=int, default=20000)\n    ap.add_argument(\"--limit-bytes\", type=int, default=DEFAULT_LIMIT_BYTES)\n    args = ap.parse_args()\n    repo_root = Path(args.repo_root).resolve()\n    out_dir = Path(args.out_dir).resolve()\n    out_dir.mkdir(parents=True, exist_ok=True)",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "TEXT_EXTS",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "TEXT_EXTS = {\n    \".py\", \".js\", \".ts\", \".tsx\", \".jsx\", \".md\", \".json\", \".yml\", \".yaml\", \".toml\",\n    \".swift\", \".m\", \".mm\", \".h\", \".hpp\", \".cc\", \".cpp\", \".c\", \".rs\", \".java\",\n    \".gradle\", \".kt\", \".kts\", \".sh\", \".rb\", \".txt\",\n}\nBINARY_EXTS = {\n    \".png\", \".jpg\", \".jpeg\", \".gif\", \".webp\", \".mp4\", \".mov\", \".zip\", \".a\", \".o\",\n    \".so\", \".dylib\", \".framework\", \".xcarchive\", \".ipa\", \".jar\", \".aar\",\n    \".pdf\", \".ttf\", \".otf\", \".woff\", \".woff2\",\n}",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "BINARY_EXTS",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "BINARY_EXTS = {\n    \".png\", \".jpg\", \".jpeg\", \".gif\", \".webp\", \".mp4\", \".mov\", \".zip\", \".a\", \".o\",\n    \".so\", \".dylib\", \".framework\", \".xcarchive\", \".ipa\", \".jar\", \".aar\",\n    \".pdf\", \".ttf\", \".otf\", \".woff\", \".woff2\",\n}\nSKIP_DIR_NAMES = {\n    \".git\", \".hg\", \".svn\", \"__pycache__\", \".venv\", \"venv\", \"node_modules\", \"Pods\",\n    \"build\", \"dist\", \".gradle\", \".idea\", \".vscode\", \".DS_Store\",\n}\nDEFAULT_LIMIT_BYTES = 1_500_000  # avoid slurping giant files",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "SKIP_DIR_NAMES",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "SKIP_DIR_NAMES = {\n    \".git\", \".hg\", \".svn\", \"__pycache__\", \".venv\", \"venv\", \"node_modules\", \"Pods\",\n    \"build\", \"dist\", \".gradle\", \".idea\", \".vscode\", \".DS_Store\",\n}\nDEFAULT_LIMIT_BYTES = 1_500_000  # avoid slurping giant files\ndef sha1_bytes(b: bytes) -> str:\n    h = hashlib.sha1()\n    h.update(b)\n    return h.hexdigest()\ndef safe_read_text(path: Path, limit_bytes: int = DEFAULT_LIMIT_BYTES) -> str:",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "DEFAULT_LIMIT_BYTES",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "DEFAULT_LIMIT_BYTES = 1_500_000  # avoid slurping giant files\ndef sha1_bytes(b: bytes) -> str:\n    h = hashlib.sha1()\n    h.update(b)\n    return h.hexdigest()\ndef safe_read_text(path: Path, limit_bytes: int = DEFAULT_LIMIT_BYTES) -> str:\n    try:\n        data = path.read_bytes()\n    except Exception:\n        return \"\"",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "PROMPT_MARKERS",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "PROMPT_MARKERS = [\n    \"SYSTEM_PROMPT\", \"system prompt\", \"You are\", \"### Instruction\", \"### Response\",\n    \"prompt_template\", \"PROMPT_TEMPLATE\", \"few-shot\", \"chain-of-thought\",\n    \"tool_calls\", \"function_call\", \"ReAct\", \"scratchpad\", \"tool parser\",\n]\nTOOL_MARKERS = [\n    \"tool\", \"tools\", \"tool_call\", \"call_tool\", \"ToolHandler\", \"ToolParser\",\n    \"function_call\", \"schema\", \"jsonschema\",\n]\nTELEMETRY_MARKERS = [",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "TOOL_MARKERS",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "TOOL_MARKERS = [\n    \"tool\", \"tools\", \"tool_call\", \"call_tool\", \"ToolHandler\", \"ToolParser\",\n    \"function_call\", \"schema\", \"jsonschema\",\n]\nTELEMETRY_MARKERS = [\n    \"telemetry\", \"trace\", \"span\", \"opentelemetry\", \"metrics\", \"prometheus\",\n    \"statsd\", \"sentry\", \"event_name\", \"eventType\", \"log_event\", \"structured log\",\n]\nRAG_MARKERS = [\n    \"embedding\", \"vector\", \"hnsw\", \"faiss\", \"pgvector\", \"retrieval\", \"rerank\",",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "TELEMETRY_MARKERS",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "TELEMETRY_MARKERS = [\n    \"telemetry\", \"trace\", \"span\", \"opentelemetry\", \"metrics\", \"prometheus\",\n    \"statsd\", \"sentry\", \"event_name\", \"eventType\", \"log_event\", \"structured log\",\n]\nRAG_MARKERS = [\n    \"embedding\", \"vector\", \"hnsw\", \"faiss\", \"pgvector\", \"retrieval\", \"rerank\",\n    \"reranker\", \"chunk\", \"chunking\", \"similarity\", \"cosine\",\n]\nEVAL_MARKERS = [\n    \"eval\", \"evaluation\", \"benchmark\", \"golden\", \"regression\", \"score\",",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "RAG_MARKERS",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "RAG_MARKERS = [\n    \"embedding\", \"vector\", \"hnsw\", \"faiss\", \"pgvector\", \"retrieval\", \"rerank\",\n    \"reranker\", \"chunk\", \"chunking\", \"similarity\", \"cosine\",\n]\nEVAL_MARKERS = [\n    \"eval\", \"evaluation\", \"benchmark\", \"golden\", \"regression\", \"score\",\n    \"accuracy\", \"mmlu\", \"truthful\", \"bleu\", \"rouge\", \"pass@\", \"unit test\",\n]\nIOS_MARKERS = [\n    \"CoreML\", \"coreml\", \"mlmodel\", \"MLModel\", \"mlx\", \"Metal\", \"ANE\",",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "EVAL_MARKERS",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "EVAL_MARKERS = [\n    \"eval\", \"evaluation\", \"benchmark\", \"golden\", \"regression\", \"score\",\n    \"accuracy\", \"mmlu\", \"truthful\", \"bleu\", \"rouge\", \"pass@\", \"unit test\",\n]\nIOS_MARKERS = [\n    \"CoreML\", \"coreml\", \"mlmodel\", \"MLModel\", \"mlx\", \"Metal\", \"ANE\",\n    \"Xcode\", \"xcworkspace\", \"xcodebuild\",\n]\nSECURITY_MARKERS = [\n    \"sanitize\", \"redact\", \"secret\", \"token\", \"apikey\", \"api_key\", \"PII\",",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "IOS_MARKERS",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "IOS_MARKERS = [\n    \"CoreML\", \"coreml\", \"mlmodel\", \"MLModel\", \"mlx\", \"Metal\", \"ANE\",\n    \"Xcode\", \"xcworkspace\", \"xcodebuild\",\n]\nSECURITY_MARKERS = [\n    \"sanitize\", \"redact\", \"secret\", \"token\", \"apikey\", \"api_key\", \"PII\",\n    \"prompt injection\", \"injection\", \"ssrf\", \"rce\", \"sandbox\", \"allowlist\",\n]\n@dataclass(frozen=True)\nclass FileSignals:",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "SECURITY_MARKERS",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "SECURITY_MARKERS = [\n    \"sanitize\", \"redact\", \"secret\", \"token\", \"apikey\", \"api_key\", \"PII\",\n    \"prompt injection\", \"injection\", \"ssrf\", \"rce\", \"sandbox\", \"allowlist\",\n]\n@dataclass(frozen=True)\nclass FileSignals:\n    path: str\n    ext: str\n    size: int\n    sha1: str",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "IMPORT_RE_PY",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "IMPORT_RE_PY = re.compile(r\"^\\s*(?:from\\s+([a-zA-Z0-9_\\.]+)\\s+import|import\\s+([a-zA-Z0-9_\\.]+))\", re.M)\nIMPORT_RE_JS = re.compile(r\"^\\s*import\\s+.*?\\s+from\\s+['\\\"]([^'\\\"]+)['\\\"]\\s*;?\", re.M)\nREQUIRE_RE_JS = re.compile(r\"require\\(\\s*['\\\"]([^'\\\"]+)['\\\"]\\s*\\)\")\nEXPORT_RE_JS = re.compile(r\"^\\s*export\\s+(?:default\\s+)?\", re.M)\ndef count_markers(text: str, markers: list[str]) -> int:\n    low = text.lower()\n    n = 0\n    for m in markers:\n        n += low.count(m.lower())\n    return n",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "IMPORT_RE_JS",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "IMPORT_RE_JS = re.compile(r\"^\\s*import\\s+.*?\\s+from\\s+['\\\"]([^'\\\"]+)['\\\"]\\s*;?\", re.M)\nREQUIRE_RE_JS = re.compile(r\"require\\(\\s*['\\\"]([^'\\\"]+)['\\\"]\\s*\\)\")\nEXPORT_RE_JS = re.compile(r\"^\\s*export\\s+(?:default\\s+)?\", re.M)\ndef count_markers(text: str, markers: list[str]) -> int:\n    low = text.lower()\n    n = 0\n    for m in markers:\n        n += low.count(m.lower())\n    return n\ndef extract_imports_exports(path: Path, text: str) -> tuple[list[str], list[str]]:",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "REQUIRE_RE_JS",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "REQUIRE_RE_JS = re.compile(r\"require\\(\\s*['\\\"]([^'\\\"]+)['\\\"]\\s*\\)\")\nEXPORT_RE_JS = re.compile(r\"^\\s*export\\s+(?:default\\s+)?\", re.M)\ndef count_markers(text: str, markers: list[str]) -> int:\n    low = text.lower()\n    n = 0\n    for m in markers:\n        n += low.count(m.lower())\n    return n\ndef extract_imports_exports(path: Path, text: str) -> tuple[list[str], list[str]]:\n    ext = path.suffix.lower()",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "EXPORT_RE_JS",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v4",
        "description": "scripts.offllm_symbiosis_advisor_v4",
        "peekOfCode": "EXPORT_RE_JS = re.compile(r\"^\\s*export\\s+(?:default\\s+)?\", re.M)\ndef count_markers(text: str, markers: list[str]) -> int:\n    low = text.lower()\n    n = 0\n    for m in markers:\n        n += low.count(m.lower())\n    return n\ndef extract_imports_exports(path: Path, text: str) -> tuple[list[str], list[str]]:\n    ext = path.suffix.lower()\n    imports: list[str] = []",
        "detail": "scripts.offllm_symbiosis_advisor_v4",
        "documentation": {}
    },
    {
        "label": "PromptSnippet",
        "kind": 6,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "class PromptSnippet:\n    file: str\n    start_line: int\n    end_line: int\n    kind: str\n    preview: str\n    sha256: str\n@dataclass(frozen=True)\nclass FileSignals:\n    file: str",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "FileSignals",
        "kind": 6,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "class FileSignals:\n    file: str\n    size: int\n    prompt_score: int\n    tool_score: int\n    telemetry_score: int\n    rag_score: int\n    eval_score: int\n    ios_score: int\n    todos: int",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "DriftCluster",
        "kind": 6,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "class DriftCluster:\n    signature: str\n    count: int\n    files: List[str]\n    sample_previews: List[str]\ndef eprint(*a: Any) -> None:\n    print(*a, file=sys.stderr)\ndef mkdirp(p: Path) -> None:\n    p.mkdir(parents=True, exist_ok=True)\ndef is_probably_text(b: bytes) -> bool:",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "eprint",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def eprint(*a: Any) -> None:\n    print(*a, file=sys.stderr)\ndef mkdirp(p: Path) -> None:\n    p.mkdir(parents=True, exist_ok=True)\ndef is_probably_text(b: bytes) -> bool:\n    if b\"\\x00\" in b:\n        return False\n    if not b:\n        return True\n    sample = b[:4096]",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "mkdirp",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def mkdirp(p: Path) -> None:\n    p.mkdir(parents=True, exist_ok=True)\ndef is_probably_text(b: bytes) -> bool:\n    if b\"\\x00\" in b:\n        return False\n    if not b:\n        return True\n    sample = b[:4096]\n    bad = 0\n    for ch in sample:",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "is_probably_text",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def is_probably_text(b: bytes) -> bool:\n    if b\"\\x00\" in b:\n        return False\n    if not b:\n        return True\n    sample = b[:4096]\n    bad = 0\n    for ch in sample:\n        if ch in (9, 10, 13):\n            continue",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "safe_relpath",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def safe_relpath(p: Path, root: Path) -> Optional[str]:\n    try:\n        rp = p.resolve()\n        rr = root.resolve()\n        rel = rp.relative_to(rr)\n        if \"..\" in rel.parts:\n            return None\n        return rel.as_posix()\n    except Exception:\n        return None",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "read_text_limited",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def read_text_limited(path: Path, max_bytes: int) -> Optional[str]:\n    try:\n        st = path.stat()\n        if st.st_size > max_bytes:\n            with path.open(\"rb\") as f:\n                b = f.read(min(max_bytes, 262144))\n            if not is_probably_text(b):\n                return None\n            return b.decode(\"utf-8\", errors=\"replace\")\n        with path.open(\"rb\") as f:",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "compile_patterns",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def compile_patterns(pats: Sequence[str]) -> List[re.Pattern[str]]:\n    out: List[re.Pattern[str]] = []\n    for s in pats:\n        try:\n            out.append(re.compile(s, re.IGNORECASE | re.MULTILINE))\n        except re.error:\n            continue\n    return out\ndef score_text(text: str, patterns: List[re.Pattern[str]]) -> int:\n    if not text:",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "score_text",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def score_text(text: str, patterns: List[re.Pattern[str]]) -> int:\n    if not text:\n        return 0\n    score = 0\n    for rx in patterns:\n        score += len(rx.findall(text))\n    return score\ndef count_todos_fixmes(text: str) -> Tuple[int, int]:\n    if not text:\n        return (0, 0)",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "count_todos_fixmes",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def count_todos_fixmes(text: str) -> Tuple[int, int]:\n    if not text:\n        return (0, 0)\n    todos = len(re.findall(r\"\\bTODO\\b\", text))\n    fixmes = len(re.findall(r\"\\bFIXME\\b\", text))\n    return (todos, fixmes)\ndef infer_lang(p: Path) -> str:\n    ext = p.suffix.lower()\n    if ext == \".py\":\n        return \"python\"",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "infer_lang",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def infer_lang(p: Path) -> str:\n    ext = p.suffix.lower()\n    if ext == \".py\":\n        return \"python\"\n    if ext in (\".js\", \".jsx\"):\n        return \"javascript\"\n    if ext in (\".ts\", \".tsx\"):\n        return \"typescript\"\n    if ext in (\".m\", \".mm\"):\n        return \"objc\"",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "load_user_config",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def load_user_config(repo_root: Path, explicit: Optional[Path]) -> Dict[str, Any]:\n    candidates: List[Path] = []\n    if explicit:\n        candidates.append(explicit)\n    else:\n        candidates.extend([\n            repo_root / \".symbiosis.json\",\n            repo_root / \".symbiosis.yaml\",\n            repo_root / \".symbiosis.yml\",\n        ])",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "cfg_list",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def cfg_list(cfg: Dict[str, Any], key: str, default: List[str]) -> List[str]:\n    v = cfg.get(key, default)\n    if isinstance(v, list):\n        return [str(x) for x in v]\n    if isinstance(v, str):\n        return [v]\n    return default\ndef cfg_bool(cfg: Dict[str, Any], key: str, default: bool) -> bool:\n    v = cfg.get(key, default)\n    if isinstance(v, bool):",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "cfg_bool",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def cfg_bool(cfg: Dict[str, Any], key: str, default: bool) -> bool:\n    v = cfg.get(key, default)\n    if isinstance(v, bool):\n        return v\n    if isinstance(v, str):\n        return v.lower() in (\"1\", \"true\", \"yes\", \"y\", \"on\")\n    return default\ndef cfg_int(cfg: Dict[str, Any], key: str, default: int) -> int:\n    v = cfg.get(key, default)\n    try:",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "cfg_int",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def cfg_int(cfg: Dict[str, Any], key: str, default: int) -> int:\n    v = cfg.get(key, default)\n    try:\n        return int(v)\n    except Exception:\n        return default\ndef merge_ignore_globs(defaults: List[str], overrides: List[str]) -> List[str]:\n    out = []\n    seen = set()\n    for item in defaults + overrides:",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "merge_ignore_globs",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def merge_ignore_globs(defaults: List[str], overrides: List[str]) -> List[str]:\n    out = []\n    seen = set()\n    for item in defaults + overrides:\n        item = str(item)\n        if item in seen:\n            continue\n        seen.add(item)\n        out.append(item)\n    return out",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "git_head_and_dirty",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def git_head_and_dirty(repo_root: Path) -> Optional[str]:\n    head = _run_git(repo_root, [\"rev-parse\", \"HEAD\"])\n    if not head:\n        return None\n    dirty = _run_git(repo_root, [\"status\", \"--porcelain\"])\n    dirty_flag = \"dirty\" if (dirty and dirty.strip()) else \"clean\"\n    return f\"{head}:{dirty_flag}\"\ndef git_churn(repo_root: Path, relpath: str, max_commits: int = 2000) -> int:\n    out = _run_git(repo_root, [\"log\", f\"-n{max_commits}\", \"--oneline\", \"--\", relpath])\n    if not out:",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "git_churn",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def git_churn(repo_root: Path, relpath: str, max_commits: int = 2000) -> int:\n    out = _run_git(repo_root, [\"log\", f\"-n{max_commits}\", \"--oneline\", \"--\", relpath])\n    if not out:\n        return 0\n    return len([ln for ln in out.splitlines() if ln.strip()])\ndef file_content_hash(p: Path, max_bytes: int) -> Optional[str]:\n    txt = read_text_limited(p, max_bytes=max_bytes)\n    if txt is None:\n        return None\n    h = hashlib.sha256()",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "file_content_hash",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def file_content_hash(p: Path, max_bytes: int) -> Optional[str]:\n    txt = read_text_limited(p, max_bytes=max_bytes)\n    if txt is None:\n        return None\n    h = hashlib.sha256()\n    h.update(txt.encode(\"utf-8\", errors=\"ignore\"))\n    return h.hexdigest()\ndef repo_fingerprint(repo_root: Path, files: Sequence[Path], max_bytes: int, use_git: bool) -> str:\n    if use_git:\n        g = git_head_and_dirty(repo_root)",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "repo_fingerprint",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def repo_fingerprint(repo_root: Path, files: Sequence[Path], max_bytes: int, use_git: bool) -> str:\n    if use_git:\n        g = git_head_and_dirty(repo_root)\n        if g:\n            return \"git:\" + hashlib.sha1(g.encode(\"utf-8\", errors=\"ignore\")).hexdigest()\n    h = hashlib.sha1()\n    for p in sorted(files, key=lambda x: x.as_posix()):\n        rel = safe_relpath(p, repo_root)\n        if not rel:\n            continue",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "extract_prompt_snippets",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def extract_prompt_snippets(rel: str, text: str, max_preview_chars: int = 240) -> List[PromptSnippet]:\n    snippets: List[PromptSnippet] = []\n    lines = text.splitlines()\n    n = len(lines)\n    # JSON chat extraction\n    if RE_JSON_CHAT_ROLE.search(text):\n        try:\n            obj = json.loads(text)\n            def walk(x: Any) -> Iterator[Tuple[str, str]]:\n                if isinstance(x, dict):",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "analyze_one_file",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def analyze_one_file(\n    p: Path,\n    repo_root: Path,\n    max_bytes: int,\n    patterns: Dict[str, List[re.Pattern[str]]],\n    include_git_churn: bool,\n) -> Tuple[Optional[FileSignals], List[PromptSnippet]]:\n    rel = safe_relpath(p, repo_root)\n    if not rel:\n        return (None, [])",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "should_index_path",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def should_index_path(rel: str, exclude_dirs: set[str], ignore_globs: List[str]) -> bool:\n    parts = rel.split(\"/\")\n    if any(part in exclude_dirs for part in parts):\n        return False\n    for g in ignore_globs:\n        if fnmatch.fnmatch(rel, g) or fnmatch.fnmatch(\"/\" + rel, g):\n            return False\n    return True\ndef iter_candidate_files(\n    repo_root: Path,",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "iter_candidate_files",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def iter_candidate_files(\n    repo_root: Path,\n    exclude_dirs: set[str],\n    ignore_globs: List[str],\n    include_generated: bool,\n) -> Tuple[List[Path], Dict[str, int]]:\n    out: List[Path] = []\n    stats = {\n        \"files_seen\": 0,\n        \"files_included\": 0,",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "token_signature",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def token_signature(snippet: str, max_tokens: int = 64) -> str:\n    toks = re.findall(r\"[A-Za-z_][A-Za-z0-9_]+\", snippet.lower())\n    if not toks:\n        return \"empty\"\n    c = Counter(toks)\n    top = [t for t, _ in c.most_common(max_tokens)]\n    h = hashlib.sha256()\n    h.update((\" \".join(top)).encode(\"utf-8\", errors=\"ignore\"))\n    return h.hexdigest()[:16]\ndef cluster_prompts(snippets: List[PromptSnippet]) -> List[DriftCluster]:",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "cluster_prompts",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def cluster_prompts(snippets: List[PromptSnippet]) -> List[DriftCluster]:\n    by_sig: Dict[str, List[PromptSnippet]] = defaultdict(list)\n    for s in snippets:\n        by_sig[token_signature(s.preview)].append(s)\n    clusters: List[DriftCluster] = []\n    for sig, items in by_sig.items():\n        files = sorted({it.file for it in items})\n        previews = [f\"{it.kind}@{it.start_line}-{it.end_line}: {it.preview}\" for it in items[:3]]\n        clusters.append(DriftCluster(sig, len(items), files, previews))\n    clusters.sort(key=lambda c: (-c.count, len(c.files), c.signature))",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "top_files_by",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def top_files_by(signals: List[FileSignals], key: str, n: int = 25) -> List[str]:\n    idx = {\n        \"prompt\": lambda s: s.prompt_score,\n        \"tool\": lambda s: s.tool_score,\n        \"telemetry\": lambda s: s.telemetry_score,\n        \"rag\": lambda s: s.rag_score,\n        \"eval\": lambda s: s.eval_score,\n        \"ios\": lambda s: s.ios_score,\n        \"todos\": lambda s: s.todos + s.fixmes,\n        \"churn\": lambda s: s.git_churn,",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "build_actions",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def build_actions(report: Dict[str, Any]) -> List[Dict[str, Any]]:\n    actions: List[Dict[str, Any]] = []\n    totals = report.get(\"totals\", {})\n    if totals.get(\"prompt_signal_files\", 0) >= 10:\n        actions.append({\n            \"priority\": \"high\",\n            \"title\": \"Unify prompt surfaces into versioned templates\",\n            \"why\": \"Prompt drift breaks alignment between runtime, fine-tuning, and eval.\",\n            \"next_steps\": [\n                \"Create prompts/v1/*.json and a registry.json (id+version).\",",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "export_sarif",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def export_sarif(report: Dict[str, Any], out_path: Path) -> None:\n    tool = {\"driver\": {\"name\": \"offLLM Symbiosis Advisor\", \"rules\": [\n        {\"id\": \"prompt-drift\", \"name\": \"Prompt drift surface\"},\n        {\"id\": \"hotspot\", \"name\": \"High-signal hotspot\"},\n    ]}}\n    results: List[Dict[str, Any]] = []\n    for c in report.get(\"prompt_drift_clusters\", [])[:25]:\n        for f in c.get(\"files\", [])[:10]:\n            results.append({\n                \"ruleId\": \"prompt-drift\",",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "compare_with_baseline",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def compare_with_baseline(current: Dict[str, Any], baseline_path: Path) -> Dict[str, Any]:\n    if not baseline_path.exists():\n        return {\"baseline_found\": False, \"summary\": \"No baseline file found.\", \"diff\": {}}\n    try:\n        baseline = json.loads(baseline_path.read_text(encoding=\"utf-8\", errors=\"replace\"))\n    except Exception as ex:\n        return {\"baseline_found\": True, \"summary\": f\"Failed to read baseline: {ex}\", \"diff\": {}}\n    cur_tot = current.get(\"totals\", {})\n    base_tot = baseline.get(\"totals\", {})\n    keys = sorted(set(cur_tot.keys()) | set(base_tot.keys()))",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "render_markdown",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def render_markdown(report: Dict[str, Any]) -> str:\n    lines: List[str] = []\n    lines.append(\"# offLLM Symbiosis Deep Report (v6)\\n\")\n    lines.append(f\"- Generated: **{report.get('generated_at','')}**\")\n    lines.append(f\"- Repo root: `{report.get('repo_root','')}`\")\n    lines.append(f\"- Repo fingerprint: `{report.get('repo_fingerprint','')}`\")\n    if report.get(\"config_path\"):\n        lines.append(f\"- Config: `{report.get('config_path')}`\")\n    if report.get(\"baseline\", {}).get(\"baseline_found\"):\n        lines.append(f\"- Baseline: `{report.get('baseline', {}).get('path','')}`\")",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "analyze_repo",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def analyze_repo(args: argparse.Namespace) -> Dict[str, Any]:\n    repo_root = Path(args.repo_root).resolve()\n    out_dir = Path(args.out_dir).resolve()\n    mkdirp(out_dir)\n    cfg = load_user_config(repo_root, Path(args.config).resolve() if args.config else None)\n    exclude_dirs = set(cfg_list(cfg, \"exclude_dirs\", sorted(DEFAULT_EXCLUDE_DIRS)))\n    ignore_globs = merge_ignore_globs(\n        DEFAULT_IGNORE_GLOBS,\n        cfg_list(cfg, \"ignore_globs\", []),\n    )",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "build_arg_parser",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def build_arg_parser() -> argparse.ArgumentParser:\n    p = argparse.ArgumentParser(description=\"offLLM Symbiosis Advisor v6 (stdlib-only)\")\n    p.add_argument(\"--repo-root\", default=\".\", help=\"Repository root\")\n    p.add_argument(\"--repo\", dest=\"repo_root\", help=\"Repository root (alias)\")\n    p.add_argument(\"--out-dir\", default=\"reports/symbiosis_v6\", help=\"Output directory\")\n    p.add_argument(\"--include-generated\", action=\"store_true\", help=\"Include typically generated dirs (runs, cache, etc.)\")\n    p.add_argument(\"--max-file-size\", type=int, default=2_000_000, help=\"Max bytes to read per file\")\n    p.add_argument(\"--workers\", type=int, default=0, help=\"Thread workers (0 => auto)\")\n    p.add_argument(\"--config\", default=\"\", help=\"Explicit config path (.symbiosis.json/.yaml)\")\n    p.add_argument(\"--git\", action=\"store_true\", help=\"Prefer git-based fingerprinting if available\")",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "def main() -> int:\n    args = build_arg_parser().parse_args()\n    report = analyze_repo(args)\n    print(json.dumps({\n        \"ok\": True,\n        \"version\": report.get(\"version\"),\n        \"generated_at\": report.get(\"generated_at\"),\n        \"repo_fingerprint\": report.get(\"repo_fingerprint\"),\n        \"out_dir\": Path(args.out_dir).resolve().as_posix(),\n    }, indent=2))",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "DEFAULT_EXCLUDE_DIRS",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "DEFAULT_EXCLUDE_DIRS = {\n    \".git\", \".hg\", \".svn\",\n    \"node_modules\", \"dist\", \"build\", \".next\", \".turbo\", \".cache\",\n    \".venv\", \"venv\", \"__pycache__\",\n    \"Pods\", \"DerivedData\",\n    \"runs\",\n    \"reports\",\n    \"unsloth_compiled_cache\",\n}\nDEFAULT_IGNORE_GLOBS = [",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "DEFAULT_IGNORE_GLOBS",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "DEFAULT_IGNORE_GLOBS = [\n    \"reports/**\",\n    \"runs/**\",\n    \"node_modules/**\",\n    \".git/**\",\n    \"dist/**\",\n    \"build/**\",\n    \"**/*.sarif\",\n    \"**/*prompt-regression*.json\",\n    \"**/*prompt-regression*\",",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "TEXT_EXT_ALLOW",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "TEXT_EXT_ALLOW = {\n    \".py\", \".js\", \".ts\", \".tsx\", \".jsx\", \".m\", \".mm\", \".swift\", \".java\", \".kt\",\n    \".c\", \".cc\", \".cpp\", \".h\", \".hpp\",\n    \".md\", \".txt\", \".rst\",\n    \".json\", \".yml\", \".yaml\",\n    \".toml\", \".ini\", \".cfg\", \".env\", \".properties\",\n    \".sh\", \".bash\", \".zsh\",\n    \".gradle\",\n    \".rb\", \".go\",\n    \".hbs\", \".mustache\",",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "ALWAYS_TEXT_NAMES",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "ALWAYS_TEXT_NAMES = {\n    \"package.json\", \"package-lock.json\", \"yarn.lock\", \"pnpm-lock.yaml\",\n    \"Podfile\", \"Gemfile\", \"Gemfile.lock\",\n    \"AGENTS.md\", \"README.md\", \"LICENSE\",\n}\nDEFAULT_PATTERN_STRINGS: Dict[str, List[str]] = {\n    \"prompt_markers\": [\n        r\"\\bsystem\\s+prompt\\b\",\n        r\"\\bdeveloper\\s+message\\b\",\n        r\"\\bprompt_template\\b\",",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "RE_JSON_CHAT_ROLE",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "RE_JSON_CHAT_ROLE = re.compile(r'\"role\"\\s*:\\s*\"(system|developer)\"', re.IGNORECASE)\nRE_HEREDOC_START = re.compile(r\"<<-?\\s*([\\\"']?)([A-Za-z0-9_]+)\\1\")\nRE_TRIPLE_QUOTE = re.compile(r\"([\\\"']{3})\")\nRE_BACKTICK_BLOCK = re.compile(r\"```\")\n@dataclass(frozen=True)\nclass PromptSnippet:\n    file: str\n    start_line: int\n    end_line: int\n    kind: str",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "RE_HEREDOC_START",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "RE_HEREDOC_START = re.compile(r\"<<-?\\s*([\\\"']?)([A-Za-z0-9_]+)\\1\")\nRE_TRIPLE_QUOTE = re.compile(r\"([\\\"']{3})\")\nRE_BACKTICK_BLOCK = re.compile(r\"```\")\n@dataclass(frozen=True)\nclass PromptSnippet:\n    file: str\n    start_line: int\n    end_line: int\n    kind: str\n    preview: str",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "RE_TRIPLE_QUOTE",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "RE_TRIPLE_QUOTE = re.compile(r\"([\\\"']{3})\")\nRE_BACKTICK_BLOCK = re.compile(r\"```\")\n@dataclass(frozen=True)\nclass PromptSnippet:\n    file: str\n    start_line: int\n    end_line: int\n    kind: str\n    preview: str\n    sha256: str",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "RE_BACKTICK_BLOCK",
        "kind": 5,
        "importPath": "scripts.offllm_symbiosis_advisor_v6",
        "description": "scripts.offllm_symbiosis_advisor_v6",
        "peekOfCode": "RE_BACKTICK_BLOCK = re.compile(r\"```\")\n@dataclass(frozen=True)\nclass PromptSnippet:\n    file: str\n    start_line: int\n    end_line: int\n    kind: str\n    preview: str\n    sha256: str\n@dataclass(frozen=True)",
        "detail": "scripts.offllm_symbiosis_advisor_v6",
        "documentation": {}
    },
    {
        "label": "SarifFinding",
        "kind": 6,
        "importPath": "scripts.offllm_symbiosis_conductor_v1",
        "description": "scripts.offllm_symbiosis_conductor_v1",
        "peekOfCode": "class SarifFinding:\n    rule_id: str\n    level: str\n    message: str\n    uri: str\n    start_line: Optional[int] = None\n@dataclass(frozen=True)\nclass Hotspot:\n    path: str\n    score: float",
        "detail": "scripts.offllm_symbiosis_conductor_v1",
        "documentation": {}
    },
    {
        "label": "Hotspot",
        "kind": 6,
        "importPath": "scripts.offllm_symbiosis_conductor_v1",
        "description": "scripts.offllm_symbiosis_conductor_v1",
        "peekOfCode": "class Hotspot:\n    path: str\n    score: float\n    reasons: List[str]\n    churn_commits: int\n# ----------------------------\n# Small utilities\n# ----------------------------\ndef _utc_now() -> str:\n    return _dt.datetime.now(tz=_dt.timezone.utc).replace(microsecond=0).isoformat().replace(\"+00:00\", \"Z\")",
        "detail": "scripts.offllm_symbiosis_conductor_v1",
        "documentation": {}
    },
    {
        "label": "ConductorConfig",
        "kind": 6,
        "importPath": "scripts.offllm_symbiosis_conductor_v1",
        "description": "scripts.offllm_symbiosis_conductor_v1",
        "peekOfCode": "class ConductorConfig:\n    max_hotspots: int = 30\n    churn_max_count: int = 200\n    rg_bin: str = \"rg\"\n    include_rg_commands: bool = True\n    include_git_churn: bool = True\n    extra_search_patterns: Dict[str, List[str]] = dataclasses.field(default_factory=dict)\n    surfaces_order: List[str] = dataclasses.field(default_factory=lambda: [\n        \"prompts\",\n        \"tools_orchestration\",",
        "detail": "scripts.offllm_symbiosis_conductor_v1",
        "documentation": {}
    },
    {
        "label": "load_user_config",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_conductor_v1",
        "description": "scripts.offllm_symbiosis_conductor_v1",
        "peekOfCode": "def load_user_config(repo_root: Path) -> ConductorConfig:\n    \"\"\"\n    Load optional config from:\n      - .offllm-symbiosis.toml\n      - .offllm-symbiosis.json\n    TOML is preferred (py>=3.11). JSON always supported.\n    \"\"\"\n    toml_p = repo_root / \".offllm-symbiosis.toml\"\n    json_p = repo_root / \".offllm-symbiosis.json\"\n    data: Dict[str, Any] = {}",
        "detail": "scripts.offllm_symbiosis_conductor_v1",
        "documentation": {}
    },
    {
        "label": "load_sarif_findings",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_conductor_v1",
        "description": "scripts.offllm_symbiosis_conductor_v1",
        "peekOfCode": "def load_sarif_findings(sarif_path: Path) -> List[SarifFinding]:\n    obj = _read_json(sarif_path)\n    findings: List[SarifFinding] = []\n    try:\n        runs = obj.get(\"runs\", [])\n        if not runs:\n            return []\n        results = runs[0].get(\"results\", [])\n        for r in results:\n            rule_id = str(r.get(\"ruleId\", \"unknown\"))",
        "detail": "scripts.offllm_symbiosis_conductor_v1",
        "documentation": {}
    },
    {
        "label": "build_rg_commands",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_conductor_v1",
        "description": "scripts.offllm_symbiosis_conductor_v1",
        "peekOfCode": "def build_rg_commands(cfg: ConductorConfig, repo_root: Path, where: Dict[str, List[str]]) -> Dict[str, List[str]]:\n    \"\"\"\n    Create ripgrep commands per surface, targeted to the file lists from where_to_search.\n    \"\"\"\n    cmds: Dict[str, List[str]] = {}\n    patterns = dict(DEFAULT_RG_PATTERNS)\n    # merge in user patterns\n    for surf, pats in cfg.extra_search_patterns.items():\n        patterns[_surface_key_normalize(surf)] = patterns.get(_surface_key_normalize(surf), []) + list(pats)\n    for surf, files in where.items():",
        "detail": "scripts.offllm_symbiosis_conductor_v1",
        "documentation": {}
    },
    {
        "label": "compute_hotspots",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_conductor_v1",
        "description": "scripts.offllm_symbiosis_conductor_v1",
        "peekOfCode": "def compute_hotspots(\n    repo_root: Path,\n    where: Dict[str, List[str]],\n    sarif: List[SarifFinding],\n    cfg: ConductorConfig,\n) -> List[Hotspot]:\n    \"\"\"\n    Hotspot score heuristic:\n      - base score from number of surfaces a file appears in\n      - + SARIF findings weight",
        "detail": "scripts.offllm_symbiosis_conductor_v1",
        "documentation": {}
    },
    {
        "label": "compare_baseline",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_conductor_v1",
        "description": "scripts.offllm_symbiosis_conductor_v1",
        "peekOfCode": "def compare_baseline(current: Dict[str, Any], baseline: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Compare report surfaces + actions + prompt clusters.\n    Output is deterministic and safe to print in CI.\n    \"\"\"\n    cur_where = _extract_where_to_search(current)\n    base_where = _extract_where_to_search(baseline)\n    def _setmap(d: Dict[str, List[str]]) -> Dict[str, set]:\n        return {k: set(v) for k, v in d.items()}\n    cur_sm = _setmap(cur_where)",
        "detail": "scripts.offllm_symbiosis_conductor_v1",
        "documentation": {}
    },
    {
        "label": "build_fine_tune_manifest",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_conductor_v1",
        "description": "scripts.offllm_symbiosis_conductor_v1",
        "peekOfCode": "def build_fine_tune_manifest(where: Dict[str, List[str]], actions: List[Dict[str, Any]]) -> Dict[str, Any]:\n    \"\"\"\n    Produce a manifest of training data sources and intended evals.\n    This is meant to be consumed by your end-to-end pipeline as \"what to harvest next\".\n    \"\"\"\n    # Map surfaces to dataset intents\n    surface_to_intent = {\n        \"prompts\": {\"type\": \"prompt_registry\", \"weight\": 3},\n        \"tools_orchestration\": {\"type\": \"tool_schemas_and_handlers\", \"weight\": 3},\n        \"telemetry\": {\"type\": \"telemetry_events\", \"weight\": 4},",
        "detail": "scripts.offllm_symbiosis_conductor_v1",
        "documentation": {}
    },
    {
        "label": "action_backlog",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_conductor_v1",
        "description": "scripts.offllm_symbiosis_conductor_v1",
        "peekOfCode": "def action_backlog(actions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n    out: List[Dict[str, Any]] = []\n    for a in actions:\n        title = str(a.get(\"title\") or \"\")\n        template = ACTION_TO_REFACTOR_TEMPLATES.get(title, {})\n        out.append({\n            \"priority\": a.get(\"priority\", \"med\"),\n            \"title\": title,\n            \"why\": a.get(\"why\", \"\"),\n            \"next_steps\": a.get(\"next_steps\", []),",
        "detail": "scripts.offllm_symbiosis_conductor_v1",
        "documentation": {}
    },
    {
        "label": "render_md",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_conductor_v1",
        "description": "scripts.offllm_symbiosis_conductor_v1",
        "peekOfCode": "def render_md(\n    repo_root: Path,\n    report_path: Path,\n    sarif_path: Optional[Path],\n    cfg: ConductorConfig,\n    fingerprint: str,\n    where: Dict[str, List[str]],\n    rg_cmds: Dict[str, List[str]],\n    hotspots: List[Hotspot],\n    backlog: List[Dict[str, Any]],",
        "detail": "scripts.offllm_symbiosis_conductor_v1",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.offllm_symbiosis_conductor_v1",
        "description": "scripts.offllm_symbiosis_conductor_v1",
        "peekOfCode": "def main(argv: Optional[List[str]] = None) -> int:\n    ap = argparse.ArgumentParser(description=\"offLLM Symbiosis Conductor (v1)\")\n    ap.add_argument(\"--repo\", required=True, help=\"Repo root (e.g. /home/ales27pm/offLLM-1)\")\n    ap.add_argument(\"--report\", required=True, help=\"Path to symbiosis_deep_report.json\")\n    ap.add_argument(\"--sarif\", default=None, help=\"Optional path to symbiosis_deep_report.sarif.json\")\n    ap.add_argument(\"--baseline\", default=None, help=\"Optional baseline report json to compare against\")\n    ap.add_argument(\"--out\", required=True, help=\"Output directory (will be created)\")\n    ap.add_argument(\"--max-hotspots\", type=int, default=None, help=\"Override max hotspots\")\n    args = ap.parse_args(argv)\n    repo_root = Path(args.repo).expanduser().resolve()",
        "detail": "scripts.offllm_symbiosis_conductor_v1",
        "documentation": {}
    },
    {
        "label": "load_prompt_registry",
        "kind": 2,
        "importPath": "scripts.train_lora",
        "description": "scripts.train_lora",
        "peekOfCode": "def load_prompt_registry(registry_path: str) -> dict:\n    if not os.path.isfile(registry_path):\n        raise FileNotFoundError(f\"Prompt registry not found: {registry_path}\")\n    with open(registry_path, \"r\", encoding=\"utf-8\") as handle:\n        text = handle.read()\n    match = re.search(r\"PROMPT_REGISTRY_JSON\\s*=\\s*`(.*?)`\", text, re.S)\n    if not match:\n        raise ValueError(\"Unable to locate PROMPT_REGISTRY_JSON in registry file\")\n    return json.loads(match.group(1))\ndef format_example(example: dict, training_template: dict) -> str:",
        "detail": "scripts.train_lora",
        "documentation": {}
    },
    {
        "label": "format_example",
        "kind": 2,
        "importPath": "scripts.train_lora",
        "description": "scripts.train_lora",
        "peekOfCode": "def format_example(example: dict, training_template: dict) -> str:\n    required_keys = {\"system_prompt\", \"user_prompt_template\", \"assistant_template\"}\n    missing = required_keys - training_template.keys()\n    if missing:\n        raise ValueError(f\"Training template missing required keys: {missing}\")\n    if not isinstance(training_template.get(\"user_prompt_template\"), str):\n        raise ValueError(\"Training template 'user_prompt_template' must be a string\")\n    system_prompt = training_template[\"system_prompt\"]\n    user_prompt = training_template[\"user_prompt_template\"].format(\n        instruction=example.get(\"instruction\", \"\"),",
        "detail": "scripts.train_lora",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.train_lora",
        "description": "scripts.train_lora",
        "peekOfCode": "def main() -> None:\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--base_model\", required=True)\n    parser.add_argument(\"--train_file\", required=True)\n    parser.add_argument(\"--output_dir\", required=True)\n    parser.add_argument(\"--max_steps\", type=int, default=50)\n    parser.add_argument(\"--prompt_template\", default=None)\n    parser.add_argument(\n        \"--manifest-out\",\n        default=os.path.join(\"export\", \"manifest.json\"),",
        "detail": "scripts.train_lora",
        "documentation": {}
    },
    {
        "label": "Configuration",
        "kind": 6,
        "importPath": "scripts.verify-ios-cpp-standard",
        "description": "scripts.verify-ios-cpp-standard",
        "peekOfCode": "class Configuration:\n    identifier: str\n    config_name: str\n    target_label: str\n    values: list[str]\ndef normalize_value(raw_value: str) -> str:\n    value = raw_value.strip()\n    if value.startswith('\"') and value.endswith('\"'):\n        value = value[1:-1]\n    return value.strip()",
        "detail": "scripts.verify-ios-cpp-standard",
        "documentation": {}
    },
    {
        "label": "normalize_value",
        "kind": 2,
        "importPath": "scripts.verify-ios-cpp-standard",
        "description": "scripts.verify-ios-cpp-standard",
        "peekOfCode": "def normalize_value(raw_value: str) -> str:\n    value = raw_value.strip()\n    if value.startswith('\"') and value.endswith('\"'):\n        value = value[1:-1]\n    return value.strip()\ndef is_variable(value: str) -> bool:\n    return value.startswith(\"$(\") or value.startswith(\"${\")\ndef extract_section(text: str, section: str) -> str:\n    pattern = re.compile(SECTION_TEMPLATE.format(section=re.escape(section)), re.DOTALL)\n    match = pattern.search(text)",
        "detail": "scripts.verify-ios-cpp-standard",
        "documentation": {}
    },
    {
        "label": "is_variable",
        "kind": 2,
        "importPath": "scripts.verify-ios-cpp-standard",
        "description": "scripts.verify-ios-cpp-standard",
        "peekOfCode": "def is_variable(value: str) -> bool:\n    return value.startswith(\"$(\") or value.startswith(\"${\")\ndef extract_section(text: str, section: str) -> str:\n    pattern = re.compile(SECTION_TEMPLATE.format(section=re.escape(section)), re.DOTALL)\n    match = pattern.search(text)\n    return match.group(\"body\") if match else \"\"\ndef parse_configurations(text: str) -> dict[str, tuple[str, list[str]]]:\n    section = extract_section(text, \"XCBuildConfiguration\")\n    configurations: dict[str, tuple[str, list[str]]] = {}\n    for match in BUILD_CONFIG_RE.finditer(section):",
        "detail": "scripts.verify-ios-cpp-standard",
        "documentation": {}
    },
    {
        "label": "extract_section",
        "kind": 2,
        "importPath": "scripts.verify-ios-cpp-standard",
        "description": "scripts.verify-ios-cpp-standard",
        "peekOfCode": "def extract_section(text: str, section: str) -> str:\n    pattern = re.compile(SECTION_TEMPLATE.format(section=re.escape(section)), re.DOTALL)\n    match = pattern.search(text)\n    return match.group(\"body\") if match else \"\"\ndef parse_configurations(text: str) -> dict[str, tuple[str, list[str]]]:\n    section = extract_section(text, \"XCBuildConfiguration\")\n    configurations: dict[str, tuple[str, list[str]]] = {}\n    for match in BUILD_CONFIG_RE.finditer(section):\n        config_id = match.group(\"id\")\n        config_name = match.group(\"name\").strip()",
        "detail": "scripts.verify-ios-cpp-standard",
        "documentation": {}
    },
    {
        "label": "parse_configurations",
        "kind": 2,
        "importPath": "scripts.verify-ios-cpp-standard",
        "description": "scripts.verify-ios-cpp-standard",
        "peekOfCode": "def parse_configurations(text: str) -> dict[str, tuple[str, list[str]]]:\n    section = extract_section(text, \"XCBuildConfiguration\")\n    configurations: dict[str, tuple[str, list[str]]] = {}\n    for match in BUILD_CONFIG_RE.finditer(section):\n        config_id = match.group(\"id\")\n        config_name = match.group(\"name\").strip()\n        body = match.group(\"body\")\n        values: list[str] = []\n        for setting_match in STD_SETTING_RE.finditer(body):\n            if value := normalize_value(setting_match.group(\"value\")):",
        "detail": "scripts.verify-ios-cpp-standard",
        "documentation": {}
    },
    {
        "label": "format_target",
        "kind": 2,
        "importPath": "scripts.verify-ios-cpp-standard",
        "description": "scripts.verify-ios-cpp-standard",
        "peekOfCode": "def format_target(kind: str, name: str) -> str:\n    prefixes = {\n        \"PBXProject\": \"Project\",\n        \"PBXNativeTarget\": \"Target\",\n        \"PBXAggregateTarget\": \"Aggregate target\",\n    }\n    prefix = prefixes.get(kind.strip(), kind.strip() or \"Unknown\")\n    return f\"{prefix} \\\"{name.strip()}\\\"\"\ndef map_configuration_targets(text: str) -> dict[str, tuple[str, str]]:\n    section = extract_section(text, \"XCConfigurationList\")",
        "detail": "scripts.verify-ios-cpp-standard",
        "documentation": {}
    },
    {
        "label": "map_configuration_targets",
        "kind": 2,
        "importPath": "scripts.verify-ios-cpp-standard",
        "description": "scripts.verify-ios-cpp-standard",
        "peekOfCode": "def map_configuration_targets(text: str) -> dict[str, tuple[str, str]]:\n    section = extract_section(text, \"XCConfigurationList\")\n    mapping: dict[str, tuple[str, str]] = {}\n    for match in CONFIG_LIST_RE.finditer(section):\n        kind = match.group(\"kind\")\n        name = match.group(\"name\")\n        configs_blob = match.group(\"configs\")\n        for config_id_match in CONFIG_ID_RE.finditer(configs_blob):\n            config_id = config_id_match.group(1)\n            mapping[config_id] = (kind, name)",
        "detail": "scripts.verify-ios-cpp-standard",
        "documentation": {}
    },
    {
        "label": "collect_configuration_reports",
        "kind": 2,
        "importPath": "scripts.verify-ios-cpp-standard",
        "description": "scripts.verify-ios-cpp-standard",
        "peekOfCode": "def collect_configuration_reports(path: Path) -> list[Configuration]:\n    text = path.read_text(errors=\"ignore\")\n    values_by_id = parse_configurations(text)\n    target_mapping = map_configuration_targets(text)\n    reports: list[Configuration] = []\n    for config_id, (config_name, values) in values_by_id.items():\n        kind, name = target_mapping.get(config_id, (\"Unknown\", config_id))\n        reports.append(\n            Configuration(\n                identifier=config_id,",
        "detail": "scripts.verify-ios-cpp-standard",
        "documentation": {}
    },
    {
        "label": "summarize_values",
        "kind": 2,
        "importPath": "scripts.verify-ios-cpp-standard",
        "description": "scripts.verify-ios-cpp-standard",
        "peekOfCode": "def summarize_values(configurations: Iterable[Configuration]) -> set[str]:\n    values: set[str] = set()\n    for config in configurations:\n        values.update(config.values)\n    return values\ndef evaluate_pods_configs(configurations: list[Configuration]) -> tuple[bool, list[str]]:\n    failures: list[str] = []\n    for config in configurations:\n        explicit_values = [value for value in config.values if not is_variable(value)]\n        if not explicit_values:",
        "detail": "scripts.verify-ios-cpp-standard",
        "documentation": {}
    },
    {
        "label": "evaluate_pods_configs",
        "kind": 2,
        "importPath": "scripts.verify-ios-cpp-standard",
        "description": "scripts.verify-ios-cpp-standard",
        "peekOfCode": "def evaluate_pods_configs(configurations: list[Configuration]) -> tuple[bool, list[str]]:\n    failures: list[str] = []\n    for config in configurations:\n        explicit_values = [value for value in config.values if not is_variable(value)]\n        if not explicit_values:\n            failures.append(\n                f\"{config.target_label} [{config.config_name}]: \"\n                f\"{', '.join(config.values) if config.values else '(missing)'}\"\n            )\n            continue",
        "detail": "scripts.verify-ios-cpp-standard",
        "documentation": {}
    },
    {
        "label": "print_app_summary",
        "kind": 2,
        "importPath": "scripts.verify-ios-cpp-standard",
        "description": "scripts.verify-ios-cpp-standard",
        "peekOfCode": "def print_app_summary(configurations: list[Configuration]) -> None:\n    explicit_values = {\n        value\n        for config in configurations\n        for value in config.values\n        if not is_variable(value)\n    }\n    if explicit_values:\n        print(\"App CLANG_CXX_LANGUAGE_STANDARD values:\", explicit_values)\n    else:",
        "detail": "scripts.verify-ios-cpp-standard",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.verify-ios-cpp-standard",
        "description": "scripts.verify-ios-cpp-standard",
        "peekOfCode": "def main() -> int:\n    if not PODS_PROJECT.exists():\n        print(\"Pods.xcodeproj not found (run pod install)\", file=sys.stderr)\n        return 2\n    pods_configs = collect_configuration_reports(PODS_PROJECT)\n    pods_values = summarize_values(pods_configs)\n    print(\"Pods CLANG_CXX_LANGUAGE_STANDARD values:\", pods_values or {\"(none)\"})\n    pods_ok, failures = evaluate_pods_configs(pods_configs)\n    if APP_PROJECT.exists():\n        app_configs = collect_configuration_reports(APP_PROJECT)",
        "detail": "scripts.verify-ios-cpp-standard",
        "documentation": {}
    },
    {
        "label": "PODS_PROJECT",
        "kind": 5,
        "importPath": "scripts.verify-ios-cpp-standard",
        "description": "scripts.verify-ios-cpp-standard",
        "peekOfCode": "PODS_PROJECT = Path(\"ios/Pods/Pods.xcodeproj/project.pbxproj\")\nAPP_PROJECT = Path(\"ios/monGARS.xcodeproj/project.pbxproj\")\nSECTION_TEMPLATE = r\"/\\* Begin {section} section \\*/(?P<body>.*?)/\\* End {section} section \\*/\"\nBUILD_CONFIG_RE = re.compile(\n    r\"\\s*(?P<id>[0-9A-Fa-f]+) /\\* (?P<name>[^*]+) \\*/ = \\{\\s*\"\n    r\"isa = XCBuildConfiguration;\\s*(?P<body>.*?)\\};\",\n    re.DOTALL,\n)\nCONFIG_LIST_RE = re.compile(\n    r\"\\s*(?P<id>[0-9A-Fa-f]+) /\\* Build configuration list for (?P<kind>[^\\\"]+) \\\"(?P<name>[^\\\"]+)\\\" \\*/ = \\{\\s*\"",
        "detail": "scripts.verify-ios-cpp-standard",
        "documentation": {}
    },
    {
        "label": "APP_PROJECT",
        "kind": 5,
        "importPath": "scripts.verify-ios-cpp-standard",
        "description": "scripts.verify-ios-cpp-standard",
        "peekOfCode": "APP_PROJECT = Path(\"ios/monGARS.xcodeproj/project.pbxproj\")\nSECTION_TEMPLATE = r\"/\\* Begin {section} section \\*/(?P<body>.*?)/\\* End {section} section \\*/\"\nBUILD_CONFIG_RE = re.compile(\n    r\"\\s*(?P<id>[0-9A-Fa-f]+) /\\* (?P<name>[^*]+) \\*/ = \\{\\s*\"\n    r\"isa = XCBuildConfiguration;\\s*(?P<body>.*?)\\};\",\n    re.DOTALL,\n)\nCONFIG_LIST_RE = re.compile(\n    r\"\\s*(?P<id>[0-9A-Fa-f]+) /\\* Build configuration list for (?P<kind>[^\\\"]+) \\\"(?P<name>[^\\\"]+)\\\" \\*/ = \\{\\s*\"\n    r\"isa = XCConfigurationList;\\s*buildConfigurations = \\((?P<configs>.*?)\\);\",",
        "detail": "scripts.verify-ios-cpp-standard",
        "documentation": {}
    },
    {
        "label": "SECTION_TEMPLATE",
        "kind": 5,
        "importPath": "scripts.verify-ios-cpp-standard",
        "description": "scripts.verify-ios-cpp-standard",
        "peekOfCode": "SECTION_TEMPLATE = r\"/\\* Begin {section} section \\*/(?P<body>.*?)/\\* End {section} section \\*/\"\nBUILD_CONFIG_RE = re.compile(\n    r\"\\s*(?P<id>[0-9A-Fa-f]+) /\\* (?P<name>[^*]+) \\*/ = \\{\\s*\"\n    r\"isa = XCBuildConfiguration;\\s*(?P<body>.*?)\\};\",\n    re.DOTALL,\n)\nCONFIG_LIST_RE = re.compile(\n    r\"\\s*(?P<id>[0-9A-Fa-f]+) /\\* Build configuration list for (?P<kind>[^\\\"]+) \\\"(?P<name>[^\\\"]+)\\\" \\*/ = \\{\\s*\"\n    r\"isa = XCConfigurationList;\\s*buildConfigurations = \\((?P<configs>.*?)\\);\",\n    re.DOTALL,",
        "detail": "scripts.verify-ios-cpp-standard",
        "documentation": {}
    },
    {
        "label": "BUILD_CONFIG_RE",
        "kind": 5,
        "importPath": "scripts.verify-ios-cpp-standard",
        "description": "scripts.verify-ios-cpp-standard",
        "peekOfCode": "BUILD_CONFIG_RE = re.compile(\n    r\"\\s*(?P<id>[0-9A-Fa-f]+) /\\* (?P<name>[^*]+) \\*/ = \\{\\s*\"\n    r\"isa = XCBuildConfiguration;\\s*(?P<body>.*?)\\};\",\n    re.DOTALL,\n)\nCONFIG_LIST_RE = re.compile(\n    r\"\\s*(?P<id>[0-9A-Fa-f]+) /\\* Build configuration list for (?P<kind>[^\\\"]+) \\\"(?P<name>[^\\\"]+)\\\" \\*/ = \\{\\s*\"\n    r\"isa = XCConfigurationList;\\s*buildConfigurations = \\((?P<configs>.*?)\\);\",\n    re.DOTALL,\n)",
        "detail": "scripts.verify-ios-cpp-standard",
        "documentation": {}
    },
    {
        "label": "CONFIG_LIST_RE",
        "kind": 5,
        "importPath": "scripts.verify-ios-cpp-standard",
        "description": "scripts.verify-ios-cpp-standard",
        "peekOfCode": "CONFIG_LIST_RE = re.compile(\n    r\"\\s*(?P<id>[0-9A-Fa-f]+) /\\* Build configuration list for (?P<kind>[^\\\"]+) \\\"(?P<name>[^\\\"]+)\\\" \\*/ = \\{\\s*\"\n    r\"isa = XCConfigurationList;\\s*buildConfigurations = \\((?P<configs>.*?)\\);\",\n    re.DOTALL,\n)\nCONFIG_ID_RE = re.compile(r\"([0-9A-Fa-f]+) /\\*\")\nSTD_SETTING_RE = re.compile(\n    r\"CLANG_CXX_LANGUAGE_STANDARD(?:\\[[^\\]]+\\])?\\s*=\\s*(?P<value>[^;]+);\"\n)\n@dataclass",
        "detail": "scripts.verify-ios-cpp-standard",
        "documentation": {}
    },
    {
        "label": "CONFIG_ID_RE",
        "kind": 5,
        "importPath": "scripts.verify-ios-cpp-standard",
        "description": "scripts.verify-ios-cpp-standard",
        "peekOfCode": "CONFIG_ID_RE = re.compile(r\"([0-9A-Fa-f]+) /\\*\")\nSTD_SETTING_RE = re.compile(\n    r\"CLANG_CXX_LANGUAGE_STANDARD(?:\\[[^\\]]+\\])?\\s*=\\s*(?P<value>[^;]+);\"\n)\n@dataclass\nclass Configuration:\n    identifier: str\n    config_name: str\n    target_label: str\n    values: list[str]",
        "detail": "scripts.verify-ios-cpp-standard",
        "documentation": {}
    },
    {
        "label": "STD_SETTING_RE",
        "kind": 5,
        "importPath": "scripts.verify-ios-cpp-standard",
        "description": "scripts.verify-ios-cpp-standard",
        "peekOfCode": "STD_SETTING_RE = re.compile(\n    r\"CLANG_CXX_LANGUAGE_STANDARD(?:\\[[^\\]]+\\])?\\s*=\\s*(?P<value>[^;]+);\"\n)\n@dataclass\nclass Configuration:\n    identifier: str\n    config_name: str\n    target_label: str\n    values: list[str]\ndef normalize_value(raw_value: str) -> str:",
        "detail": "scripts.verify-ios-cpp-standard",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.verify-ios-rn-versions",
        "description": "scripts.verify-ios-rn-versions",
        "peekOfCode": "def main():\n    pkg_path = Path(\"package.json\")\n    lock_path = Path(\"ios/Podfile.lock\")\n    if not pkg_path.exists():\n        print(\"package.json not found\", file=sys.stderr)\n        sys.exit(2)\n    if not lock_path.exists():\n        print(\"ios/Podfile.lock not found (run pod install)\", file=sys.stderr)\n        sys.exit(2)\n    pkg = json.loads(pkg_path.read_text())",
        "detail": "scripts.verify-ios-rn-versions",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.xcresult_top_issues",
        "description": "scripts.xcresult_top_issues",
        "peekOfCode": "def main() -> None:\n    try:\n        data = json.load(sys.stdin)\n    except Exception:\n        # If input isn't JSON for any reason, don't fail the step\n        return\n    pairs: List[Tuple[str, str]] = []\n    _collect_messages(data, pairs)\n    pairs = _dedupe_preserve_order(pairs)\n    for sev, msg in pairs[:200]:",
        "detail": "scripts.xcresult_top_issues",
        "documentation": {}
    },
    {
        "label": "UnslothBCOConfig",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothBCOTrainer",
        "description": "unsloth_compiled_cache.UnslothBCOTrainer",
        "peekOfCode": "class UnslothBCOConfig(BCOConfig):\n    \"\"\"\n    Configuration class for the [`BCOTrainer`].\n    This class includes only the parameters that are specific to BCO training. For a full list of training arguments,\n    please refer to the [`~transformers.TrainingArguments`] documentation. Note that default values in this class may\n    differ from those in [`~transformers.TrainingArguments`].\n    Using [`~transformers.HfArgumentParser`] we can turn this class into\n    [argparse](https://docs.python.org/3/library/argparse#module-argparse) arguments that can be specified on the\n    command line.\n    Parameters:",
        "detail": "unsloth_compiled_cache.UnslothBCOTrainer",
        "documentation": {}
    },
    {
        "label": "_UnslothBCOTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothBCOTrainer",
        "description": "unsloth_compiled_cache.UnslothBCOTrainer",
        "peekOfCode": "class _UnslothBCOTrainer(BaseTrainer):\n    r\"\"\"\"\"\"\n    _tag_names = [\"trl\", \"bco\"]\n    _name = \"BCO\"\n    _paper = {\n        \"title\": \"Binary Classifier Optimization for Large Language Model Alignment\",\n        \"id\": \"2404.04656\",\n        # docstyle-ignore\n        \"citation\": textwrap.dedent(\"\"\"\\\n            @article{jung2024binary,",
        "detail": "unsloth_compiled_cache.UnslothBCOTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothBCOTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothBCOTrainer",
        "description": "unsloth_compiled_cache.UnslothBCOTrainer",
        "peekOfCode": "class UnslothBCOTrainer(_UnslothBCOTrainer):\n    \"\"\"\n    Initialize BCOTrainer from [BCO](https://huggingface.co/papers/2404.04656) paper.\n    Args:\n        model ([`~transformers.PreTrainedModel`]):\n            The model to train, preferably an [`~transformers.AutoModelForSequenceClassification`].\n        ref_model ([`PreTrainedModelWrapper`]):\n            Hugging Face transformer model with a casual language modelling head. Used for implicit reward computation\n            and loss. If no reference model is provided, the trainer will create a reference model with the same\n            architecture as the model to be optimized.",
        "detail": "unsloth_compiled_cache.UnslothBCOTrainer",
        "documentation": {}
    },
    {
        "label": "prepare_for_training_mode",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothBCOTrainer",
        "description": "unsloth_compiled_cache.UnslothBCOTrainer",
        "peekOfCode": "def prepare_for_training_mode(f):\n    @functools.wraps(f)\n    def wrapper(self, *args, **kwargs):\n        # Enable training mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_training\"):\n            self.model.for_training()\n        output = f(self, *args, **kwargs)\n        # Return inference mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_inference\"):\n            self.model.for_inference()",
        "detail": "unsloth_compiled_cache.UnslothBCOTrainer",
        "documentation": {}
    },
    {
        "label": "chunked_selective_log_softmax",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothBCOTrainer",
        "description": "unsloth_compiled_cache.UnslothBCOTrainer",
        "peekOfCode": "def chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)\n        logsumexp_values = torch.logsumexp(chunk_logits, dim = -1)",
        "detail": "unsloth_compiled_cache.UnslothBCOTrainer",
        "documentation": {}
    },
    {
        "label": "calculate_pad_tokens_in_prompt",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothBCOTrainer",
        "description": "unsloth_compiled_cache.UnslothBCOTrainer",
        "peekOfCode": "def calculate_pad_tokens_in_prompt(\n    input_ids: torch.Tensor,\n    logits_to_keep: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given prompt tensor, it returns all the left padded tokens in that sequence. so [pad, pad, pad, cat] = 3 tokens\n    \"\"\"\n    if logits_to_keep >= input_ids.shape[1]:\n        raise ValueError(\"logits_to_keep must be smaller than the sequence length.\")",
        "detail": "unsloth_compiled_cache.UnslothBCOTrainer",
        "documentation": {}
    },
    {
        "label": "create_completion_attention_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothBCOTrainer",
        "description": "unsloth_compiled_cache.UnslothBCOTrainer",
        "peekOfCode": "def create_completion_attention_mask(\n    completion_input_ids: torch.Tensor,\n    left_pad_tokens_per_prompt: torch.Tensor,\n    max_left_pad: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given that we have a sequence, [p,p,p,c,c,c,pad,pad,pad]\n    Where p are extra prompt tokens we got from slicing the torch tensor, c is completion tokens\n    and pad are pad tokens, this function would make a completion mask that would 0 out the pad",
        "detail": "unsloth_compiled_cache.UnslothBCOTrainer",
        "documentation": {}
    },
    {
        "label": "left_pack_padding",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothBCOTrainer",
        "description": "unsloth_compiled_cache.UnslothBCOTrainer",
        "peekOfCode": "def left_pack_padding(tensor: torch.Tensor, pad_id: int) -> torch.Tensor:\n    \"\"\"\n    Moves all padding tokens in each sequence of a batch to the right.\n    \"\"\"\n    mask = (tensor != pad_id)\n    # Must do stable=True since binary mark is unordered\n    sorted_indices = torch.argsort(mask, dim=1, descending=True, stable=True)\n    packed_tensor = torch.gather(tensor, 1, sorted_indices)\n    return packed_tensor\ndef align_logprobs_with_mask(",
        "detail": "unsloth_compiled_cache.UnslothBCOTrainer",
        "documentation": {}
    },
    {
        "label": "align_logprobs_with_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothBCOTrainer",
        "description": "unsloth_compiled_cache.UnslothBCOTrainer",
        "peekOfCode": "def align_logprobs_with_mask(\n    logprob_tensor: torch.Tensor,\n    attention_mask: torch.Tensor,\n    pad_value: float = 0.0\n) -> torch.Tensor:\n    \"\"\"\n    Aligns a log probability tensor with a given attention mask.\n    \"\"\"\n    device = logprob_tensor.device\n    batch_size, logprob_seq_len = logprob_tensor.shape",
        "detail": "unsloth_compiled_cache.UnslothBCOTrainer",
        "documentation": {}
    },
    {
        "label": "torch_compile_options",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothBCOTrainer",
        "description": "unsloth_compiled_cache.UnslothBCOTrainer",
        "peekOfCode": "torch_compile_options = {\n    \"epilogue_fusion\"   : True,\n    \"max_autotune\"      : False,\n    \"shape_padding\"     : True,\n    \"trace.enabled\"     : False,\n    \"triton.cudagraphs\" : False,\n}\n@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only",
        "detail": "unsloth_compiled_cache.UnslothBCOTrainer",
        "documentation": {}
    },
    {
        "label": "@torch.compile(dynamic",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothBCOTrainer",
        "description": "unsloth_compiled_cache.UnslothBCOTrainer",
        "peekOfCode": "@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)",
        "detail": "unsloth_compiled_cache.UnslothBCOTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothCPOConfig",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothCPOTrainer",
        "description": "unsloth_compiled_cache.UnslothCPOTrainer",
        "peekOfCode": "class UnslothCPOConfig(CPOConfig):\n    \"\"\"\n    Configuration class for the [`CPOTrainer`].\n    This class includes only the parameters that are specific to CPO training. For a full list of training arguments,\n    please refer to the [`~transformers.TrainingArguments`] documentation. Note that default values in this class may\n    differ from those in [`~transformers.TrainingArguments`].\n    Using [`~transformers.HfArgumentParser`] we can turn this class into\n    [argparse](https://docs.python.org/3/library/argparse#module-argparse) arguments that can be specified on the\n    command line.\n    Parameters:",
        "detail": "unsloth_compiled_cache.UnslothCPOTrainer",
        "documentation": {}
    },
    {
        "label": "_UnslothCPOTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothCPOTrainer",
        "description": "unsloth_compiled_cache.UnslothCPOTrainer",
        "peekOfCode": "class _UnslothCPOTrainer(BaseTrainer):\n    r\"\"\"\"\"\"\n    _tag_names = [\"trl\", \"cpo\"]\n    _name = \"CPO\"\n    _paper = {\n        \"title\": \"Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation\",\n        \"id\": \"2401.08417\",\n        # docstyle-ignore\n        \"citation\": textwrap.dedent(\"\"\"\\\n            @inproceedings{xu2024contrastive,",
        "detail": "unsloth_compiled_cache.UnslothCPOTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothCPOTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothCPOTrainer",
        "description": "unsloth_compiled_cache.UnslothCPOTrainer",
        "peekOfCode": "class UnslothCPOTrainer(_UnslothCPOTrainer):\n    \"\"\"\n    Initialize CPOTrainer.\n    Args:\n        model ([`~transformers.PreTrainedModel`]):\n            The model to train, preferably an [`~transformers.AutoModelForSequenceClassification`].\n        args ([`CPOConfig`]):\n            The CPO config arguments to use for training.\n        data_collator ([`~transformers.DataCollator`]):\n            The data collator to use for training. If None is specified, the default data collator",
        "detail": "unsloth_compiled_cache.UnslothCPOTrainer",
        "documentation": {}
    },
    {
        "label": "prepare_for_training_mode",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothCPOTrainer",
        "description": "unsloth_compiled_cache.UnslothCPOTrainer",
        "peekOfCode": "def prepare_for_training_mode(f):\n    @functools.wraps(f)\n    def wrapper(self, *args, **kwargs):\n        # Enable training mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_training\"):\n            self.model.for_training()\n        output = f(self, *args, **kwargs)\n        # Return inference mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_inference\"):\n            self.model.for_inference()",
        "detail": "unsloth_compiled_cache.UnslothCPOTrainer",
        "documentation": {}
    },
    {
        "label": "chunked_selective_log_softmax",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothCPOTrainer",
        "description": "unsloth_compiled_cache.UnslothCPOTrainer",
        "peekOfCode": "def chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)\n        logsumexp_values = torch.logsumexp(chunk_logits, dim = -1)",
        "detail": "unsloth_compiled_cache.UnslothCPOTrainer",
        "documentation": {}
    },
    {
        "label": "calculate_pad_tokens_in_prompt",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothCPOTrainer",
        "description": "unsloth_compiled_cache.UnslothCPOTrainer",
        "peekOfCode": "def calculate_pad_tokens_in_prompt(\n    input_ids: torch.Tensor,\n    logits_to_keep: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given prompt tensor, it returns all the left padded tokens in that sequence. so [pad, pad, pad, cat] = 3 tokens\n    \"\"\"\n    if logits_to_keep >= input_ids.shape[1]:\n        raise ValueError(\"logits_to_keep must be smaller than the sequence length.\")",
        "detail": "unsloth_compiled_cache.UnslothCPOTrainer",
        "documentation": {}
    },
    {
        "label": "create_completion_attention_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothCPOTrainer",
        "description": "unsloth_compiled_cache.UnslothCPOTrainer",
        "peekOfCode": "def create_completion_attention_mask(\n    completion_input_ids: torch.Tensor,\n    left_pad_tokens_per_prompt: torch.Tensor,\n    max_left_pad: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given that we have a sequence, [p,p,p,c,c,c,pad,pad,pad]\n    Where p are extra prompt tokens we got from slicing the torch tensor, c is completion tokens\n    and pad are pad tokens, this function would make a completion mask that would 0 out the pad",
        "detail": "unsloth_compiled_cache.UnslothCPOTrainer",
        "documentation": {}
    },
    {
        "label": "left_pack_padding",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothCPOTrainer",
        "description": "unsloth_compiled_cache.UnslothCPOTrainer",
        "peekOfCode": "def left_pack_padding(tensor: torch.Tensor, pad_id: int) -> torch.Tensor:\n    \"\"\"\n    Moves all padding tokens in each sequence of a batch to the right.\n    \"\"\"\n    mask = (tensor != pad_id)\n    # Must do stable=True since binary mark is unordered\n    sorted_indices = torch.argsort(mask, dim=1, descending=True, stable=True)\n    packed_tensor = torch.gather(tensor, 1, sorted_indices)\n    return packed_tensor\ndef align_logprobs_with_mask(",
        "detail": "unsloth_compiled_cache.UnslothCPOTrainer",
        "documentation": {}
    },
    {
        "label": "align_logprobs_with_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothCPOTrainer",
        "description": "unsloth_compiled_cache.UnslothCPOTrainer",
        "peekOfCode": "def align_logprobs_with_mask(\n    logprob_tensor: torch.Tensor,\n    attention_mask: torch.Tensor,\n    pad_value: float = 0.0\n) -> torch.Tensor:\n    \"\"\"\n    Aligns a log probability tensor with a given attention mask.\n    \"\"\"\n    device = logprob_tensor.device\n    batch_size, logprob_seq_len = logprob_tensor.shape",
        "detail": "unsloth_compiled_cache.UnslothCPOTrainer",
        "documentation": {}
    },
    {
        "label": "torch_compile_options",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothCPOTrainer",
        "description": "unsloth_compiled_cache.UnslothCPOTrainer",
        "peekOfCode": "torch_compile_options = {\n    \"epilogue_fusion\"   : True,\n    \"max_autotune\"      : False,\n    \"shape_padding\"     : True,\n    \"trace.enabled\"     : False,\n    \"triton.cudagraphs\" : False,\n}\n@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only",
        "detail": "unsloth_compiled_cache.UnslothCPOTrainer",
        "documentation": {}
    },
    {
        "label": "@torch.compile(dynamic",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothCPOTrainer",
        "description": "unsloth_compiled_cache.UnslothCPOTrainer",
        "peekOfCode": "@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)",
        "detail": "unsloth_compiled_cache.UnslothCPOTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothDPOConfig",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothDPOTrainer",
        "peekOfCode": "class UnslothDPOConfig(DPOConfig):\n    \"\"\"\n    Configuration class for the [`DPOTrainer`].\n    This class includes only the parameters that are specific to DPO training. For a full list of training arguments,\n    please refer to the [`~transformers.TrainingArguments`] documentation. Note that default values in this class may\n    differ from those in [`~transformers.TrainingArguments`].\n    Using [`~transformers.HfArgumentParser`] we can turn this class into\n    [argparse](https://docs.python.org/3/library/argparse#module-argparse) arguments that can be specified on the\n    command line.\n    Parameters:",
        "detail": "unsloth_compiled_cache.UnslothDPOTrainer",
        "documentation": {}
    },
    {
        "label": "_UnslothDPOTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothDPOTrainer",
        "peekOfCode": "class _UnslothDPOTrainer(BaseTrainer):\n    \"\"\"\"\"\"\n    _tag_names = [\"trl\", \"dpo\"]\n    _name = \"DPO\"\n    _paper = {\n        \"title\": \"Direct Preference Optimization: Your Language Model is Secretly a Reward Model\",\n        \"id\": \"2305.18290\",\n        # docstyle-ignore\n        \"citation\": textwrap.dedent(\"\"\"\\\n            @inproceedings{rafailov2023direct,",
        "detail": "unsloth_compiled_cache.UnslothDPOTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothDPOTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothDPOTrainer",
        "peekOfCode": "class UnslothDPOTrainer(_UnslothDPOTrainer):\n    \"\"\"\n    Trainer for Direct Preference Optimization (DPO) method.\n    This class is a wrapper around the [`transformers.Trainer`] class and inherits all of its attributes and methods.\n    Args:\n        model (`Union[str, PreTrainedModel]`):\n            Model to be trained. Can be either:\n            - A string, being the *model id* of a pretrained model hosted inside a model repo on huggingface.co, or a\n              path to a *directory* containing model weights saved using\n              [`~transformers.PreTrainedModel.save_pretrained`], e.g., `'./my_model_directory/'`. The model is loaded",
        "detail": "unsloth_compiled_cache.UnslothDPOTrainer",
        "documentation": {}
    },
    {
        "label": "prepare_for_training_mode",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothDPOTrainer",
        "peekOfCode": "def prepare_for_training_mode(f):\n    @functools.wraps(f)\n    def wrapper(self, *args, **kwargs):\n        # Enable training mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_training\"):\n            self.model.for_training()\n        output = f(self, *args, **kwargs)\n        # Return inference mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_inference\"):\n            self.model.for_inference()",
        "detail": "unsloth_compiled_cache.UnslothDPOTrainer",
        "documentation": {}
    },
    {
        "label": "chunked_selective_log_softmax",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothDPOTrainer",
        "peekOfCode": "def chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)\n        logsumexp_values = torch.logsumexp(chunk_logits, dim = -1)",
        "detail": "unsloth_compiled_cache.UnslothDPOTrainer",
        "documentation": {}
    },
    {
        "label": "calculate_pad_tokens_in_prompt",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothDPOTrainer",
        "peekOfCode": "def calculate_pad_tokens_in_prompt(\n    input_ids: torch.Tensor,\n    logits_to_keep: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given prompt tensor, it returns all the left padded tokens in that sequence. so [pad, pad, pad, cat] = 3 tokens\n    \"\"\"\n    if logits_to_keep >= input_ids.shape[1]:\n        raise ValueError(\"logits_to_keep must be smaller than the sequence length.\")",
        "detail": "unsloth_compiled_cache.UnslothDPOTrainer",
        "documentation": {}
    },
    {
        "label": "create_completion_attention_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothDPOTrainer",
        "peekOfCode": "def create_completion_attention_mask(\n    completion_input_ids: torch.Tensor,\n    left_pad_tokens_per_prompt: torch.Tensor,\n    max_left_pad: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given that we have a sequence, [p,p,p,c,c,c,pad,pad,pad]\n    Where p are extra prompt tokens we got from slicing the torch tensor, c is completion tokens\n    and pad are pad tokens, this function would make a completion mask that would 0 out the pad",
        "detail": "unsloth_compiled_cache.UnslothDPOTrainer",
        "documentation": {}
    },
    {
        "label": "left_pack_padding",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothDPOTrainer",
        "peekOfCode": "def left_pack_padding(tensor: torch.Tensor, pad_id: int) -> torch.Tensor:\n    \"\"\"\n    Moves all padding tokens in each sequence of a batch to the right.\n    \"\"\"\n    mask = (tensor != pad_id)\n    # Must do stable=True since binary mark is unordered\n    sorted_indices = torch.argsort(mask, dim=1, descending=True, stable=True)\n    packed_tensor = torch.gather(tensor, 1, sorted_indices)\n    return packed_tensor\ndef align_logprobs_with_mask(",
        "detail": "unsloth_compiled_cache.UnslothDPOTrainer",
        "documentation": {}
    },
    {
        "label": "align_logprobs_with_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothDPOTrainer",
        "peekOfCode": "def align_logprobs_with_mask(\n    logprob_tensor: torch.Tensor,\n    attention_mask: torch.Tensor,\n    pad_value: float = 0.0\n) -> torch.Tensor:\n    \"\"\"\n    Aligns a log probability tensor with a given attention mask.\n    \"\"\"\n    device = logprob_tensor.device\n    batch_size, logprob_seq_len = logprob_tensor.shape",
        "detail": "unsloth_compiled_cache.UnslothDPOTrainer",
        "documentation": {}
    },
    {
        "label": "torch_compile_options",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothDPOTrainer",
        "peekOfCode": "torch_compile_options = {\n    \"epilogue_fusion\"   : True,\n    \"max_autotune\"      : False,\n    \"shape_padding\"     : True,\n    \"trace.enabled\"     : False,\n    \"triton.cudagraphs\" : False,\n}\n@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only",
        "detail": "unsloth_compiled_cache.UnslothDPOTrainer",
        "documentation": {}
    },
    {
        "label": "@torch.compile(dynamic",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothDPOTrainer",
        "peekOfCode": "@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)",
        "detail": "unsloth_compiled_cache.UnslothDPOTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothGKDConfig",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothGKDTrainer",
        "description": "unsloth_compiled_cache.UnslothGKDTrainer",
        "peekOfCode": "class UnslothGKDConfig(GKDConfig):\n    \"\"\"\n    Configuration class for [`GKDTrainer`].\n    This class includes only the parameters that are specific to GKD training. For a full list of training arguments,\n    please refer to the [`~transformers.TrainingArguments`] and [`SFTConfig`] documentation.\n    Args:\n        temperature (`float`, *optional*, defaults to `0.9`):\n            Temperature for sampling. The higher the temperature, the more random the completions.\n        lmbda (`float`, *optional*, defaults to `0.5`):\n            Lambda parameter that controls the student data fraction (i.e., the proportion of on-policy",
        "detail": "unsloth_compiled_cache.UnslothGKDTrainer",
        "documentation": {}
    },
    {
        "label": "_UnslothGKDTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothGKDTrainer",
        "description": "unsloth_compiled_cache.UnslothGKDTrainer",
        "peekOfCode": "class _UnslothGKDTrainer(SFTTrainer):\n    \"\"\"\"\"\"\n    _tag_names = [\"trl\", \"gkd\"]\n    _name = \"GKD\"\n    _paper = {\n        \"title\": \"On-Policy Distillation of Language Models: Learning from Self-Generated Mistakes\",\n        \"id\": \"2306.13649\",\n        # docstyle-ignore\n        \"citation\": textwrap.dedent(\"\"\"\\\n            @inproceedings{agarwal2024on-policy,",
        "detail": "unsloth_compiled_cache.UnslothGKDTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothGKDTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothGKDTrainer",
        "description": "unsloth_compiled_cache.UnslothGKDTrainer",
        "peekOfCode": "class UnslothGKDTrainer(_UnslothGKDTrainer):\n    \"\"\"\n    Trainer for Generalized Knowledge Distillation (GKD) of language models.\n    For details on GKD, see the paper: [On-Policy Distillation of Language Models: Learning from Self-Generated\n    Mistakes](https://huggingface.co/papers/2306.13649).\n    Args:\n        model ([`~transformers.PreTrainedModel`] or `torch.nn.Module` or `str`, *optional*):\n            Model to be trained, or the string identifier of the model to be instantiated from a pretrained model.\n        teacher_model ([`~transformers.PreTrainedModel`] or `torch.nn.Module` or `str`, *optional*):\n            Teacher model for knowledge distillation, or the string identifier of the model to be instantiated from a",
        "detail": "unsloth_compiled_cache.UnslothGKDTrainer",
        "documentation": {}
    },
    {
        "label": "prepare_for_training_mode",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothGKDTrainer",
        "description": "unsloth_compiled_cache.UnslothGKDTrainer",
        "peekOfCode": "def prepare_for_training_mode(f):\n    @functools.wraps(f)\n    def wrapper(self, *args, **kwargs):\n        # Enable training mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_training\"):\n            self.model.for_training()\n        output = f(self, *args, **kwargs)\n        # Return inference mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_inference\"):\n            self.model.for_inference()",
        "detail": "unsloth_compiled_cache.UnslothGKDTrainer",
        "documentation": {}
    },
    {
        "label": "chunked_selective_log_softmax",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothGKDTrainer",
        "description": "unsloth_compiled_cache.UnslothGKDTrainer",
        "peekOfCode": "def chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)\n        logsumexp_values = torch.logsumexp(chunk_logits, dim = -1)",
        "detail": "unsloth_compiled_cache.UnslothGKDTrainer",
        "documentation": {}
    },
    {
        "label": "calculate_pad_tokens_in_prompt",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothGKDTrainer",
        "description": "unsloth_compiled_cache.UnslothGKDTrainer",
        "peekOfCode": "def calculate_pad_tokens_in_prompt(\n    input_ids: torch.Tensor,\n    logits_to_keep: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given prompt tensor, it returns all the left padded tokens in that sequence. so [pad, pad, pad, cat] = 3 tokens\n    \"\"\"\n    if logits_to_keep >= input_ids.shape[1]:\n        raise ValueError(\"logits_to_keep must be smaller than the sequence length.\")",
        "detail": "unsloth_compiled_cache.UnslothGKDTrainer",
        "documentation": {}
    },
    {
        "label": "create_completion_attention_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothGKDTrainer",
        "description": "unsloth_compiled_cache.UnslothGKDTrainer",
        "peekOfCode": "def create_completion_attention_mask(\n    completion_input_ids: torch.Tensor,\n    left_pad_tokens_per_prompt: torch.Tensor,\n    max_left_pad: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given that we have a sequence, [p,p,p,c,c,c,pad,pad,pad]\n    Where p are extra prompt tokens we got from slicing the torch tensor, c is completion tokens\n    and pad are pad tokens, this function would make a completion mask that would 0 out the pad",
        "detail": "unsloth_compiled_cache.UnslothGKDTrainer",
        "documentation": {}
    },
    {
        "label": "left_pack_padding",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothGKDTrainer",
        "description": "unsloth_compiled_cache.UnslothGKDTrainer",
        "peekOfCode": "def left_pack_padding(tensor: torch.Tensor, pad_id: int) -> torch.Tensor:\n    \"\"\"\n    Moves all padding tokens in each sequence of a batch to the right.\n    \"\"\"\n    mask = (tensor != pad_id)\n    # Must do stable=True since binary mark is unordered\n    sorted_indices = torch.argsort(mask, dim=1, descending=True, stable=True)\n    packed_tensor = torch.gather(tensor, 1, sorted_indices)\n    return packed_tensor\ndef align_logprobs_with_mask(",
        "detail": "unsloth_compiled_cache.UnslothGKDTrainer",
        "documentation": {}
    },
    {
        "label": "align_logprobs_with_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothGKDTrainer",
        "description": "unsloth_compiled_cache.UnslothGKDTrainer",
        "peekOfCode": "def align_logprobs_with_mask(\n    logprob_tensor: torch.Tensor,\n    attention_mask: torch.Tensor,\n    pad_value: float = 0.0\n) -> torch.Tensor:\n    \"\"\"\n    Aligns a log probability tensor with a given attention mask.\n    \"\"\"\n    device = logprob_tensor.device\n    batch_size, logprob_seq_len = logprob_tensor.shape",
        "detail": "unsloth_compiled_cache.UnslothGKDTrainer",
        "documentation": {}
    },
    {
        "label": "torch_compile_options",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothGKDTrainer",
        "description": "unsloth_compiled_cache.UnslothGKDTrainer",
        "peekOfCode": "torch_compile_options = {\n    \"epilogue_fusion\"   : True,\n    \"max_autotune\"      : False,\n    \"shape_padding\"     : True,\n    \"trace.enabled\"     : False,\n    \"triton.cudagraphs\" : False,\n}\n@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only",
        "detail": "unsloth_compiled_cache.UnslothGKDTrainer",
        "documentation": {}
    },
    {
        "label": "@torch.compile(dynamic",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothGKDTrainer",
        "description": "unsloth_compiled_cache.UnslothGKDTrainer",
        "peekOfCode": "@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)",
        "detail": "unsloth_compiled_cache.UnslothGKDTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothEfficientGRPO",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "description": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "peekOfCode": "class UnslothEfficientGRPO(torch.autograd.Function):\n    # All Unsloth Zoo code licensed under LGPLv3\n    @staticmethod\n    def forward(ctx, _new_hidden_states, _old_hidden_states, _ref_hidden_states, _sampling_per_token_logps, lm_head, _input_ids, _mask, _advantages, beta, scaler = None, n_chunks = 1, extra_kwargs=None):\n        if extra_kwargs is None:\n            extra_kwargs = {}\n        def compute_loss(new_hidden_states, old_hidden_states, ref_hidden_states, sampling_per_token_logps, input_ids, mask, advantages, scaling):\n            new_logits = torch.matmul(new_hidden_states.to(lm_head.dtype), lm_head.t())\n            new_logits = new_logits[:, :-1, :] # exclude the last logit: it corresponds to the next token pred\n            with torch.no_grad():",
        "detail": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothGRPOConfig",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "description": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "peekOfCode": "class UnslothGRPOConfig(GRPOConfig):\n    \"\"\"\n    Configuration class for the [`GRPOTrainer`].\n    This class includes only the parameters that are specific to GRPO training. For a full list of training arguments,\n    please refer to the [`~transformers.TrainingArguments`] documentation. Note that default values in this class may\n    differ from those in [`~transformers.TrainingArguments`].\n    Using [`~transformers.HfArgumentParser`] we can turn this class into\n    [argparse](https://docs.python.org/3/library/argparse#module-argparse) arguments that can be specified on the\n    command line.\n    Parameters:",
        "detail": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "documentation": {}
    },
    {
        "label": "_UnslothGRPOTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "description": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "peekOfCode": "class _UnslothGRPOTrainer(BaseTrainer):\n    \"\"\"\"\"\"\n    _tag_names = [\"trl\", \"grpo\"]\n    _name = \"GRPO\"\n    _paper = {\n        \"title\": \"DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models\",\n        \"id\": \"2402.03300\",\n        # docstyle-ignore\n        \"citation\": textwrap.dedent(\"\"\"\\\n            @article{shao2024deepseekmath,",
        "detail": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothGRPOTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "description": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "peekOfCode": "class UnslothGRPOTrainer(_UnslothGRPOTrainer):\n    \"\"\"\n    Trainer for the Group Relative Policy Optimization (GRPO) method. This algorithm was initially proposed in the\n    paper [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language\n    Models](https://huggingface.co/papers/2402.03300).\n    Example:\n    ```python\n    from datasets import load_dataset\n    from trl import GRPOTrainer\n    dataset = load_dataset(\"trl-lib/tldr\", split=\"train\")",
        "detail": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "documentation": {}
    },
    {
        "label": "prepare_for_training_mode",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "description": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "peekOfCode": "def prepare_for_training_mode(f):\n    @functools.wraps(f)\n    def wrapper(self, *args, **kwargs):\n        # Enable training mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_training\"):\n            self.model.for_training()\n        output = f(self, *args, **kwargs)\n        # Return inference mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_inference\"):\n            self.model.for_inference()",
        "detail": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "documentation": {}
    },
    {
        "label": "chunked_selective_log_softmax",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "description": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "peekOfCode": "def chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)\n        logsumexp_values = torch.logsumexp(chunk_logits, dim = -1)",
        "detail": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "documentation": {}
    },
    {
        "label": "calculate_pad_tokens_in_prompt",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "description": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "peekOfCode": "def calculate_pad_tokens_in_prompt(\n    input_ids: torch.Tensor,\n    logits_to_keep: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given prompt tensor, it returns all the left padded tokens in that sequence. so [pad, pad, pad, cat] = 3 tokens\n    \"\"\"\n    if logits_to_keep >= input_ids.shape[1]:\n        raise ValueError(\"logits_to_keep must be smaller than the sequence length.\")",
        "detail": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "documentation": {}
    },
    {
        "label": "create_completion_attention_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "description": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "peekOfCode": "def create_completion_attention_mask(\n    completion_input_ids: torch.Tensor,\n    left_pad_tokens_per_prompt: torch.Tensor,\n    max_left_pad: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given that we have a sequence, [p,p,p,c,c,c,pad,pad,pad]\n    Where p are extra prompt tokens we got from slicing the torch tensor, c is completion tokens\n    and pad are pad tokens, this function would make a completion mask that would 0 out the pad",
        "detail": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "documentation": {}
    },
    {
        "label": "left_pack_padding",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "description": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "peekOfCode": "def left_pack_padding(tensor: torch.Tensor, pad_id: int) -> torch.Tensor:\n    \"\"\"\n    Moves all padding tokens in each sequence of a batch to the right.\n    \"\"\"\n    mask = (tensor != pad_id)\n    # Must do stable=True since binary mark is unordered\n    sorted_indices = torch.argsort(mask, dim=1, descending=True, stable=True)\n    packed_tensor = torch.gather(tensor, 1, sorted_indices)\n    return packed_tensor\ndef align_logprobs_with_mask(",
        "detail": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "documentation": {}
    },
    {
        "label": "align_logprobs_with_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "description": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "peekOfCode": "def align_logprobs_with_mask(\n    logprob_tensor: torch.Tensor,\n    attention_mask: torch.Tensor,\n    pad_value: float = 0.0\n) -> torch.Tensor:\n    \"\"\"\n    Aligns a log probability tensor with a given attention mask.\n    \"\"\"\n    device = logprob_tensor.device\n    batch_size, logprob_seq_len = logprob_tensor.shape",
        "detail": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "documentation": {}
    },
    {
        "label": "grpo_compute_loss",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "description": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "peekOfCode": "def grpo_compute_loss(\n    ref_logits,\n    new_logits,\n    old_logits,\n    sampling_per_token_logps,\n    input_ids,\n    mask,\n    beta,\n    advantages,\n    **kwargs",
        "detail": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "documentation": {}
    },
    {
        "label": "grpo_accumulated_loss",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "description": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "peekOfCode": "def grpo_accumulated_loss(\n    trainer,\n    input_ids,\n    attention_mask,\n    logits_to_keep,\n    completion_mask,\n    advantages,\n    old_hidden_states,\n    ref_hidden_states,\n    n_chunks = -1,",
        "detail": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "documentation": {}
    },
    {
        "label": "grpo_compute_loss_slow",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "description": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "peekOfCode": "def grpo_compute_loss_slow(\n    ref_logits,\n    new_logits,\n    old_logits,\n    sampling_per_token_logps,\n    input_ids,\n    mask,\n    beta,\n    advantages,\n    **kwargs",
        "detail": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "documentation": {}
    },
    {
        "label": "grpo_update_SamplingParams",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "description": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "peekOfCode": "def grpo_update_SamplingParams(SamplingParams, generation_kwargs, vllm_sampling_params = None):\n    good_sampling_params_keys = inspect.signature(SamplingParams).parameters.keys()\n    # Filter generation_kwargs\n    new_generation_kwargs = {}\n    for key in generation_kwargs.keys():\n        if key in good_sampling_params_keys:\n            new_generation_kwargs[key] = generation_kwargs[key]\n    generation_kwargs = new_generation_kwargs\n    if vllm_sampling_params is not None:\n        for key in good_sampling_params_keys:",
        "detail": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "documentation": {}
    },
    {
        "label": "vLLMSamplingParams",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "description": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "peekOfCode": "def vLLMSamplingParams(**kwargs):\n    from vllm import SamplingParams\n    sampling_params = SamplingParams(**kwargs)\n    sampling_params._set_kwargs = kwargs\n    return sampling_params\n@dataclass\nclass UnslothGRPOConfig(GRPOConfig):\n    \"\"\"\n    Configuration class for the [`GRPOTrainer`].\n    This class includes only the parameters that are specific to GRPO training. For a full list of training arguments,",
        "detail": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "documentation": {}
    },
    {
        "label": "torch_compile_options",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "description": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "peekOfCode": "torch_compile_options = {\n    \"epilogue_fusion\"   : True,\n    \"max_autotune\"      : False,\n    \"shape_padding\"     : True,\n    \"trace.enabled\"     : False,\n    \"triton.cudagraphs\" : False,\n}\n@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only",
        "detail": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "documentation": {}
    },
    {
        "label": "@torch.compile(dynamic",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "description": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "peekOfCode": "@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)",
        "detail": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "documentation": {}
    },
    {
        "label": "@torch.compile(dynamic",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "description": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "peekOfCode": "@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options)\ndef grpo_compute_loss_slow(\n    ref_logits,\n    new_logits,\n    old_logits,\n    sampling_per_token_logps,\n    input_ids,\n    mask,\n    beta,\n    advantages,",
        "detail": "unsloth_compiled_cache.UnslothGRPOTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothKTOConfig",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothKTOTrainer",
        "description": "unsloth_compiled_cache.UnslothKTOTrainer",
        "peekOfCode": "class UnslothKTOConfig(KTOConfig):\n    \"\"\"\n    Configuration class for the [`KTOTrainer`].\n    This class includes only the parameters that are specific to KTO training. For a full list of training arguments,\n    please refer to the [`~transformers.TrainingArguments`] documentation. Note that default values in this class may\n    differ from those in [`~transformers.TrainingArguments`].\n    Using [`~transformers.HfArgumentParser`] we can turn this class into\n    [argparse](https://docs.python.org/3/library/argparse#module-argparse) arguments that can be specified on the\n    command line.\n    Parameters:",
        "detail": "unsloth_compiled_cache.UnslothKTOTrainer",
        "documentation": {}
    },
    {
        "label": "_UnslothKTOTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothKTOTrainer",
        "description": "unsloth_compiled_cache.UnslothKTOTrainer",
        "peekOfCode": "class _UnslothKTOTrainer(BaseTrainer):\n    r\"\"\"\"\"\"\n    _tag_names = [\"trl\", \"kto\"]\n    _name = \"KTO\"\n    _paper = {\n        \"title\": \"KTO: Model Alignment as Prospect Theoretic Optimization\",\n        \"id\": \"2402.01306\",\n        # docstyle-ignore\n        \"citation\": textwrap.dedent(\"\"\"\\\n            @article{ethayarajh2024kto,",
        "detail": "unsloth_compiled_cache.UnslothKTOTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothKTOTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothKTOTrainer",
        "description": "unsloth_compiled_cache.UnslothKTOTrainer",
        "peekOfCode": "class UnslothKTOTrainer(_UnslothKTOTrainer):\n    \"\"\"\n    Initialize KTOTrainer.\n    Args:\n        model ([`~transformers.PreTrainedModel`]):\n            The model to train, preferably an [`~transformers.AutoModelForSequenceClassification`].\n        ref_model ([`PreTrainedModelWrapper`]):\n            Hugging Face transformer model with a casual language modelling head. Used for implicit reward computation\n            and loss. If no reference model is provided, the trainer will create a reference model with the same\n            architecture as the model to be optimized.",
        "detail": "unsloth_compiled_cache.UnslothKTOTrainer",
        "documentation": {}
    },
    {
        "label": "prepare_for_training_mode",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothKTOTrainer",
        "description": "unsloth_compiled_cache.UnslothKTOTrainer",
        "peekOfCode": "def prepare_for_training_mode(f):\n    @functools.wraps(f)\n    def wrapper(self, *args, **kwargs):\n        # Enable training mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_training\"):\n            self.model.for_training()\n        output = f(self, *args, **kwargs)\n        # Return inference mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_inference\"):\n            self.model.for_inference()",
        "detail": "unsloth_compiled_cache.UnslothKTOTrainer",
        "documentation": {}
    },
    {
        "label": "chunked_selective_log_softmax",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothKTOTrainer",
        "description": "unsloth_compiled_cache.UnslothKTOTrainer",
        "peekOfCode": "def chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)\n        logsumexp_values = torch.logsumexp(chunk_logits, dim = -1)",
        "detail": "unsloth_compiled_cache.UnslothKTOTrainer",
        "documentation": {}
    },
    {
        "label": "calculate_pad_tokens_in_prompt",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothKTOTrainer",
        "description": "unsloth_compiled_cache.UnslothKTOTrainer",
        "peekOfCode": "def calculate_pad_tokens_in_prompt(\n    input_ids: torch.Tensor,\n    logits_to_keep: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given prompt tensor, it returns all the left padded tokens in that sequence. so [pad, pad, pad, cat] = 3 tokens\n    \"\"\"\n    if logits_to_keep >= input_ids.shape[1]:\n        raise ValueError(\"logits_to_keep must be smaller than the sequence length.\")",
        "detail": "unsloth_compiled_cache.UnslothKTOTrainer",
        "documentation": {}
    },
    {
        "label": "create_completion_attention_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothKTOTrainer",
        "description": "unsloth_compiled_cache.UnslothKTOTrainer",
        "peekOfCode": "def create_completion_attention_mask(\n    completion_input_ids: torch.Tensor,\n    left_pad_tokens_per_prompt: torch.Tensor,\n    max_left_pad: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given that we have a sequence, [p,p,p,c,c,c,pad,pad,pad]\n    Where p are extra prompt tokens we got from slicing the torch tensor, c is completion tokens\n    and pad are pad tokens, this function would make a completion mask that would 0 out the pad",
        "detail": "unsloth_compiled_cache.UnslothKTOTrainer",
        "documentation": {}
    },
    {
        "label": "left_pack_padding",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothKTOTrainer",
        "description": "unsloth_compiled_cache.UnslothKTOTrainer",
        "peekOfCode": "def left_pack_padding(tensor: torch.Tensor, pad_id: int) -> torch.Tensor:\n    \"\"\"\n    Moves all padding tokens in each sequence of a batch to the right.\n    \"\"\"\n    mask = (tensor != pad_id)\n    # Must do stable=True since binary mark is unordered\n    sorted_indices = torch.argsort(mask, dim=1, descending=True, stable=True)\n    packed_tensor = torch.gather(tensor, 1, sorted_indices)\n    return packed_tensor\ndef align_logprobs_with_mask(",
        "detail": "unsloth_compiled_cache.UnslothKTOTrainer",
        "documentation": {}
    },
    {
        "label": "align_logprobs_with_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothKTOTrainer",
        "description": "unsloth_compiled_cache.UnslothKTOTrainer",
        "peekOfCode": "def align_logprobs_with_mask(\n    logprob_tensor: torch.Tensor,\n    attention_mask: torch.Tensor,\n    pad_value: float = 0.0\n) -> torch.Tensor:\n    \"\"\"\n    Aligns a log probability tensor with a given attention mask.\n    \"\"\"\n    device = logprob_tensor.device\n    batch_size, logprob_seq_len = logprob_tensor.shape",
        "detail": "unsloth_compiled_cache.UnslothKTOTrainer",
        "documentation": {}
    },
    {
        "label": "torch_compile_options",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothKTOTrainer",
        "description": "unsloth_compiled_cache.UnslothKTOTrainer",
        "peekOfCode": "torch_compile_options = {\n    \"epilogue_fusion\"   : True,\n    \"max_autotune\"      : False,\n    \"shape_padding\"     : True,\n    \"trace.enabled\"     : False,\n    \"triton.cudagraphs\" : False,\n}\n@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only",
        "detail": "unsloth_compiled_cache.UnslothKTOTrainer",
        "documentation": {}
    },
    {
        "label": "@torch.compile(dynamic",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothKTOTrainer",
        "description": "unsloth_compiled_cache.UnslothKTOTrainer",
        "peekOfCode": "@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)",
        "detail": "unsloth_compiled_cache.UnslothKTOTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothNashMDConfig",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "description": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "peekOfCode": "class UnslothNashMDConfig(NashMDConfig):\n    \"\"\"\n    Configuration class for the [`NashMDTrainer`].\n    Subclass of [`OnlineDPOConfig`] we can use all its arguments and add the following:\n    Parameters:\n        mixture_coef (`float` or `list[float]`, *optional*, defaults to `0.5`):\n            Logit mixture coefficient for the model and reference model. If a list of floats is provided then the\n            mixture coefficient is selected for each new epoch and the last coefficient is used for the rest of the\n            epochs.\n    \"\"\"",
        "detail": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "documentation": {}
    },
    {
        "label": "_UnslothNashMDTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "description": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "peekOfCode": "class _UnslothNashMDTrainer(OnlineDPOTrainer):\n    \"\"\"\"\"\"\n    _tag_names = [\"trl\", \"nash-md\"]\n    _name = \"Nash-MD\"\n    _paper = {\n        \"title\": \"Nash Learning from Human Feedback\",\n        \"id\": \"2312.00886\",\n        # docstyle-ignore\n        \"citation\": textwrap.dedent(\"\"\"\\\n            @inproceedings{munos2024nash,",
        "detail": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothNashMDTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "description": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "peekOfCode": "class UnslothNashMDTrainer(_UnslothNashMDTrainer):\n    \"\"\"\n    Trainer for the Nash-MD method.\n    It is implemented as a subclass of [`OnlineDPOTrainer`].\n    Args:\n        model ([`~transformers.PreTrainedModel`]):\n            The model to train, preferably an `AutoModelForCausalLM`.\n        ref_model ([`PreTrainedModelWrapper`]):\n            Hugging Face transformer model with a casual language modelling head. Used for implicit reward computation\n            and loss. If no reference model is provided, the trainer will create a reference model with the same",
        "detail": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "documentation": {}
    },
    {
        "label": "prepare_for_training_mode",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "description": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "peekOfCode": "def prepare_for_training_mode(f):\n    @functools.wraps(f)\n    def wrapper(self, *args, **kwargs):\n        # Enable training mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_training\"):\n            self.model.for_training()\n        output = f(self, *args, **kwargs)\n        # Return inference mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_inference\"):\n            self.model.for_inference()",
        "detail": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "documentation": {}
    },
    {
        "label": "chunked_selective_log_softmax",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "description": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "peekOfCode": "def chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)\n        logsumexp_values = torch.logsumexp(chunk_logits, dim = -1)",
        "detail": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "documentation": {}
    },
    {
        "label": "calculate_pad_tokens_in_prompt",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "description": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "peekOfCode": "def calculate_pad_tokens_in_prompt(\n    input_ids: torch.Tensor,\n    logits_to_keep: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given prompt tensor, it returns all the left padded tokens in that sequence. so [pad, pad, pad, cat] = 3 tokens\n    \"\"\"\n    if logits_to_keep >= input_ids.shape[1]:\n        raise ValueError(\"logits_to_keep must be smaller than the sequence length.\")",
        "detail": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "documentation": {}
    },
    {
        "label": "create_completion_attention_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "description": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "peekOfCode": "def create_completion_attention_mask(\n    completion_input_ids: torch.Tensor,\n    left_pad_tokens_per_prompt: torch.Tensor,\n    max_left_pad: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given that we have a sequence, [p,p,p,c,c,c,pad,pad,pad]\n    Where p are extra prompt tokens we got from slicing the torch tensor, c is completion tokens\n    and pad are pad tokens, this function would make a completion mask that would 0 out the pad",
        "detail": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "documentation": {}
    },
    {
        "label": "left_pack_padding",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "description": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "peekOfCode": "def left_pack_padding(tensor: torch.Tensor, pad_id: int) -> torch.Tensor:\n    \"\"\"\n    Moves all padding tokens in each sequence of a batch to the right.\n    \"\"\"\n    mask = (tensor != pad_id)\n    # Must do stable=True since binary mark is unordered\n    sorted_indices = torch.argsort(mask, dim=1, descending=True, stable=True)\n    packed_tensor = torch.gather(tensor, 1, sorted_indices)\n    return packed_tensor\ndef align_logprobs_with_mask(",
        "detail": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "documentation": {}
    },
    {
        "label": "align_logprobs_with_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "description": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "peekOfCode": "def align_logprobs_with_mask(\n    logprob_tensor: torch.Tensor,\n    attention_mask: torch.Tensor,\n    pad_value: float = 0.0\n) -> torch.Tensor:\n    \"\"\"\n    Aligns a log probability tensor with a given attention mask.\n    \"\"\"\n    device = logprob_tensor.device\n    batch_size, logprob_seq_len = logprob_tensor.shape",
        "detail": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "documentation": {}
    },
    {
        "label": "torch_compile_options",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "description": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "peekOfCode": "torch_compile_options = {\n    \"epilogue_fusion\"   : True,\n    \"max_autotune\"      : False,\n    \"shape_padding\"     : True,\n    \"trace.enabled\"     : False,\n    \"triton.cudagraphs\" : False,\n}\n@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only",
        "detail": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "documentation": {}
    },
    {
        "label": "@torch.compile(dynamic",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "description": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "peekOfCode": "@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)",
        "detail": "unsloth_compiled_cache.UnslothNashMDTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothORPOConfig",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothORPOTrainer",
        "description": "unsloth_compiled_cache.UnslothORPOTrainer",
        "peekOfCode": "class UnslothORPOConfig(ORPOConfig):\n    \"\"\"\n    Configuration class for the [`ORPOTrainer`].\n    This class includes only the parameters that are specific to ORPO training. For a full list of training arguments,\n    please refer to the [`~transformers.TrainingArguments`] documentation. Note that default values in this class may\n    differ from those in [`~transformers.TrainingArguments`].\n    Using [`~transformers.HfArgumentParser`] we can turn this class into\n    [argparse](https://docs.python.org/3/library/argparse#module-argparse) arguments that can be specified on the\n    command line.\n    Parameters:",
        "detail": "unsloth_compiled_cache.UnslothORPOTrainer",
        "documentation": {}
    },
    {
        "label": "_UnslothORPOTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothORPOTrainer",
        "description": "unsloth_compiled_cache.UnslothORPOTrainer",
        "peekOfCode": "class _UnslothORPOTrainer(BaseTrainer):\n    r\"\"\"\"\"\"\n    _tag_names = [\"trl\", \"orpo\"]\n    _name = \"ORPO\"\n    _paper = {\n        \"title\": \"ORPO: Monolithic Preference Optimization without Reference Model\",\n        \"id\": \"2403.07691\",\n        # docstyle-ignore\n        \"citation\": textwrap.dedent(\"\"\"\\\n            @article{hong2024orpo,",
        "detail": "unsloth_compiled_cache.UnslothORPOTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothORPOTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothORPOTrainer",
        "description": "unsloth_compiled_cache.UnslothORPOTrainer",
        "peekOfCode": "class UnslothORPOTrainer(_UnslothORPOTrainer):\n    \"\"\"\n    Initialize ORPOTrainer.\n    Args:\n        model ([`~transformers.PreTrainedModel`]):\n            The model to train, preferably an [`~transformers.AutoModelForSequenceClassification`].\n        args ([`ORPOConfig`]):\n            The ORPO config arguments to use for training.\n        data_collator ([`~transformers.DataCollator`]):\n            The data collator to use for training. If None is specified, the default data collator",
        "detail": "unsloth_compiled_cache.UnslothORPOTrainer",
        "documentation": {}
    },
    {
        "label": "prepare_for_training_mode",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothORPOTrainer",
        "description": "unsloth_compiled_cache.UnslothORPOTrainer",
        "peekOfCode": "def prepare_for_training_mode(f):\n    @functools.wraps(f)\n    def wrapper(self, *args, **kwargs):\n        # Enable training mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_training\"):\n            self.model.for_training()\n        output = f(self, *args, **kwargs)\n        # Return inference mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_inference\"):\n            self.model.for_inference()",
        "detail": "unsloth_compiled_cache.UnslothORPOTrainer",
        "documentation": {}
    },
    {
        "label": "chunked_selective_log_softmax",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothORPOTrainer",
        "description": "unsloth_compiled_cache.UnslothORPOTrainer",
        "peekOfCode": "def chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)\n        logsumexp_values = torch.logsumexp(chunk_logits, dim = -1)",
        "detail": "unsloth_compiled_cache.UnslothORPOTrainer",
        "documentation": {}
    },
    {
        "label": "calculate_pad_tokens_in_prompt",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothORPOTrainer",
        "description": "unsloth_compiled_cache.UnslothORPOTrainer",
        "peekOfCode": "def calculate_pad_tokens_in_prompt(\n    input_ids: torch.Tensor,\n    logits_to_keep: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given prompt tensor, it returns all the left padded tokens in that sequence. so [pad, pad, pad, cat] = 3 tokens\n    \"\"\"\n    if logits_to_keep >= input_ids.shape[1]:\n        raise ValueError(\"logits_to_keep must be smaller than the sequence length.\")",
        "detail": "unsloth_compiled_cache.UnslothORPOTrainer",
        "documentation": {}
    },
    {
        "label": "create_completion_attention_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothORPOTrainer",
        "description": "unsloth_compiled_cache.UnslothORPOTrainer",
        "peekOfCode": "def create_completion_attention_mask(\n    completion_input_ids: torch.Tensor,\n    left_pad_tokens_per_prompt: torch.Tensor,\n    max_left_pad: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given that we have a sequence, [p,p,p,c,c,c,pad,pad,pad]\n    Where p are extra prompt tokens we got from slicing the torch tensor, c is completion tokens\n    and pad are pad tokens, this function would make a completion mask that would 0 out the pad",
        "detail": "unsloth_compiled_cache.UnslothORPOTrainer",
        "documentation": {}
    },
    {
        "label": "left_pack_padding",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothORPOTrainer",
        "description": "unsloth_compiled_cache.UnslothORPOTrainer",
        "peekOfCode": "def left_pack_padding(tensor: torch.Tensor, pad_id: int) -> torch.Tensor:\n    \"\"\"\n    Moves all padding tokens in each sequence of a batch to the right.\n    \"\"\"\n    mask = (tensor != pad_id)\n    # Must do stable=True since binary mark is unordered\n    sorted_indices = torch.argsort(mask, dim=1, descending=True, stable=True)\n    packed_tensor = torch.gather(tensor, 1, sorted_indices)\n    return packed_tensor\ndef align_logprobs_with_mask(",
        "detail": "unsloth_compiled_cache.UnslothORPOTrainer",
        "documentation": {}
    },
    {
        "label": "align_logprobs_with_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothORPOTrainer",
        "description": "unsloth_compiled_cache.UnslothORPOTrainer",
        "peekOfCode": "def align_logprobs_with_mask(\n    logprob_tensor: torch.Tensor,\n    attention_mask: torch.Tensor,\n    pad_value: float = 0.0\n) -> torch.Tensor:\n    \"\"\"\n    Aligns a log probability tensor with a given attention mask.\n    \"\"\"\n    device = logprob_tensor.device\n    batch_size, logprob_seq_len = logprob_tensor.shape",
        "detail": "unsloth_compiled_cache.UnslothORPOTrainer",
        "documentation": {}
    },
    {
        "label": "torch_compile_options",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothORPOTrainer",
        "description": "unsloth_compiled_cache.UnslothORPOTrainer",
        "peekOfCode": "torch_compile_options = {\n    \"epilogue_fusion\"   : True,\n    \"max_autotune\"      : False,\n    \"shape_padding\"     : True,\n    \"trace.enabled\"     : False,\n    \"triton.cudagraphs\" : False,\n}\n@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only",
        "detail": "unsloth_compiled_cache.UnslothORPOTrainer",
        "documentation": {}
    },
    {
        "label": "@torch.compile(dynamic",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothORPOTrainer",
        "description": "unsloth_compiled_cache.UnslothORPOTrainer",
        "peekOfCode": "@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)",
        "detail": "unsloth_compiled_cache.UnslothORPOTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothOnlineDPOConfig",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "peekOfCode": "class UnslothOnlineDPOConfig(OnlineDPOConfig):\n    \"\"\"\n    Configuration class for the [`OnlineDPOTrainer`].\n    This class includes only the parameters that are specific to Online DPO training. For a full list of training\n    arguments, please refer to the [`~transformers.TrainingArguments`] documentation. Note that default values in this\n    class may differ from those in [`~transformers.TrainingArguments`].\n    Using [`~transformers.HfArgumentParser`] we can turn this class into\n    [argparse](https://docs.python.org/3/library/argparse#module-argparse) arguments that can be specified on the\n    command line.\n    Parameters:",
        "detail": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "documentation": {}
    },
    {
        "label": "_UnslothOnlineDPOTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "peekOfCode": "class _UnslothOnlineDPOTrainer(BaseTrainer):\n    r\"\"\"\"\"\"\n    _tag_names = [\"trl\", \"online-dpo\"]\n    _name = \"Online DPO\"\n    _paper = {\n        \"title\": \"Direct Language Model Alignment from Online AI Feedback\",\n        \"id\": \"2402.04792\",\n        # docstyle-ignore\n        \"citation\": textwrap.dedent(\"\"\"\\\n            @article{guo2024direct,",
        "detail": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothOnlineDPOTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "peekOfCode": "class UnslothOnlineDPOTrainer(_UnslothOnlineDPOTrainer):\n    \"\"\"\n    Initialize OnlineDPOTrainer.\n    Args:\n        model (`Union[str, nn.Module, PreTrainedModel]`):\n            Model to be trained. Can be either:\n            - A string, being the *model id* of a pretrained model hosted inside a model repo on huggingface.co, or a\n              path to a *directory* containing model weights saved using\n              [`~transformers.PreTrainedModel.save_pretrained`], e.g., `'./my_model_directory/'`. The model is loaded\n              using [`~transformers.AutoModelForCausalLM.from_pretrained`] with the keyword arguments in",
        "detail": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "documentation": {}
    },
    {
        "label": "prepare_for_training_mode",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "peekOfCode": "def prepare_for_training_mode(f):\n    @functools.wraps(f)\n    def wrapper(self, *args, **kwargs):\n        # Enable training mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_training\"):\n            self.model.for_training()\n        output = f(self, *args, **kwargs)\n        # Return inference mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_inference\"):\n            self.model.for_inference()",
        "detail": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "documentation": {}
    },
    {
        "label": "chunked_selective_log_softmax",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "peekOfCode": "def chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)\n        logsumexp_values = torch.logsumexp(chunk_logits, dim = -1)",
        "detail": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "documentation": {}
    },
    {
        "label": "calculate_pad_tokens_in_prompt",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "peekOfCode": "def calculate_pad_tokens_in_prompt(\n    input_ids: torch.Tensor,\n    logits_to_keep: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given prompt tensor, it returns all the left padded tokens in that sequence. so [pad, pad, pad, cat] = 3 tokens\n    \"\"\"\n    if logits_to_keep >= input_ids.shape[1]:\n        raise ValueError(\"logits_to_keep must be smaller than the sequence length.\")",
        "detail": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "documentation": {}
    },
    {
        "label": "create_completion_attention_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "peekOfCode": "def create_completion_attention_mask(\n    completion_input_ids: torch.Tensor,\n    left_pad_tokens_per_prompt: torch.Tensor,\n    max_left_pad: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given that we have a sequence, [p,p,p,c,c,c,pad,pad,pad]\n    Where p are extra prompt tokens we got from slicing the torch tensor, c is completion tokens\n    and pad are pad tokens, this function would make a completion mask that would 0 out the pad",
        "detail": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "documentation": {}
    },
    {
        "label": "left_pack_padding",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "peekOfCode": "def left_pack_padding(tensor: torch.Tensor, pad_id: int) -> torch.Tensor:\n    \"\"\"\n    Moves all padding tokens in each sequence of a batch to the right.\n    \"\"\"\n    mask = (tensor != pad_id)\n    # Must do stable=True since binary mark is unordered\n    sorted_indices = torch.argsort(mask, dim=1, descending=True, stable=True)\n    packed_tensor = torch.gather(tensor, 1, sorted_indices)\n    return packed_tensor\ndef align_logprobs_with_mask(",
        "detail": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "documentation": {}
    },
    {
        "label": "align_logprobs_with_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "peekOfCode": "def align_logprobs_with_mask(\n    logprob_tensor: torch.Tensor,\n    attention_mask: torch.Tensor,\n    pad_value: float = 0.0\n) -> torch.Tensor:\n    \"\"\"\n    Aligns a log probability tensor with a given attention mask.\n    \"\"\"\n    device = logprob_tensor.device\n    batch_size, logprob_seq_len = logprob_tensor.shape",
        "detail": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "documentation": {}
    },
    {
        "label": "vLLMSamplingParams",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "peekOfCode": "def vLLMSamplingParams(**kwargs):\n    from vllm import SamplingParams\n    sampling_params = SamplingParams(**kwargs)\n    sampling_params._set_kwargs = kwargs\n    return sampling_params\n@dataclass\nclass UnslothOnlineDPOConfig(OnlineDPOConfig):\n    \"\"\"\n    Configuration class for the [`OnlineDPOTrainer`].\n    This class includes only the parameters that are specific to Online DPO training. For a full list of training",
        "detail": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "documentation": {}
    },
    {
        "label": "torch_compile_options",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "peekOfCode": "torch_compile_options = {\n    \"epilogue_fusion\"   : True,\n    \"max_autotune\"      : False,\n    \"shape_padding\"     : True,\n    \"trace.enabled\"     : False,\n    \"triton.cudagraphs\" : False,\n}\n@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only",
        "detail": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "documentation": {}
    },
    {
        "label": "@torch.compile(dynamic",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "description": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "peekOfCode": "@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)",
        "detail": "unsloth_compiled_cache.UnslothOnlineDPOTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothPPOConfig",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothPPOTrainer",
        "description": "unsloth_compiled_cache.UnslothPPOTrainer",
        "peekOfCode": "class UnslothPPOConfig(PPOConfig):\n    \"\"\"\n    Configuration class for the [`PPOTrainer`].\n    This class includes only the parameters that are specific to PPO training. For a full list of training arguments,\n    please refer to the [`~transformers.TrainingArguments`] and [`OnPolicyConfig`] documentation. Note that default\n    values in this class may differ from those in [`~transformers.TrainingArguments`].\n    Using [`~transformers.HfArgumentParser`] we can turn this class into\n    [argparse](https://docs.python.org/3/library/argparse#module-argparse) arguments that can be specified on the\n    command line.\n    Parameters:",
        "detail": "unsloth_compiled_cache.UnslothPPOTrainer",
        "documentation": {}
    },
    {
        "label": "_UnslothPPOTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothPPOTrainer",
        "description": "unsloth_compiled_cache.UnslothPPOTrainer",
        "peekOfCode": "class _UnslothPPOTrainer(BaseTrainer):\n    \"\"\"\"\"\"\n    _tag_names = [\"trl\", \"ppo\"]\n    _name = \"PPO\"\n    _paper = {\n        \"title\": \"Fine-Tuning Language Models from Human Preferences\",\n        \"id\": \"1909.08593\",\n        # docstyle-ignore\n        \"citation\": textwrap.dedent(\"\"\"\\\n            @article{mziegler2019fine-tuning,",
        "detail": "unsloth_compiled_cache.UnslothPPOTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothPPOTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothPPOTrainer",
        "description": "unsloth_compiled_cache.UnslothPPOTrainer",
        "peekOfCode": "class UnslothPPOTrainer(_UnslothPPOTrainer):\n    \"\"\"\n    Trainer for Proximal Policy Optimization (PPO).\n    For details on PPO, see the paper: [Proximal Policy Optimization\n    Algorithms](https://huggingface.co/papers/1707.06347).\n    Args:\n        args ([`PPOConfig`]):\n            Training arguments.\n        processing_class ([`~transformers.PreTrainedTokenizerBase`], [`~transformers.BaseImageProcessor`], [`~transformers.FeatureExtractionMixin`] or [`~transformers.ProcessorMixin`]):\n            Class to process the data.",
        "detail": "unsloth_compiled_cache.UnslothPPOTrainer",
        "documentation": {}
    },
    {
        "label": "prepare_for_training_mode",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothPPOTrainer",
        "description": "unsloth_compiled_cache.UnslothPPOTrainer",
        "peekOfCode": "def prepare_for_training_mode(f):\n    @functools.wraps(f)\n    def wrapper(self, *args, **kwargs):\n        # Enable training mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_training\"):\n            self.model.for_training()\n        output = f(self, *args, **kwargs)\n        # Return inference mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_inference\"):\n            self.model.for_inference()",
        "detail": "unsloth_compiled_cache.UnslothPPOTrainer",
        "documentation": {}
    },
    {
        "label": "chunked_selective_log_softmax",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothPPOTrainer",
        "description": "unsloth_compiled_cache.UnslothPPOTrainer",
        "peekOfCode": "def chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)\n        logsumexp_values = torch.logsumexp(chunk_logits, dim = -1)",
        "detail": "unsloth_compiled_cache.UnslothPPOTrainer",
        "documentation": {}
    },
    {
        "label": "calculate_pad_tokens_in_prompt",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothPPOTrainer",
        "description": "unsloth_compiled_cache.UnslothPPOTrainer",
        "peekOfCode": "def calculate_pad_tokens_in_prompt(\n    input_ids: torch.Tensor,\n    logits_to_keep: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given prompt tensor, it returns all the left padded tokens in that sequence. so [pad, pad, pad, cat] = 3 tokens\n    \"\"\"\n    if logits_to_keep >= input_ids.shape[1]:\n        raise ValueError(\"logits_to_keep must be smaller than the sequence length.\")",
        "detail": "unsloth_compiled_cache.UnslothPPOTrainer",
        "documentation": {}
    },
    {
        "label": "create_completion_attention_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothPPOTrainer",
        "description": "unsloth_compiled_cache.UnslothPPOTrainer",
        "peekOfCode": "def create_completion_attention_mask(\n    completion_input_ids: torch.Tensor,\n    left_pad_tokens_per_prompt: torch.Tensor,\n    max_left_pad: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given that we have a sequence, [p,p,p,c,c,c,pad,pad,pad]\n    Where p are extra prompt tokens we got from slicing the torch tensor, c is completion tokens\n    and pad are pad tokens, this function would make a completion mask that would 0 out the pad",
        "detail": "unsloth_compiled_cache.UnslothPPOTrainer",
        "documentation": {}
    },
    {
        "label": "left_pack_padding",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothPPOTrainer",
        "description": "unsloth_compiled_cache.UnslothPPOTrainer",
        "peekOfCode": "def left_pack_padding(tensor: torch.Tensor, pad_id: int) -> torch.Tensor:\n    \"\"\"\n    Moves all padding tokens in each sequence of a batch to the right.\n    \"\"\"\n    mask = (tensor != pad_id)\n    # Must do stable=True since binary mark is unordered\n    sorted_indices = torch.argsort(mask, dim=1, descending=True, stable=True)\n    packed_tensor = torch.gather(tensor, 1, sorted_indices)\n    return packed_tensor\ndef align_logprobs_with_mask(",
        "detail": "unsloth_compiled_cache.UnslothPPOTrainer",
        "documentation": {}
    },
    {
        "label": "align_logprobs_with_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothPPOTrainer",
        "description": "unsloth_compiled_cache.UnslothPPOTrainer",
        "peekOfCode": "def align_logprobs_with_mask(\n    logprob_tensor: torch.Tensor,\n    attention_mask: torch.Tensor,\n    pad_value: float = 0.0\n) -> torch.Tensor:\n    \"\"\"\n    Aligns a log probability tensor with a given attention mask.\n    \"\"\"\n    device = logprob_tensor.device\n    batch_size, logprob_seq_len = logprob_tensor.shape",
        "detail": "unsloth_compiled_cache.UnslothPPOTrainer",
        "documentation": {}
    },
    {
        "label": "torch_compile_options",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothPPOTrainer",
        "description": "unsloth_compiled_cache.UnslothPPOTrainer",
        "peekOfCode": "torch_compile_options = {\n    \"epilogue_fusion\"   : True,\n    \"max_autotune\"      : False,\n    \"shape_padding\"     : True,\n    \"trace.enabled\"     : False,\n    \"triton.cudagraphs\" : False,\n}\n@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only",
        "detail": "unsloth_compiled_cache.UnslothPPOTrainer",
        "documentation": {}
    },
    {
        "label": "@torch.compile(dynamic",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothPPOTrainer",
        "description": "unsloth_compiled_cache.UnslothPPOTrainer",
        "peekOfCode": "@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)",
        "detail": "unsloth_compiled_cache.UnslothPPOTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothPRMConfig",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothPRMTrainer",
        "description": "unsloth_compiled_cache.UnslothPRMTrainer",
        "peekOfCode": "class UnslothPRMConfig(PRMConfig):\n    \"\"\"\n    Configuration class for the [`PRMTrainer`].\n    This class includes only the parameters that are specific to PRM training. For a full list of training arguments,\n    please refer to the [`~transformers.TrainingArguments`] documentation. Note that default values in this class may\n    differ from those in [`~transformers.TrainingArguments`].\n    Using [`~transformers.HfArgumentParser`] we can turn this class into\n    [argparse](https://docs.python.org/3/library/argparse#module-argparse) arguments that can be specified on the\n    command line.\n    Parameters:",
        "detail": "unsloth_compiled_cache.UnslothPRMTrainer",
        "documentation": {}
    },
    {
        "label": "_UnslothPRMTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothPRMTrainer",
        "description": "unsloth_compiled_cache.UnslothPRMTrainer",
        "peekOfCode": "class _UnslothPRMTrainer(BaseTrainer):\n    \"\"\"\"\"\"\n    _tag_names = [\"trl\", \"prm\"]\n    _name = \"PRM\"\n    _paper = {\n        \"title\": \"Solving math word problems with process-and outcome-based feedback\",\n        \"id\": \"2211.14275\",\n        # docstyle-ignore\n        \"citation\": textwrap.dedent(\"\"\"\\\n            @article{uesato2022solving,",
        "detail": "unsloth_compiled_cache.UnslothPRMTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothPRMTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothPRMTrainer",
        "description": "unsloth_compiled_cache.UnslothPRMTrainer",
        "peekOfCode": "class UnslothPRMTrainer(_UnslothPRMTrainer):\n    \"\"\"\n    Initialize PRMTrainer.\n    Args:\n        model ([`~transformers.PreTrainedModel`]):\n            The model to train, preferably an `AutoModelForTokenClassification`.\n        args ([`PRMConfig`]):\n            The arguments to use for training.\n        data_collator ([`~transformers.DataCollator`]):\n            The data collator to use for training. If None is specified, the default data collator",
        "detail": "unsloth_compiled_cache.UnslothPRMTrainer",
        "documentation": {}
    },
    {
        "label": "prepare_for_training_mode",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothPRMTrainer",
        "description": "unsloth_compiled_cache.UnslothPRMTrainer",
        "peekOfCode": "def prepare_for_training_mode(f):\n    @functools.wraps(f)\n    def wrapper(self, *args, **kwargs):\n        # Enable training mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_training\"):\n            self.model.for_training()\n        output = f(self, *args, **kwargs)\n        # Return inference mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_inference\"):\n            self.model.for_inference()",
        "detail": "unsloth_compiled_cache.UnslothPRMTrainer",
        "documentation": {}
    },
    {
        "label": "chunked_selective_log_softmax",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothPRMTrainer",
        "description": "unsloth_compiled_cache.UnslothPRMTrainer",
        "peekOfCode": "def chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)\n        logsumexp_values = torch.logsumexp(chunk_logits, dim = -1)",
        "detail": "unsloth_compiled_cache.UnslothPRMTrainer",
        "documentation": {}
    },
    {
        "label": "calculate_pad_tokens_in_prompt",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothPRMTrainer",
        "description": "unsloth_compiled_cache.UnslothPRMTrainer",
        "peekOfCode": "def calculate_pad_tokens_in_prompt(\n    input_ids: torch.Tensor,\n    logits_to_keep: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given prompt tensor, it returns all the left padded tokens in that sequence. so [pad, pad, pad, cat] = 3 tokens\n    \"\"\"\n    if logits_to_keep >= input_ids.shape[1]:\n        raise ValueError(\"logits_to_keep must be smaller than the sequence length.\")",
        "detail": "unsloth_compiled_cache.UnslothPRMTrainer",
        "documentation": {}
    },
    {
        "label": "create_completion_attention_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothPRMTrainer",
        "description": "unsloth_compiled_cache.UnslothPRMTrainer",
        "peekOfCode": "def create_completion_attention_mask(\n    completion_input_ids: torch.Tensor,\n    left_pad_tokens_per_prompt: torch.Tensor,\n    max_left_pad: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given that we have a sequence, [p,p,p,c,c,c,pad,pad,pad]\n    Where p are extra prompt tokens we got from slicing the torch tensor, c is completion tokens\n    and pad are pad tokens, this function would make a completion mask that would 0 out the pad",
        "detail": "unsloth_compiled_cache.UnslothPRMTrainer",
        "documentation": {}
    },
    {
        "label": "left_pack_padding",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothPRMTrainer",
        "description": "unsloth_compiled_cache.UnslothPRMTrainer",
        "peekOfCode": "def left_pack_padding(tensor: torch.Tensor, pad_id: int) -> torch.Tensor:\n    \"\"\"\n    Moves all padding tokens in each sequence of a batch to the right.\n    \"\"\"\n    mask = (tensor != pad_id)\n    # Must do stable=True since binary mark is unordered\n    sorted_indices = torch.argsort(mask, dim=1, descending=True, stable=True)\n    packed_tensor = torch.gather(tensor, 1, sorted_indices)\n    return packed_tensor\ndef align_logprobs_with_mask(",
        "detail": "unsloth_compiled_cache.UnslothPRMTrainer",
        "documentation": {}
    },
    {
        "label": "align_logprobs_with_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothPRMTrainer",
        "description": "unsloth_compiled_cache.UnslothPRMTrainer",
        "peekOfCode": "def align_logprobs_with_mask(\n    logprob_tensor: torch.Tensor,\n    attention_mask: torch.Tensor,\n    pad_value: float = 0.0\n) -> torch.Tensor:\n    \"\"\"\n    Aligns a log probability tensor with a given attention mask.\n    \"\"\"\n    device = logprob_tensor.device\n    batch_size, logprob_seq_len = logprob_tensor.shape",
        "detail": "unsloth_compiled_cache.UnslothPRMTrainer",
        "documentation": {}
    },
    {
        "label": "torch_compile_options",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothPRMTrainer",
        "description": "unsloth_compiled_cache.UnslothPRMTrainer",
        "peekOfCode": "torch_compile_options = {\n    \"epilogue_fusion\"   : True,\n    \"max_autotune\"      : False,\n    \"shape_padding\"     : True,\n    \"trace.enabled\"     : False,\n    \"triton.cudagraphs\" : False,\n}\n@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only",
        "detail": "unsloth_compiled_cache.UnslothPRMTrainer",
        "documentation": {}
    },
    {
        "label": "@torch.compile(dynamic",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothPRMTrainer",
        "description": "unsloth_compiled_cache.UnslothPRMTrainer",
        "peekOfCode": "@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)",
        "detail": "unsloth_compiled_cache.UnslothPRMTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothRLOOConfig",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "description": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "peekOfCode": "class UnslothRLOOConfig(RLOOConfig):\n    \"\"\"\n    Configuration class for the [`RLOOTrainer`].\n    This class includes only the parameters that are specific to RLOO training. For a full list of training arguments,\n    please refer to the [`~transformers.TrainingArguments`] documentation. Note that default values in this class may\n    differ from those in [`~transformers.TrainingArguments`].\n    Using [`~transformers.HfArgumentParser`] we can turn this class into\n    [argparse](https://docs.python.org/3/library/argparse#module-argparse) arguments that can be specified on the\n    command line.\n    Parameters:",
        "detail": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "documentation": {}
    },
    {
        "label": "_UnslothRLOOTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "description": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "peekOfCode": "class _UnslothRLOOTrainer(BaseTrainer):\n    \"\"\"\"\"\"\n    _tag_names = [\"trl\", \"rloo\"]\n    _name = \"RLOO\"\n    _paper = {\n        \"title\": \"Back to Basics: Revisiting REINFORCE-Style Optimization for Learning from Human Feedback in LLMs\",\n        \"id\": \"2402.14740\",\n        # docstyle-ignore\n        \"citation\": textwrap.dedent(\"\"\"\\\n            @inproceedings{ahmadian2024back,",
        "detail": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothRLOOTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "description": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "peekOfCode": "class UnslothRLOOTrainer(_UnslothRLOOTrainer):\n    \"\"\"\n    Trainer for the Reinforce Leave One Out (RLOO) method. This algorithm was initially proposed in the paper [Back to\n    Basics: Revisiting REINFORCE Style Optimization for Learning from Human Feedback in\n    LLMs](https://huggingface.co/papers/2402.14740).\n    Example:\n    ```python\n    from datasets import load_dataset\n    from trl import RLOOTrainer\n    dataset = load_dataset(\"trl-lib/tldr\", split=\"train\")",
        "detail": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "documentation": {}
    },
    {
        "label": "prepare_for_training_mode",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "description": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "peekOfCode": "def prepare_for_training_mode(f):\n    @functools.wraps(f)\n    def wrapper(self, *args, **kwargs):\n        # Enable training mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_training\"):\n            self.model.for_training()\n        output = f(self, *args, **kwargs)\n        # Return inference mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_inference\"):\n            self.model.for_inference()",
        "detail": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "documentation": {}
    },
    {
        "label": "chunked_selective_log_softmax",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "description": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "peekOfCode": "def chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)\n        logsumexp_values = torch.logsumexp(chunk_logits, dim = -1)",
        "detail": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "documentation": {}
    },
    {
        "label": "calculate_pad_tokens_in_prompt",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "description": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "peekOfCode": "def calculate_pad_tokens_in_prompt(\n    input_ids: torch.Tensor,\n    logits_to_keep: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given prompt tensor, it returns all the left padded tokens in that sequence. so [pad, pad, pad, cat] = 3 tokens\n    \"\"\"\n    if logits_to_keep >= input_ids.shape[1]:\n        raise ValueError(\"logits_to_keep must be smaller than the sequence length.\")",
        "detail": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "documentation": {}
    },
    {
        "label": "create_completion_attention_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "description": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "peekOfCode": "def create_completion_attention_mask(\n    completion_input_ids: torch.Tensor,\n    left_pad_tokens_per_prompt: torch.Tensor,\n    max_left_pad: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given that we have a sequence, [p,p,p,c,c,c,pad,pad,pad]\n    Where p are extra prompt tokens we got from slicing the torch tensor, c is completion tokens\n    and pad are pad tokens, this function would make a completion mask that would 0 out the pad",
        "detail": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "documentation": {}
    },
    {
        "label": "left_pack_padding",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "description": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "peekOfCode": "def left_pack_padding(tensor: torch.Tensor, pad_id: int) -> torch.Tensor:\n    \"\"\"\n    Moves all padding tokens in each sequence of a batch to the right.\n    \"\"\"\n    mask = (tensor != pad_id)\n    # Must do stable=True since binary mark is unordered\n    sorted_indices = torch.argsort(mask, dim=1, descending=True, stable=True)\n    packed_tensor = torch.gather(tensor, 1, sorted_indices)\n    return packed_tensor\ndef align_logprobs_with_mask(",
        "detail": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "documentation": {}
    },
    {
        "label": "align_logprobs_with_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "description": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "peekOfCode": "def align_logprobs_with_mask(\n    logprob_tensor: torch.Tensor,\n    attention_mask: torch.Tensor,\n    pad_value: float = 0.0\n) -> torch.Tensor:\n    \"\"\"\n    Aligns a log probability tensor with a given attention mask.\n    \"\"\"\n    device = logprob_tensor.device\n    batch_size, logprob_seq_len = logprob_tensor.shape",
        "detail": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "documentation": {}
    },
    {
        "label": "vLLMSamplingParams",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "description": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "peekOfCode": "def vLLMSamplingParams(**kwargs):\n    from vllm import SamplingParams\n    sampling_params = SamplingParams(**kwargs)\n    sampling_params._set_kwargs = kwargs\n    return sampling_params\n@dataclass\nclass UnslothRLOOConfig(RLOOConfig):\n    \"\"\"\n    Configuration class for the [`RLOOTrainer`].\n    This class includes only the parameters that are specific to RLOO training. For a full list of training arguments,",
        "detail": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "documentation": {}
    },
    {
        "label": "torch_compile_options",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "description": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "peekOfCode": "torch_compile_options = {\n    \"epilogue_fusion\"   : True,\n    \"max_autotune\"      : False,\n    \"shape_padding\"     : True,\n    \"trace.enabled\"     : False,\n    \"triton.cudagraphs\" : False,\n}\n@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only",
        "detail": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "documentation": {}
    },
    {
        "label": "@torch.compile(dynamic",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "description": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "peekOfCode": "@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)",
        "detail": "unsloth_compiled_cache.UnslothRLOOTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothRewardConfig",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothRewardTrainer",
        "description": "unsloth_compiled_cache.UnslothRewardTrainer",
        "peekOfCode": "class UnslothRewardConfig(RewardConfig):\n    \"\"\"\n    Configuration class for the [`RewardTrainer`].\n    This class includes only the parameters that are specific to Reward training. For a full list of training\n    arguments, please refer to the [`~transformers.TrainingArguments`] documentation. Note that default values in this\n    class may differ from those in [`~transformers.TrainingArguments`].\n    Using [`~transformers.HfArgumentParser`] we can turn this class into\n    [argparse](https://docs.python.org/3/library/argparse#module-argparse) arguments that can be specified on the\n    command line.\n    Parameters:",
        "detail": "unsloth_compiled_cache.UnslothRewardTrainer",
        "documentation": {}
    },
    {
        "label": "_UnslothRewardTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothRewardTrainer",
        "description": "unsloth_compiled_cache.UnslothRewardTrainer",
        "peekOfCode": "class _UnslothRewardTrainer(BaseTrainer):\n    \"\"\"\"\"\"\n    _tag_names = [\"trl\", \"reward-trainer\"]\n    _name = \"Reward\"\n    _template_file = \"rm_model_card.md\"\n    def __init__(\n        self,\n        model: Union[str, PreTrainedModel],\n        args: Optional[RewardConfig] = None,\n        data_collator: Optional[DataCollator] = None,",
        "detail": "unsloth_compiled_cache.UnslothRewardTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothRewardTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothRewardTrainer",
        "description": "unsloth_compiled_cache.UnslothRewardTrainer",
        "peekOfCode": "class UnslothRewardTrainer(_UnslothRewardTrainer):\n    \"\"\"\n    Trainer for Outcome-supervised Reward Models (ORM).\n    This class is a wrapper around the [`~transformers.Trainer`] class and inherits all of its attributes and methods.\n    Example:\n    ```python\n    from trl import RewardTrainer\n    from datasets import load_dataset\n    dataset = load_dataset(\"trl-lib/ultrafeedback_binarized\", split=\"train\")\n    trainer = RewardTrainer(model=\"Qwen/Qwen2.5-0.5B-Instruct\", train_dataset=dataset)",
        "detail": "unsloth_compiled_cache.UnslothRewardTrainer",
        "documentation": {}
    },
    {
        "label": "prepare_for_training_mode",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothRewardTrainer",
        "description": "unsloth_compiled_cache.UnslothRewardTrainer",
        "peekOfCode": "def prepare_for_training_mode(f):\n    @functools.wraps(f)\n    def wrapper(self, *args, **kwargs):\n        # Enable training mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_training\"):\n            self.model.for_training()\n        output = f(self, *args, **kwargs)\n        # Return inference mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_inference\"):\n            self.model.for_inference()",
        "detail": "unsloth_compiled_cache.UnslothRewardTrainer",
        "documentation": {}
    },
    {
        "label": "chunked_selective_log_softmax",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothRewardTrainer",
        "description": "unsloth_compiled_cache.UnslothRewardTrainer",
        "peekOfCode": "def chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)\n        logsumexp_values = torch.logsumexp(chunk_logits, dim = -1)",
        "detail": "unsloth_compiled_cache.UnslothRewardTrainer",
        "documentation": {}
    },
    {
        "label": "calculate_pad_tokens_in_prompt",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothRewardTrainer",
        "description": "unsloth_compiled_cache.UnslothRewardTrainer",
        "peekOfCode": "def calculate_pad_tokens_in_prompt(\n    input_ids: torch.Tensor,\n    logits_to_keep: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given prompt tensor, it returns all the left padded tokens in that sequence. so [pad, pad, pad, cat] = 3 tokens\n    \"\"\"\n    if logits_to_keep >= input_ids.shape[1]:\n        raise ValueError(\"logits_to_keep must be smaller than the sequence length.\")",
        "detail": "unsloth_compiled_cache.UnslothRewardTrainer",
        "documentation": {}
    },
    {
        "label": "create_completion_attention_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothRewardTrainer",
        "description": "unsloth_compiled_cache.UnslothRewardTrainer",
        "peekOfCode": "def create_completion_attention_mask(\n    completion_input_ids: torch.Tensor,\n    left_pad_tokens_per_prompt: torch.Tensor,\n    max_left_pad: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given that we have a sequence, [p,p,p,c,c,c,pad,pad,pad]\n    Where p are extra prompt tokens we got from slicing the torch tensor, c is completion tokens\n    and pad are pad tokens, this function would make a completion mask that would 0 out the pad",
        "detail": "unsloth_compiled_cache.UnslothRewardTrainer",
        "documentation": {}
    },
    {
        "label": "left_pack_padding",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothRewardTrainer",
        "description": "unsloth_compiled_cache.UnslothRewardTrainer",
        "peekOfCode": "def left_pack_padding(tensor: torch.Tensor, pad_id: int) -> torch.Tensor:\n    \"\"\"\n    Moves all padding tokens in each sequence of a batch to the right.\n    \"\"\"\n    mask = (tensor != pad_id)\n    # Must do stable=True since binary mark is unordered\n    sorted_indices = torch.argsort(mask, dim=1, descending=True, stable=True)\n    packed_tensor = torch.gather(tensor, 1, sorted_indices)\n    return packed_tensor\ndef align_logprobs_with_mask(",
        "detail": "unsloth_compiled_cache.UnslothRewardTrainer",
        "documentation": {}
    },
    {
        "label": "align_logprobs_with_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothRewardTrainer",
        "description": "unsloth_compiled_cache.UnslothRewardTrainer",
        "peekOfCode": "def align_logprobs_with_mask(\n    logprob_tensor: torch.Tensor,\n    attention_mask: torch.Tensor,\n    pad_value: float = 0.0\n) -> torch.Tensor:\n    \"\"\"\n    Aligns a log probability tensor with a given attention mask.\n    \"\"\"\n    device = logprob_tensor.device\n    batch_size, logprob_seq_len = logprob_tensor.shape",
        "detail": "unsloth_compiled_cache.UnslothRewardTrainer",
        "documentation": {}
    },
    {
        "label": "torch_compile_options",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothRewardTrainer",
        "description": "unsloth_compiled_cache.UnslothRewardTrainer",
        "peekOfCode": "torch_compile_options = {\n    \"epilogue_fusion\"   : True,\n    \"max_autotune\"      : False,\n    \"shape_padding\"     : True,\n    \"trace.enabled\"     : False,\n    \"triton.cudagraphs\" : False,\n}\n@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only",
        "detail": "unsloth_compiled_cache.UnslothRewardTrainer",
        "documentation": {}
    },
    {
        "label": "@torch.compile(dynamic",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothRewardTrainer",
        "description": "unsloth_compiled_cache.UnslothRewardTrainer",
        "peekOfCode": "@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)",
        "detail": "unsloth_compiled_cache.UnslothRewardTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothSFTConfig",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothSFTTrainer",
        "description": "unsloth_compiled_cache.UnslothSFTTrainer",
        "peekOfCode": "class UnslothSFTConfig(SFTConfig):\n    \"\"\"\n    Configuration class for the [`SFTTrainer`].\n    This class includes only the parameters that are specific to SFT training. For a full list of training arguments,\n    please refer to the [`~transformers.TrainingArguments`] documentation. Note that default values in this class may\n    differ from those in [`~transformers.TrainingArguments`].\n    Using [`~transformers.HfArgumentParser`] we can turn this class into\n    [argparse](https://docs.python.org/3/library/argparse#module-argparse) arguments that can be specified on the\n    command line.\n    Parameters:",
        "detail": "unsloth_compiled_cache.UnslothSFTTrainer",
        "documentation": {}
    },
    {
        "label": "_UnslothSFTTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothSFTTrainer",
        "description": "unsloth_compiled_cache.UnslothSFTTrainer",
        "peekOfCode": "class _UnslothSFTTrainer(BaseTrainer):\n    \"\"\"\"\"\"\n    _tag_names = [\"trl\", \"sft\"]\n    _name = \"SFT\"\n    def __init__(\n        self,\n        model: Union[str, PreTrainedModel],\n        args: Optional[Union[SFTConfig, TrainingArguments]] = None,\n        data_collator: Optional[DataCollator] = None,\n        train_dataset: Optional[Union[Dataset, IterableDataset]] = None,",
        "detail": "unsloth_compiled_cache.UnslothSFTTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothSFTTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothSFTTrainer",
        "description": "unsloth_compiled_cache.UnslothSFTTrainer",
        "peekOfCode": "class UnslothSFTTrainer(_UnslothSFTTrainer):\n    \"\"\"\n    Trainer for Supervised Fine-Tuning (SFT) method.\n    This class is a wrapper around the [`~transformers.Trainer`] class and inherits all of its attributes and methods.\n    Example:\n    ```python\n    from datasets import load_dataset\n    from trl import SFTTrainer\n    dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train[:1%]\")\n    trainer = SFTTrainer(model=\"Qwen/Qwen2-0.5B-Instruct\", train_dataset=dataset)",
        "detail": "unsloth_compiled_cache.UnslothSFTTrainer",
        "documentation": {}
    },
    {
        "label": "prepare_for_training_mode",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothSFTTrainer",
        "description": "unsloth_compiled_cache.UnslothSFTTrainer",
        "peekOfCode": "def prepare_for_training_mode(f):\n    @functools.wraps(f)\n    def wrapper(self, *args, **kwargs):\n        # Enable training mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_training\"):\n            self.model.for_training()\n        output = f(self, *args, **kwargs)\n        # Return inference mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_inference\"):\n            self.model.for_inference()",
        "detail": "unsloth_compiled_cache.UnslothSFTTrainer",
        "documentation": {}
    },
    {
        "label": "chunked_selective_log_softmax",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothSFTTrainer",
        "description": "unsloth_compiled_cache.UnslothSFTTrainer",
        "peekOfCode": "def chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)\n        logsumexp_values = torch.logsumexp(chunk_logits, dim = -1)",
        "detail": "unsloth_compiled_cache.UnslothSFTTrainer",
        "documentation": {}
    },
    {
        "label": "calculate_pad_tokens_in_prompt",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothSFTTrainer",
        "description": "unsloth_compiled_cache.UnslothSFTTrainer",
        "peekOfCode": "def calculate_pad_tokens_in_prompt(\n    input_ids: torch.Tensor,\n    logits_to_keep: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given prompt tensor, it returns all the left padded tokens in that sequence. so [pad, pad, pad, cat] = 3 tokens\n    \"\"\"\n    if logits_to_keep >= input_ids.shape[1]:\n        raise ValueError(\"logits_to_keep must be smaller than the sequence length.\")",
        "detail": "unsloth_compiled_cache.UnslothSFTTrainer",
        "documentation": {}
    },
    {
        "label": "create_completion_attention_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothSFTTrainer",
        "description": "unsloth_compiled_cache.UnslothSFTTrainer",
        "peekOfCode": "def create_completion_attention_mask(\n    completion_input_ids: torch.Tensor,\n    left_pad_tokens_per_prompt: torch.Tensor,\n    max_left_pad: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given that we have a sequence, [p,p,p,c,c,c,pad,pad,pad]\n    Where p are extra prompt tokens we got from slicing the torch tensor, c is completion tokens\n    and pad are pad tokens, this function would make a completion mask that would 0 out the pad",
        "detail": "unsloth_compiled_cache.UnslothSFTTrainer",
        "documentation": {}
    },
    {
        "label": "left_pack_padding",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothSFTTrainer",
        "description": "unsloth_compiled_cache.UnslothSFTTrainer",
        "peekOfCode": "def left_pack_padding(tensor: torch.Tensor, pad_id: int) -> torch.Tensor:\n    \"\"\"\n    Moves all padding tokens in each sequence of a batch to the right.\n    \"\"\"\n    mask = (tensor != pad_id)\n    # Must do stable=True since binary mark is unordered\n    sorted_indices = torch.argsort(mask, dim=1, descending=True, stable=True)\n    packed_tensor = torch.gather(tensor, 1, sorted_indices)\n    return packed_tensor\ndef align_logprobs_with_mask(",
        "detail": "unsloth_compiled_cache.UnslothSFTTrainer",
        "documentation": {}
    },
    {
        "label": "align_logprobs_with_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothSFTTrainer",
        "description": "unsloth_compiled_cache.UnslothSFTTrainer",
        "peekOfCode": "def align_logprobs_with_mask(\n    logprob_tensor: torch.Tensor,\n    attention_mask: torch.Tensor,\n    pad_value: float = 0.0\n) -> torch.Tensor:\n    \"\"\"\n    Aligns a log probability tensor with a given attention mask.\n    \"\"\"\n    device = logprob_tensor.device\n    batch_size, logprob_seq_len = logprob_tensor.shape",
        "detail": "unsloth_compiled_cache.UnslothSFTTrainer",
        "documentation": {}
    },
    {
        "label": "torch_compile_options",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothSFTTrainer",
        "description": "unsloth_compiled_cache.UnslothSFTTrainer",
        "peekOfCode": "torch_compile_options = {\n    \"epilogue_fusion\"   : True,\n    \"max_autotune\"      : False,\n    \"shape_padding\"     : True,\n    \"trace.enabled\"     : False,\n    \"triton.cudagraphs\" : False,\n}\n@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only",
        "detail": "unsloth_compiled_cache.UnslothSFTTrainer",
        "documentation": {}
    },
    {
        "label": "@torch.compile(dynamic",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothSFTTrainer",
        "description": "unsloth_compiled_cache.UnslothSFTTrainer",
        "peekOfCode": "@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)",
        "detail": "unsloth_compiled_cache.UnslothSFTTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothXPOConfig",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothXPOTrainer",
        "description": "unsloth_compiled_cache.UnslothXPOTrainer",
        "peekOfCode": "class UnslothXPOConfig(XPOConfig):\n    \"\"\"\n    Configuration class for the [`XPOTrainer`].\n    Subclass of [`OnlineDPOConfig`] we can use all its arguments and add the following:\n    Parameters:\n        alpha (`float` or `list[float]`, *optional*, defaults to `1e-5`):\n            Weight of the XPO loss term. If a list of floats is provided then the alpha is selected for each new epoch\n            and the last alpha is used for the rest of the epochs.\n    \"\"\"\n    vllm_sampling_params: Optional[Any] = field(",
        "detail": "unsloth_compiled_cache.UnslothXPOTrainer",
        "documentation": {}
    },
    {
        "label": "_UnslothXPOTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothXPOTrainer",
        "description": "unsloth_compiled_cache.UnslothXPOTrainer",
        "peekOfCode": "class _UnslothXPOTrainer(OnlineDPOTrainer):\n    \"\"\"\"\"\"\n    _tag_names = [\"trl\", \"xpo\"]\n    _name = \"XPO\"\n    _paper = {\n        \"title\": \"Exploratory Preference Optimization: Harnessing Implicit Q*-Approximation for Sample-Efficient RLHF\",\n        \"id\": \"2405.21046\",\n        # docstyle-ignore\n        \"citation\": textwrap.dedent(\"\"\"\\\n            @article{jung2024binary,",
        "detail": "unsloth_compiled_cache.UnslothXPOTrainer",
        "documentation": {}
    },
    {
        "label": "UnslothXPOTrainer",
        "kind": 6,
        "importPath": "unsloth_compiled_cache.UnslothXPOTrainer",
        "description": "unsloth_compiled_cache.UnslothXPOTrainer",
        "peekOfCode": "class UnslothXPOTrainer(_UnslothXPOTrainer):\n    \"\"\"\n    Trainer for Exploratory Preference Optimization (XPO).\n    It is implemented as a subclass of [`OnlineDPOTrainer`].\n    Args:\n        model ([`~transformers.PreTrainedModel`]):\n            The model to train, preferably an `AutoModelForCausalLM`.\n        ref_model ([`PreTrainedModelWrapper`]):\n            Hugging Face transformer model with a casual language modelling head. Used for implicit reward computation\n            and loss. If no reference model is provided, the trainer will create a reference model with the same",
        "detail": "unsloth_compiled_cache.UnslothXPOTrainer",
        "documentation": {}
    },
    {
        "label": "prepare_for_training_mode",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothXPOTrainer",
        "description": "unsloth_compiled_cache.UnslothXPOTrainer",
        "peekOfCode": "def prepare_for_training_mode(f):\n    @functools.wraps(f)\n    def wrapper(self, *args, **kwargs):\n        # Enable training mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_training\"):\n            self.model.for_training()\n        output = f(self, *args, **kwargs)\n        # Return inference mode\n        if hasattr(self, 'model') and hasattr(self.model, \"for_inference\"):\n            self.model.for_inference()",
        "detail": "unsloth_compiled_cache.UnslothXPOTrainer",
        "documentation": {}
    },
    {
        "label": "chunked_selective_log_softmax",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothXPOTrainer",
        "description": "unsloth_compiled_cache.UnslothXPOTrainer",
        "peekOfCode": "def chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)\n        logsumexp_values = torch.logsumexp(chunk_logits, dim = -1)",
        "detail": "unsloth_compiled_cache.UnslothXPOTrainer",
        "documentation": {}
    },
    {
        "label": "calculate_pad_tokens_in_prompt",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothXPOTrainer",
        "description": "unsloth_compiled_cache.UnslothXPOTrainer",
        "peekOfCode": "def calculate_pad_tokens_in_prompt(\n    input_ids: torch.Tensor,\n    logits_to_keep: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given prompt tensor, it returns all the left padded tokens in that sequence. so [pad, pad, pad, cat] = 3 tokens\n    \"\"\"\n    if logits_to_keep >= input_ids.shape[1]:\n        raise ValueError(\"logits_to_keep must be smaller than the sequence length.\")",
        "detail": "unsloth_compiled_cache.UnslothXPOTrainer",
        "documentation": {}
    },
    {
        "label": "create_completion_attention_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothXPOTrainer",
        "description": "unsloth_compiled_cache.UnslothXPOTrainer",
        "peekOfCode": "def create_completion_attention_mask(\n    completion_input_ids: torch.Tensor,\n    left_pad_tokens_per_prompt: torch.Tensor,\n    max_left_pad: int,\n    pad_token_id: int\n) -> torch.Tensor:\n    \"\"\"\n    Given that we have a sequence, [p,p,p,c,c,c,pad,pad,pad]\n    Where p are extra prompt tokens we got from slicing the torch tensor, c is completion tokens\n    and pad are pad tokens, this function would make a completion mask that would 0 out the pad",
        "detail": "unsloth_compiled_cache.UnslothXPOTrainer",
        "documentation": {}
    },
    {
        "label": "left_pack_padding",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothXPOTrainer",
        "description": "unsloth_compiled_cache.UnslothXPOTrainer",
        "peekOfCode": "def left_pack_padding(tensor: torch.Tensor, pad_id: int) -> torch.Tensor:\n    \"\"\"\n    Moves all padding tokens in each sequence of a batch to the right.\n    \"\"\"\n    mask = (tensor != pad_id)\n    # Must do stable=True since binary mark is unordered\n    sorted_indices = torch.argsort(mask, dim=1, descending=True, stable=True)\n    packed_tensor = torch.gather(tensor, 1, sorted_indices)\n    return packed_tensor\ndef align_logprobs_with_mask(",
        "detail": "unsloth_compiled_cache.UnslothXPOTrainer",
        "documentation": {}
    },
    {
        "label": "align_logprobs_with_mask",
        "kind": 2,
        "importPath": "unsloth_compiled_cache.UnslothXPOTrainer",
        "description": "unsloth_compiled_cache.UnslothXPOTrainer",
        "peekOfCode": "def align_logprobs_with_mask(\n    logprob_tensor: torch.Tensor,\n    attention_mask: torch.Tensor,\n    pad_value: float = 0.0\n) -> torch.Tensor:\n    \"\"\"\n    Aligns a log probability tensor with a given attention mask.\n    \"\"\"\n    device = logprob_tensor.device\n    batch_size, logprob_seq_len = logprob_tensor.shape",
        "detail": "unsloth_compiled_cache.UnslothXPOTrainer",
        "documentation": {}
    },
    {
        "label": "torch_compile_options",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothXPOTrainer",
        "description": "unsloth_compiled_cache.UnslothXPOTrainer",
        "peekOfCode": "torch_compile_options = {\n    \"epilogue_fusion\"   : True,\n    \"max_autotune\"      : False,\n    \"shape_padding\"     : True,\n    \"trace.enabled\"     : False,\n    \"triton.cudagraphs\" : False,\n}\n@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only",
        "detail": "unsloth_compiled_cache.UnslothXPOTrainer",
        "documentation": {}
    },
    {
        "label": "@torch.compile(dynamic",
        "kind": 5,
        "importPath": "unsloth_compiled_cache.UnslothXPOTrainer",
        "description": "unsloth_compiled_cache.UnslothXPOTrainer",
        "peekOfCode": "@torch.compile(dynamic = True, fullgraph = True, options = torch_compile_options,)\ndef chunked_selective_log_softmax(logits, index):\n    # Split into 4 chunks only\n    chunked_logits = torch.chunk(logits.reshape(-1, logits.shape[-1]), chunks = 4, dim = 0)\n    chunked_index  = torch.chunk(index.reshape(-1), chunks = 4, dim = 0)\n    all_per_token_logps = []\n    # Below loop does the same as selective_log_softmax(chunk_logits, chunk_index)\n    for chunk_logits, chunk_index in zip(chunked_logits, chunked_index):\n        chunk_logits = chunk_logits.to(torch.float32)\n        selected_logits = torch.gather(chunk_logits, dim = -1, index = chunk_index.unsqueeze(-1)).squeeze(-1)",
        "detail": "unsloth_compiled_cache.UnslothXPOTrainer",
        "documentation": {}
    }
]