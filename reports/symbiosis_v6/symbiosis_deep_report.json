{
  "version": "v6",
  "generated_at": "2025-12-25T03:57:54Z",
  "repo_root": "/home/ales27pm/offLLM-1",
  "repo_fingerprint": "git:fb949bd0f181a4a0a2f27d594ad4d16ca79c39e6",
  "config_path": null,
  "indexing_summary": {
    "files_scanned": 368,
    "files_indexed": 323,
    "files_excluded": 45,
    "excluded_patterns": [
      "**/*.sarif",
      "**/*prompt-regression*",
      "**/*prompt-regression*.json",
      "**/*symbiosis*",
      "**/*symbiosis*report*",
      ".cache/**",
      ".git/**",
      ".hg/**",
      ".next/**",
      ".svn/**",
      ".turbo/**",
      ".venv/**",
      "DerivedData/**",
      "Pods/**",
      "__pycache__/**",
      "build/**",
      "dist/**",
      "node_modules/**",
      "reports/**",
      "runs/**",
      "unsloth_compiled_cache/**",
      "venv/**"
    ]
  },
  "indexing": {
    "exclude_dirs": [
      ".cache",
      ".git",
      ".hg",
      ".next",
      ".svn",
      ".turbo",
      ".venv",
      "DerivedData",
      "Pods",
      "__pycache__",
      "build",
      "dist",
      "node_modules",
      "reports",
      "runs",
      "unsloth_compiled_cache",
      "venv"
    ],
    "ignore_globs": [
      "reports/**",
      "runs/**",
      "node_modules/**",
      ".git/**",
      "dist/**",
      "build/**",
      "**/*.sarif",
      "**/*prompt-regression*.json",
      "**/*prompt-regression*",
      "**/*symbiosis*",
      "**/*symbiosis*report*"
    ],
    "files_included": 323,
    "files_excluded": 45
  },
  "totals": {
    "files_seen": 323,
    "text_files_indexed": 323,
    "prompt_signal_files": 19,
    "tool_signal_files": 29,
    "telemetry_signal_files": 36,
    "rag_signal_files": 45,
    "eval_signal_files": 65,
    "ios_signal_files": 63
  },
  "where_to_search": {
    "prompts": [
      "ios/MyOfflineLLMApp/Turbo/LLM.swift",
      "ios/MyOfflineLLMApp/MLX/MLXModule.swift",
      ".vscode/PythonImportHelper-v2-Completion.json",
      "__tests__/promptBuilder.test.js",
      "src/core/AgentOrchestrator.js",
      "src/utils/buildPrompt.ts",
      "src/services/treeOfThought.js",
      "scripts/ci/download-mlx-model.sh",
      "scripts/train_lora.py",
      "src/native/mlx.ts",
      "src/native/MLXModule.ts",
      "scripts/eval/run_prompt_regression.py",
      "docs/codebase-audit.md",
      "MLXModule.swift",
      "__tests__/evalSummary.test.js",
      "src/services/chat/mlxChat.ts",
      "src/hooks/useMlxChat.ts",
      "prompts/v1/runtime_prompt.json",
      "prompts/v1/training_prompt.json"
    ],
    "tools_orchestration": [
      ".vscode/PythonImportHelper-v2-Completion.json",
      "docs/agent-architecture.md",
      "src/core/tools/ToolHandler.js",
      "__tests__/toolRegistry.test.js",
      "package-lock.json",
      "__tests__/toolHandler.test.js",
      "scripts/mlops/telemetry_redaction.py",
      "scripts/eval/golden_prompts.json",
      "src/App.js",
      "src/utils/telemetry.js",
      "__tests__/goldenPrompts.test.js",
      "scripts/mlops/telemetry_to_sft.py",
      "src/core/AgentOrchestrator.js",
      "__tests__/telemetryDatasets.test.js",
      "src/core/tools/ToolRegistry.js",
      "src/core/prompt/PromptBuilder.js",
      "eval/redteam_tool_injection.json",
      "AGENTS.md",
      "src/core/AGENTS.md",
      "src/tools/AGENTS.md",
      "scripts/eval/run_prompt_regression.py",
      "__tests__/promptBuilder.test.js",
      "scripts/train_lora.py",
      "__tests__/telemetry.test.js",
      "schemas/telemetry_event.schema.json",
      "prompts/v1/training_prompt.json",
      "src/architecture/toolSystem.js",
      "docs/telemetry-events.md",
      "prompts/v1/runtime_prompt.json"
    ],
    "telemetry": [
      ".vscode/PythonImportHelper-v2-Completion.json",
      "package-lock.json",
      "docs/telemetry-events.md",
      "scripts/eval/write_eval_summary.py",
      "src/utils/telemetry.js",
      "docs/agent-architecture.md",
      "scripts/mlops/telemetry_to_retrieval_triples.py",
      "__tests__/telemetryDatasets.test.js",
      "scripts/mlops/telemetry_to_sft.py",
      "scripts/mlops/telemetry_to_tool_calls.py",
      "scripts/mlops/telemetry_redaction.py",
      "__tests__/evalSummary.test.js",
      "scripts/mlops/generate_retrieval_pairs.py",
      "scripts/eval/retrieval_eval.py",
      "scripts/eval/export_equivalence.py",
      "android/app/src/main/java/com/mongars/LlamaTurboModule.java",
      "__tests__/telemetry.test.js",
      "src/architecture/AGENTS.md",
      "ios/MyOfflineLLMApp/Turbo/LLM.swift",
      "scripts/offllm_end_to_end_pipeline.py",
      "src/services/treeOfThought.js",
      "AGENTS.md",
      ".github/workflows/offllm_pipeline.yml",
      "docs/codebase-audit.md",
      "src/services/AGENTS.md",
      "schemas/telemetry_event.schema.json",
      "__tests__/telemetryRedaction.test.js",
      "scripts/convert_to_coreml.py",
      "src/core/tools/ToolHandler.js",
      "src/core/AgentOrchestrator.js",
      "tools/AGENTS.md",
      "src/core/AGENTS.md",
      "docs/codebase-audit-20250215.md",
      "src/core/memory/services/Retriever.js",
      "__tests__/deviceUtils.test.js"
    ],
    "retrieval_rag": [
      ".vscode/PythonImportHelper-v2-Completion.json",
      "src/utils/hnswVectorStore.js",
      "scripts/offllm_end_to_end_pipeline.py",
      "android/app/src/main/cpp/llama_jni.cpp",
      "docs/agent-architecture.md",
      "src/utils/sparseAttention.js",
      "scripts/eval/write_eval_summary.py",
      "src/services/contextEngineer.js",
      "scripts/eval/golden_prompts.json",
      "__tests__/hnswVectorStore.test.js",
      "ios/MyOfflineLLMApp/Turbo/LLM.swift",
      "scripts/mlops/telemetry_to_retrieval_triples.py",
      "eval/retrieval_eval.py",
      "__tests__/contextEngineer.test.js",
      "__tests__/evalSummary.test.js",
      "__tests__/vectorMemory.test.js",
      "src/utils/vectorUtils.js",
      "android/app/src/main/java/com/mongars/LlamaTurboModule.java",
      "src/core/AGENTS.md",
      "src/core/memory/services/VectorIndexer.js",
      "src/services/AGENTS.md",
      "docs/telemetry-events.md",
      "src/memory/AGENTS.md",
      "scripts/mlops/llm2vec_train.py",
      "src/core/AgentOrchestrator.js",
      "AGENTS.md",
      ".github/workflows/offllm_pipeline.yml",
      "docs/codebase-audit.md",
      "src/memory/VectorMemory.ts",
      "__tests__/telemetryDatasets.test.js",
      "src/core/memory/services/Retriever.js",
      "scripts/mlops/generate_retrieval_pairs.py",
      "scripts/eval/retrieval_eval.py",
      "src/core/memory/MemoryManager.js",
      "src/utils/telemetry.js"
    ],
    "evaluation": [
      ".vscode/PythonImportHelper-v2-Completion.json",
      "__tests__/AGENTS.md",
      "package-lock.json",
      ".github/workflows/prompt_regression.yml",
      "__tests__/toolHandler.test.js",
      "__tests__/telemetry.test.js",
      "src/services/AGENTS.md",
      "docs/agent-architecture.md",
      ".github/workflows/e2e.yml",
      "src/core/AGENTS.md",
      "src/services/treeOfThought.js",
      "AGENTS.md",
      "scripts/eval/write_eval_summary.py",
      "docs/AGENTS.md",
      "scripts/eval/run_prompt_regression.py",
      "__tests__/machoFatBinary.test.js",
      "src/core/tools/ToolHandler.js",
      "__tests__/buildReport.test.js",
      "__tests__/contextEngineer.test.js",
      "__tests__/evalSummary.test.js",
      "__tests__/vectorMemory.test.js",
      "ci/run_prompt_regression.sh",
      "__tests__/promptBuilder.test.js",
      "package.json",
      "docs/codebase-audit.md",
      "__tests__/deviceUtils.test.js",
      "src/tools/AGENTS.md",
      "scripts/eval/export_equivalence.py",
      "src/architecture/AGENTS.md",
      "__tests__/consents.test.js",
      "__tests__/hnswVectorStore.test.js",
      "__tests__/telemetryRedaction.test.js",
      "src/utils/deviceUtils.js",
      "android/app/src/main/java/com/mongars/LlamaTurboModule.java",
      "__tests__/telemetryDatasets.test.js"
    ],
    "ios_mlx_coreml": [
      ".vscode/PythonImportHelper-v2-Completion.json",
      "project.yml",
      "scripts/ci/check_mlx_bridge.js",
      "scripts/ci/download-mlx-model.sh",
      ".github/workflows/offllm_pipeline.yml",
      "ios/project.yml",
      "scripts/offllm_end_to_end_pipeline.py",
      ".github/workflows/ios-deploy-testflight.yml",
      ".github/workflows/ios-build-signed-ipa.yml",
      "README.md",
      "__tests__/hfRepoDownloader.test.js",
      "ios/scripts/patch-mlx-metal-cxx17.sh",
      "scripts/detect_mlx_symbols.sh",
      "src/App.js",
      "scripts/dev/doctor.sh",
      "ios/MyOfflineLLMApp/Turbo/LLM.swift",
      "ios/MyOfflineLLMApp/MLX/MLXModule.swift",
      "scripts/build-ios-unsigned.sh",
      "scripts/apply_ios_mlx_fixes.sh",
      ".github/workflows/ios-signed-monGARS.yml",
      "scripts/ci/bootstrap_ios.sh",
      "ios/Podfile",
      "scripts/convert_to_coreml.py",
      "scripts/ci/select_xcode_and_ensure_ios.sh",
      "docs/agent-architecture.md",
      "src/utils/hfRepoDownloader.js",
      "eval/export_equivalence.py",
      "scripts/verify-ios-rn-versions.py",
      "src/services/chat/mlxChat.ts",
      "scripts/AGENTS.md",
      "scripts/ci/ensure_ios_platform.sh",
      "scripts/ci/emit_ios_diagnostics_summary.py",
      "scripts/ci/export_ipa.sh",
      "scripts/ci/bootstrap-build.sh",
      "build.sh"
    ],
    "todos_fixmes": [],
    "hot_churn": []
  },
  "prompt_drift_clusters": [
    {
      "signature": "83875f3f535c1be2",
      "count": 1,
      "files": [
        "src/core/AgentOrchestrator.js"
      ],
      "sample_previews": [
        "marker-window@52-59: console.warn(`[Agent] Pruning context (${currentLength} chars)...`);      // Always keep System Prompt (usually first message)     const systemPrompts = context.filter(       (m) => m.role === \"system\" && !m.content.startsWith(\"Observation\""
      ]
    },
    {
      "signature": "8d1eaffc23c7ebb5",
      "count": 1,
      "files": [
        ".vscode/PythonImportHelper-v2-Completion.json"
      ],
      "sample_previews": [
        "marker-window@13679-13686: \"importPath\": \"scripts.offllm_symbiosis_advisor_v4\",         \"description\": \"scripts.offllm_symbiosis_advisor_v4\",         \"peekOfCode\": \"PROMPT_MARKERS = [\\n    \\\"SYSTEM_PROMPT\\\", \\\"system prompt\\\", \\\"You are\\\", \\\"### Instruction\\\", \\\"### "
      ]
    },
    {
      "signature": "9f324b92e6802daf",
      "count": 1,
      "files": [
        ".vscode/PythonImportHelper-v2-Completion.json"
      ],
      "sample_previews": [
        "marker-window@12914-12921: \"importPath\": \"scripts.mlops.offllm_symbiosis_advisor_v4\",         \"description\": \"scripts.mlops.offllm_symbiosis_advisor_v4\",         \"peekOfCode\": \"PROMPT_MARKERS = [\\n    \\\"SYSTEM_PROMPT\\\",\\n    \\\"system prompt\\\",\\n    \\\"You are\\\",\\n    "
      ]
    },
    {
      "signature": "d874e8da8d0fd1df",
      "count": 1,
      "files": [
        "docs/codebase-audit.md"
      ],
      "sample_previews": [
        "marker-window@28-35: ### Prompt routing and tool execution  - `PromptBuilder` normalises tool metadata before injecting it into the system prompt so downstream parsing keeps deterministic ordering and excludes malformed entries.\u3010F:src/core/prompt/PromptBuilder."
      ]
    }
  ],
  "prompt_snippets": [
    {
      "file": "docs/codebase-audit.md",
      "start_line": 28,
      "end_line": 35,
      "kind": "marker-window",
      "preview": "### Prompt routing and tool execution  - `PromptBuilder` normalises tool metadata before injecting it into the system prompt so downstream parsing keeps deterministic ordering and excludes malformed entries.\u3010F:src/core/prompt/PromptBuilder.",
      "sha256": "c277bdb22eec5a8bddc762fd01ffb03b92ee9bbe450517f6cea7b68f6cec4830"
    },
    {
      "file": "src/core/AgentOrchestrator.js",
      "start_line": 52,
      "end_line": 59,
      "kind": "marker-window",
      "preview": "console.warn(`[Agent] Pruning context (${currentLength} chars)...`);      // Always keep System Prompt (usually first message)     const systemPrompts = context.filter(       (m) => m.role === \"system\" && !m.content.startsWith(\"Observation\"",
      "sha256": "14552e98f7b088597b2a3efa8b558d43b93eb829b526bb0950010b89a23c2fa0"
    },
    {
      "file": ".vscode/PythonImportHelper-v2-Completion.json",
      "start_line": 12914,
      "end_line": 12921,
      "kind": "marker-window",
      "preview": "\"importPath\": \"scripts.mlops.offllm_symbiosis_advisor_v4\",         \"description\": \"scripts.mlops.offllm_symbiosis_advisor_v4\",         \"peekOfCode\": \"PROMPT_MARKERS = [\\n    \\\"SYSTEM_PROMPT\\\",\\n    \\\"system prompt\\\",\\n    \\\"You are\\\",\\n    ",
      "sha256": "da8990bde3655e43f06203f538d7a42b696c523f71ad28280f91b3ecdf892d41"
    },
    {
      "file": ".vscode/PythonImportHelper-v2-Completion.json",
      "start_line": 13679,
      "end_line": 13686,
      "kind": "marker-window",
      "preview": "\"importPath\": \"scripts.offllm_symbiosis_advisor_v4\",         \"description\": \"scripts.offllm_symbiosis_advisor_v4\",         \"peekOfCode\": \"PROMPT_MARKERS = [\\n    \\\"SYSTEM_PROMPT\\\", \\\"system prompt\\\", \\\"You are\\\", \\\"### Instruction\\\", \\\"### ",
      "sha256": "5046b314caf6b665d04ab74307ea28fdabd4dc0fa3bfbe094b0bd7bbc12d9236"
    }
  ],
  "elapsed_seconds": 2.484,
  "params": {
    "include_generated": false,
    "max_file_size": 2000000,
    "workers": 32,
    "use_git": true,
    "include_git_churn": false
  },
  "actions": [
    {
      "priority": "high",
      "title": "Unify prompt surfaces into versioned templates",
      "why": "Prompt drift breaks alignment between runtime, fine-tuning, and eval.",
      "next_steps": [
        "Create prompts/v1/*.json and a registry.json (id+version).",
        "Load prompts at runtime by id+version; log prompt_id+version into telemetry.",
        "Add CI lint: fail if new system prompts are added outside registry."
      ],
      "evidence": [
        "ios/MyOfflineLLMApp/Turbo/LLM.swift",
        "ios/MyOfflineLLMApp/MLX/MLXModule.swift",
        ".vscode/PythonImportHelper-v2-Completion.json",
        "__tests__/promptBuilder.test.js",
        "src/core/AgentOrchestrator.js",
        "src/utils/buildPrompt.ts",
        "src/services/treeOfThought.js",
        "scripts/ci/download-mlx-model.sh",
        "scripts/train_lora.py",
        "src/native/mlx.ts",
        "src/native/MLXModule.ts",
        "scripts/eval/run_prompt_regression.py",
        "docs/codebase-audit.md",
        "MLXModule.swift",
        "__tests__/evalSummary.test.js",
        "src/services/chat/mlxChat.ts",
        "src/hooks/useMlxChat.ts",
        "prompts/v1/runtime_prompt.json",
        "prompts/v1/training_prompt.json"
      ]
    },
    {
      "priority": "high",
      "title": "Standardise telemetry schema and redaction",
      "why": "Telemetry is the bridge between what the app did and what the model should learn.",
      "next_steps": [
        "Define an event schema for model interactions.",
        "Centralise PII redaction (emails, tokens, keys).",
        "Implement telemetry\u2192SFT and telemetry\u2192retrieval pairs transforms."
      ],
      "evidence": [
        ".vscode/PythonImportHelper-v2-Completion.json",
        "package-lock.json",
        "docs/telemetry-events.md",
        "scripts/eval/write_eval_summary.py",
        "src/utils/telemetry.js",
        "docs/agent-architecture.md",
        "scripts/mlops/telemetry_to_retrieval_triples.py",
        "__tests__/telemetryDatasets.test.js",
        "scripts/mlops/telemetry_to_sft.py",
        "scripts/mlops/telemetry_to_tool_calls.py",
        "scripts/mlops/telemetry_redaction.py",
        "__tests__/evalSummary.test.js",
        "scripts/mlops/generate_retrieval_pairs.py",
        "scripts/eval/retrieval_eval.py",
        "scripts/eval/export_equivalence.py",
        "android/app/src/main/java/com/mongars/LlamaTurboModule.java",
        "__tests__/telemetry.test.js",
        "src/architecture/AGENTS.md",
        "ios/MyOfflineLLMApp/Turbo/LLM.swift",
        "scripts/offllm_end_to_end_pipeline.py"
      ]
    },
    {
      "priority": "med",
      "title": "Isolate retrieval + chunking into a single library surface",
      "why": "Stable chunking/embedding settings prevent offline vs runtime mismatch.",
      "next_steps": [
        "Extract chunking rules into one module with golden tests.",
        "Log retrieval traces into telemetry.",
        "Train embeddings/LLM2Vec with the same chunk distribution used at runtime."
      ],
      "evidence": [
        ".vscode/PythonImportHelper-v2-Completion.json",
        "src/utils/hnswVectorStore.js",
        "scripts/offllm_end_to_end_pipeline.py",
        "android/app/src/main/cpp/llama_jni.cpp",
        "docs/agent-architecture.md",
        "src/utils/sparseAttention.js",
        "scripts/eval/write_eval_summary.py",
        "src/services/contextEngineer.js",
        "scripts/eval/golden_prompts.json",
        "__tests__/hnswVectorStore.test.js",
        "ios/MyOfflineLLMApp/Turbo/LLM.swift",
        "scripts/mlops/telemetry_to_retrieval_triples.py",
        "eval/retrieval_eval.py",
        "__tests__/contextEngineer.test.js",
        "__tests__/evalSummary.test.js",
        "__tests__/vectorMemory.test.js",
        "src/utils/vectorUtils.js",
        "android/app/src/main/java/com/mongars/LlamaTurboModule.java",
        "src/core/AGENTS.md",
        "src/core/memory/services/VectorIndexer.js"
      ]
    },
    {
      "priority": "high",
      "title": "Make evaluation first-class (golden set + regression gates)",
      "why": "Fine-tuning without a regression gate is just vibe-training.",
      "next_steps": [
        "Create a golden eval suite: tool parsing, JSON validity, groundedness/citations, refusal correctness.",
        "Add an offline eval CLI and a CI job that blocks regressions.",
        "Version eval cases alongside prompt templates."
      ],
      "evidence": [
        ".vscode/PythonImportHelper-v2-Completion.json",
        "__tests__/AGENTS.md",
        "package-lock.json",
        ".github/workflows/prompt_regression.yml",
        "__tests__/toolHandler.test.js",
        "__tests__/telemetry.test.js",
        "src/services/AGENTS.md",
        "docs/agent-architecture.md",
        ".github/workflows/e2e.yml",
        "src/core/AGENTS.md",
        "src/services/treeOfThought.js",
        "AGENTS.md",
        "scripts/eval/write_eval_summary.py",
        "docs/AGENTS.md",
        "scripts/eval/run_prompt_regression.py",
        "__tests__/machoFatBinary.test.js",
        "src/core/tools/ToolHandler.js",
        "__tests__/buildReport.test.js",
        "__tests__/contextEngineer.test.js",
        "__tests__/evalSummary.test.js"
      ]
    },
    {
      "priority": "med",
      "title": "Harden tool-calling boundaries and injection resistance",
      "why": "Tool-calling is the highest-risk surface; harden and train for safe behaviour.",
      "next_steps": [
        "Validate tool args against JSON schema before execution.",
        "Capability-based allowlists.",
        "Add red-team eval set: injection, schema smuggling, exfil attempts."
      ],
      "evidence": [
        ".vscode/PythonImportHelper-v2-Completion.json",
        "docs/agent-architecture.md",
        "src/core/tools/ToolHandler.js",
        "__tests__/toolRegistry.test.js",
        "package-lock.json",
        "__tests__/toolHandler.test.js",
        "scripts/mlops/telemetry_redaction.py",
        "scripts/eval/golden_prompts.json",
        "src/App.js",
        "src/utils/telemetry.js",
        "__tests__/goldenPrompts.test.js",
        "scripts/mlops/telemetry_to_sft.py",
        "src/core/AgentOrchestrator.js",
        "__tests__/telemetryDatasets.test.js",
        "src/core/tools/ToolRegistry.js",
        "src/core/prompt/PromptBuilder.js",
        "eval/redteam_tool_injection.json",
        "AGENTS.md",
        "src/core/AGENTS.md",
        "src/tools/AGENTS.md"
      ]
    }
  ]
}