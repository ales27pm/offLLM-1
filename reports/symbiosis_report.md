# offLLM Symbiosis Report

- Generated: **2025-12-22T00:30:52.336788Z**
- Repo root: `/home/ales27pm/offLLM-1`
- Repo fingerprint: `81a450b9658f9ad3dade279b273181af7eca504f`

## Totals

- **files_seen**: 411
- **text_files_indexed**: 341
- **prompt_signal_files**: 35
- **tool_signal_files**: 35
- **telemetry_signal_files**: 35
- **rag_signal_files**: 35
- **eval_signal_files**: 35
- **ios_signal_files**: 35

## Where to search

### Prompts

- `reports/build-log.txt`
- `reports/archive-result.json`
- `reports/ResultBundle_unsigned.json`
- `package-lock.json`
- `runs/scad/20251221_191939/scad_report.json`
- `runs/scad/20251221_162349/scad_report.json`
- `runs/scad/20251221_161858/scad_report.json`
- `runs/scad/20251221_161242/scad_report.json`
- `runs/scad/20251221_160110/scad_report.json`
- `package.json`
- `ios/Podfile`
- `ios/MyOfflineLLMApp/Turbo/LLM+Turbo.mm`
- `ios/MyOfflineLLMApp/AppDelegate.mm`
- `android/app/src/main/java/com/mongars/MonGarsPackage.java`
- `android/app/src/main/java/com/mongars/LlamaTurboModule.java`
- `android/app/src/main/java/com/mongars/LocationTurboModule.java`
- `android/app/src/main/java/com/mongars/ContactsTurboModule.java`
- `scripts/offllm_symbiosis_advisor_v4.py`
- `scripts/mlops/offllm_symbiosis_advisor_v4.py`
- `scripts/train_lora.py`
- `android/app/src/main/java/com/mongars/CallTurboModule.java`
- `android/app/src/main/java/com/mongars/MapsTurboModule.java`
- `android/app/src/main/java/com/mongars/DeviceInfoTurboModule.java`
- `android/app/src/main/java/com/mongars/CalendarTurboModule.java`
- `android/app/src/main/java/com/mongars/SensorsTurboModule.java`
- … and 10 more

### Tools / Orchestration

- `reports/build-log.txt`
- `runs/scad/20251221_191939/scad_report.json`
- `runs/scad/20251221_162349/scad_report.json`
- `runs/scad/20251221_161858/scad_report.json`
- `runs/scad/20251221_161242/scad_report.json`
- `runs/scad/20251221_160110/scad_report.json`
- `package-lock.json`
- `__tests__/promptBuilder.test.js`
- `src/core/tools/ToolRegistry.js`
- `src/App.js`
- `scripts/offllm_symbiosis_advisor_v4.py`
- `scripts/mlops/offllm_symbiosis_advisor_v4.py`
- `runs/20251221_162349/sft/tokenizer.json`
- `runs/20251221_162349/sft/checkpoint-800/tokenizer.json`
- `runs/20251221_162349/sft/checkpoint-600/tokenizer.json`
- `docs/agent-architecture.md`
- `src/architecture/toolSystem.js`
- `__tests__/toolHandler.test.js`
- `AGENTS.md`
- `src/core/AgentOrchestrator.js`
- `src/tools/AGENTS.md`
- `scripts/mlops/telemetry_to_sft.py`
- `__tests__/toolRegistry.test.js`
- `scripts/offllm_end_to_end_pipeline.py`
- `src/core/AGENTS.md`
- … and 10 more

### Telemetry

- `runs/scad/20251221_191939/scad_report.json`
- `runs/scad/20251221_162349/scad_report.json`
- `runs/scad/20251221_161858/scad_report.json`
- `runs/scad/20251221_161242/scad_report.json`
- `runs/scad/20251221_160110/scad_report.json`
- `unsloth_compiled_cache/UnslothKTOTrainer.py`
- `unsloth_compiled_cache/UnslothBCOTrainer.py`
- `unsloth_compiled_cache/UnslothORPOTrainer.py`
- `unsloth_compiled_cache/UnslothDPOTrainer.py`
- `unsloth_compiled_cache/UnslothCPOTrainer.py`
- `unsloth_compiled_cache/UnslothGRPOTrainer.py`
- `unsloth_compiled_cache/UnslothRewardTrainer.py`
- `unsloth_compiled_cache/UnslothPPOTrainer.py`
- `unsloth_compiled_cache/UnslothRLOOTrainer.py`
- `unsloth_compiled_cache/UnslothOnlineDPOTrainer.py`
- `unsloth_compiled_cache/UnslothSFTTrainer.py`
- `scripts/offllm_symbiosis_advisor_v4.py`
- `scripts/mlops/offllm_symbiosis_advisor_v4.py`
- `runs/20251221_162349/sft/tokenizer.json`
- `runs/20251221_162349/sft/checkpoint-800/tokenizer.json`
- `runs/20251221_162349/sft/checkpoint-600/tokenizer.json`
- `unsloth_compiled_cache/UnslothPRMTrainer.py`
- `package-lock.json`
- `unsloth_compiled_cache/UnslothXPOTrainer.py`
- `unsloth_compiled_cache/UnslothNashMDTrainer.py`
- … and 10 more

### Retrieval / RAG

- `unsloth_compiled_cache/UnslothBCOTrainer.py`
- `unsloth_compiled_cache/UnslothGRPOTrainer.py`
- `src/utils/sparseAttention.js`
- `src/utils/hnswVectorStore.js`
- `src/services/contextEngineer.js`
- `runs/scad/20251221_191939/scad_report.json`
- `runs/scad/20251221_162349/scad_report.json`
- `runs/scad/20251221_161858/scad_report.json`
- `runs/scad/20251221_161242/scad_report.json`
- `runs/scad/20251221_160110/scad_report.json`
- `scripts/offllm_symbiosis_advisor_v4.py`
- `scripts/mlops/offllm_symbiosis_advisor_v4.py`
- `scripts/offllm_end_to_end_pipeline.py`
- `unsloth_compiled_cache/UnslothKTOTrainer.py`
- `unsloth_compiled_cache/UnslothDPOTrainer.py`
- `runs/20251221_162349/sft/tokenizer.json`
- `runs/20251221_162349/sft/checkpoint-800/tokenizer.json`
- `runs/20251221_162349/sft/checkpoint-600/tokenizer.json`
- `unsloth_compiled_cache/UnslothRewardTrainer.py`
- `unsloth_compiled_cache/UnslothSFTTrainer.py`
- `unsloth_compiled_cache/UnslothORPOTrainer.py`
- `unsloth_compiled_cache/UnslothGKDTrainer.py`
- `unsloth_compiled_cache/UnslothCPOTrainer.py`
- `unsloth_compiled_cache/UnslothRLOOTrainer.py`
- `scripts/offllm_symbiosis_advisor_v3.py`
- … and 10 more

### Evaluation

- `runs/scad/20251221_191939/scad_report.json`
- `runs/scad/20251221_162349/scad_report.json`
- `runs/scad/20251221_161858/scad_report.json`
- `runs/scad/20251221_161242/scad_report.json`
- `runs/scad/20251221_160110/scad_report.json`
- `unsloth_compiled_cache/UnslothKTOTrainer.py`
- `unsloth_compiled_cache/UnslothBCOTrainer.py`
- `unsloth_compiled_cache/UnslothDPOTrainer.py`
- `unsloth_compiled_cache/UnslothOnlineDPOTrainer.py`
- `unsloth_compiled_cache/UnslothCPOTrainer.py`
- `unsloth_compiled_cache/UnslothORPOTrainer.py`
- `unsloth_compiled_cache/UnslothRLOOTrainer.py`
- `unsloth_compiled_cache/UnslothPPOTrainer.py`
- `unsloth_compiled_cache/UnslothNashMDTrainer.py`
- `unsloth_compiled_cache/UnslothGRPOTrainer.py`
- `unsloth_compiled_cache/UnslothRewardTrainer.py`
- `unsloth_compiled_cache/UnslothXPOTrainer.py`
- `unsloth_compiled_cache/UnslothSFTTrainer.py`
- `unsloth_compiled_cache/UnslothPRMTrainer.py`
- `unsloth_compiled_cache/UnslothGKDTrainer.py`
- `runs/20251221_162349/sft/checkpoint-800/trainer_state.json`
- `scripts/offllm_symbiosis_advisor_v4.py`
- `scripts/mlops/offllm_symbiosis_advisor_v4.py`
- `runs/20251221_162349/sft/checkpoint-600/trainer_state.json`
- `runs/20251221_162349/sft/tokenizer.json`
- … and 10 more

### iOS / MLX / CoreML

- `reports/build-log.txt`
- `scripts/offllm_end_to_end_pipeline.py`
- `runs/20251221_162349/sft/tokenizer.json`
- `runs/20251221_162349/sft/checkpoint-800/tokenizer.json`
- `runs/20251221_162349/sft/checkpoint-600/tokenizer.json`
- `scripts/ci/check_mlx_bridge.js`
- `.github/workflows/offllm_pipeline.yml`
- `runs/scad/20251221_191939/scad_report.json`
- `runs/scad/20251221_162349/scad_report.json`
- `runs/scad/20251221_161858/scad_report.json`
- `runs/scad/20251221_161242/scad_report.json`
- `runs/scad/20251221_160110/scad_report.json`
- `__tests__/hfRepoDownloader.test.js`
- `reports/archive-result.json`
- `reports/ResultBundle_unsigned.json`
- `scripts/dev/doctor.sh`
- `scripts/ci/select_xcode_and_ensure_ios.sh`
- `project.yml`
- `.github/workflows/ios-deploy-testflight.yml`
- `scripts/ci/select_xcode.sh`
- `scripts/ci/download-mlx-model.sh`
- `.github/workflows/ios-build-signed-ipa.yml`
- `ios/project.yml`
- `README.md`
- `scripts/convert_to_coreml.py`
- … and 10 more

### Security

- `reports/build-log.txt`
- `runs/20251221_162349/sft/tokenizer.json`
- `runs/20251221_162349/sft/checkpoint-800/tokenizer.json`
- `runs/20251221_162349/sft/checkpoint-600/tokenizer.json`
- `unsloth_compiled_cache/UnslothGRPOTrainer.py`
- `unsloth_compiled_cache/UnslothDPOTrainer.py`
- `unsloth_compiled_cache/UnslothORPOTrainer.py`
- `unsloth_compiled_cache/UnslothCPOTrainer.py`
- `unsloth_compiled_cache/UnslothOnlineDPOTrainer.py`
- `runs/20251221_162349/sft/tokenizer_config.json`
- `runs/20251221_162349/sft/checkpoint-800/tokenizer_config.json`
- `runs/20251221_162349/sft/checkpoint-600/tokenizer_config.json`
- `unsloth_compiled_cache/UnslothRLOOTrainer.py`
- `unsloth_compiled_cache/UnslothSFTTrainer.py`
- `unsloth_compiled_cache/UnslothRewardTrainer.py`
- `runs/20251221_162349/sft/checkpoint-800/trainer_state.json`
- `unsloth_compiled_cache/UnslothBCOTrainer.py`
- `unsloth_compiled_cache/UnslothKTOTrainer.py`
- `ios/Podfile`
- `unsloth_compiled_cache/UnslothPPOTrainer.py`
- `runs/20251221_162349/sft/checkpoint-600/trainer_state.json`
- `unsloth_compiled_cache/UnslothGKDTrainer.py`
- `unsloth_compiled_cache/UnslothPRMTrainer.py`
- `unsloth_compiled_cache/UnslothXPOTrainer.py`
- `package-lock.json`
- … and 10 more

## Refactor findings

### Unify prompt surfaces into versioned templates (high)

**Why:** Multiple prompt definitions scattered across the repo tend to drift. Drift breaks fine-tuning, evaluation, and runtime behaviour alignment.
**Where:**

- `reports/build-log.txt`
- `reports/archive-result.json`
- `reports/ResultBundle_unsigned.json`
- `package-lock.json`
- `runs/scad/20251221_191939/scad_report.json`
- `runs/scad/20251221_162349/scad_report.json`
- `runs/scad/20251221_161858/scad_report.json`
- `runs/scad/20251221_161242/scad_report.json`
- `runs/scad/20251221_160110/scad_report.json`
- `package.json`
- `ios/Podfile`
- `ios/MyOfflineLLMApp/Turbo/LLM+Turbo.mm`
  **Suggested actions:**
- Create a single prompt-template registry (e.g. prompts/v1/\*.json) with explicit versioning.
- Have runtime load prompts by ID+version; log prompt_id+version into telemetry for every generation.
- Add a lint step that fails CI if new hardcoded system prompts are added outside the registry.

### Standardise telemetry schema and redaction (high)

**Why:** Telemetry is the bridge between 'what the app did' and 'what the model should learn'. Without stable schema + redaction, you can't safely build SFT/RAG datasets from real usage.
**Where:**

- `runs/scad/20251221_191939/scad_report.json`
- `runs/scad/20251221_162349/scad_report.json`
- `runs/scad/20251221_161858/scad_report.json`
- `runs/scad/20251221_161242/scad_report.json`
- `runs/scad/20251221_160110/scad_report.json`
- `unsloth_compiled_cache/UnslothKTOTrainer.py`
- `unsloth_compiled_cache/UnslothBCOTrainer.py`
- `unsloth_compiled_cache/UnslothORPOTrainer.py`
- `unsloth_compiled_cache/UnslothDPOTrainer.py`
- `unsloth_compiled_cache/UnslothCPOTrainer.py`
- `unsloth_compiled_cache/UnslothGRPOTrainer.py`
- `unsloth_compiled_cache/UnslothRewardTrainer.py`
  **Suggested actions:**
- Define an event schema (JSON Schema / zod) for model interactions: input, output, tool_calls, latencies, errors.
- Centralise PII redaction: strip secrets, emails, keys; hash stable identifiers.
- Write telemetry→datasets transforms: telemetry→SFT JSONL, telemetry→retrieval pairs, telemetry→eval cases.

### Isolate retrieval and chunking into a single library surface (med)

**Why:** Retrieval quality depends on stable chunking and embedding settings. Scattered implementations cause mismatch between offline indexing and runtime retrieval.
**Where:**

- `unsloth_compiled_cache/UnslothBCOTrainer.py`
- `unsloth_compiled_cache/UnslothGRPOTrainer.py`
- `src/utils/sparseAttention.js`
- `src/utils/hnswVectorStore.js`
- `src/services/contextEngineer.js`
- `runs/scad/20251221_191939/scad_report.json`
- `runs/scad/20251221_162349/scad_report.json`
- `runs/scad/20251221_161858/scad_report.json`
- `runs/scad/20251221_161242/scad_report.json`
- `runs/scad/20251221_160110/scad_report.json`
- `scripts/offllm_symbiosis_advisor_v4.py`
- `scripts/mlops/offllm_symbiosis_advisor_v4.py`
  **Suggested actions:**
- Extract chunking rules into one module with golden tests (same input → same chunks).
- Log retrieval traces into telemetry (query, top-k ids, scores, reranker decisions).
- Train embeddings/LLM2Vec using the same chunk distribution you use at runtime.

### Make evaluation first-class (golden set + regression gates) (high)

**Why:** Fine-tuning without a regression gate is just vibe-training. A small but strict eval harness catches prompt drift and tool regressions early.
**Where:**

- `runs/scad/20251221_191939/scad_report.json`
- `runs/scad/20251221_162349/scad_report.json`
- `runs/scad/20251221_161858/scad_report.json`
- `runs/scad/20251221_161242/scad_report.json`
- `runs/scad/20251221_160110/scad_report.json`
- `unsloth_compiled_cache/UnslothKTOTrainer.py`
- `unsloth_compiled_cache/UnslothBCOTrainer.py`
- `unsloth_compiled_cache/UnslothDPOTrainer.py`
- `unsloth_compiled_cache/UnslothOnlineDPOTrainer.py`
- `unsloth_compiled_cache/UnslothCPOTrainer.py`
- `unsloth_compiled_cache/UnslothORPOTrainer.py`
- `unsloth_compiled_cache/UnslothRLOOTrainer.py`
  **Suggested actions:**
- Create a golden eval suite: tool parsing, JSON validity, citation behaviour, refusal correctness.
- Add offline eval CLI and a CI job that runs it on every PR.
- Version eval cases alongside prompt templates; tie eval metrics to releases.

### Harden tool-calling boundaries and injection resistance (med)

**Why:** Tool-calling is the highest-risk surface. Harden parsing, allowlists, and sandboxing. Then fine-tune specifically on tool-safe behaviours and refusal patterns.
**Where:**

- `reports/build-log.txt`
- `runs/scad/20251221_191939/scad_report.json`
- `runs/scad/20251221_162349/scad_report.json`
- `runs/scad/20251221_161858/scad_report.json`
- `runs/scad/20251221_161242/scad_report.json`
- `runs/scad/20251221_160110/scad_report.json`
- `package-lock.json`
- `__tests__/promptBuilder.test.js`
- `reports/build-log.txt`
- `runs/20251221_162349/sft/tokenizer.json`
- `runs/20251221_162349/sft/checkpoint-800/tokenizer.json`
- `runs/20251221_162349/sft/checkpoint-600/tokenizer.json`
  **Suggested actions:**
- Enforce JSON schema validation for tool arguments before execution.
- Add allowlist + capability-based tool routing (tools exposed depend on context).
- Add a red-team eval set: prompt injection, data exfil attempts, schema smuggling.

### Pay down TODO/FIXME hotspots that sit on critical paths (low)

**Why:** TODOs in orchestration, retrieval, and export paths tend to become latent production bugs.
**Where:**

- `runs/20251221_162349/sft/checkpoint-600/tokenizer.json`
- `runs/20251221_162349/sft/checkpoint-800/tokenizer.json`
- `runs/20251221_162349/sft/tokenizer.json`
- `scripts/mlops/offllm_symbiosis_advisor_v4.py`
- `scripts/offllm_symbiosis_advisor_v4.py`
- `unsloth_compiled_cache/UnslothBCOTrainer.py`
- `unsloth_compiled_cache/UnslothCPOTrainer.py`
- `unsloth_compiled_cache/UnslothDPOTrainer.py`
- `unsloth_compiled_cache/UnslothGKDTrainer.py`
- `unsloth_compiled_cache/UnslothGRPOTrainer.py`
- `unsloth_compiled_cache/UnslothKTOTrainer.py`
- `unsloth_compiled_cache/UnslothNashMDTrainer.py`
  **Suggested actions:**
- Classify TODOs: (a) correctness, (b) perf, (c) security, (d) UX; then address in that order.
- Convert top TODOs into tracked issues with acceptance tests.

## Fine-tuning axes (code + model symbiosis)

### Tool calling & JSON robustness

- **Goal:** Valid tool JSON, correct tool selection, safe refusal when schema cannot be satisfied.
- **Dataset sources:**
  - telemetry: tool_calls + outcomes
  - code: tool schemas + handlers
- **Evals:**
  - tool-json-validity@k
  - tool-selection-accuracy
  - refusal-correctness
- **Notes:** Train with 'observations' (tool results) to prevent the model from hallucinating tool outputs. Include negative examples where tool args are malicious or invalid.

### Retrieval-aware answering (RAG discipline)

- **Goal:** Use retrieved context correctly; cite, quote minimally, and say 'I don't know' when absent.
- **Dataset sources:**
  - telemetry: retrieval traces + final answers
  - code: chunking + embedding configs
- **Evals:**
  - context-groundedness
  - citation-precision
  - hallucination-rate
- **Notes:** If chunking changes, regenerate retrieval pairs and re-run evals. Align embedding model + tokenization with runtime settings.

### Product voice + prompt adherence

- **Goal:** Consistent style, safety rules, and system prompt compliance across versions.
- **Dataset sources:**
  - prompt_registry: versioned templates
- **Evals:**
  - prompt-adherence
  - format-compliance
- **Notes:** Treat prompts as API: version them, test them, and log them.

### French bilingual capability

- **Goal:** High-quality French understanding and generation with Canadian French robustness.
- **Dataset sources:**
  - HF French corpora (cleaned)
  - your internal French docs + UI strings
  - telemetry from francophone usage (after redaction)
- **Evals:**
  - fr-grammar-score (heuristic)
  - fr-instruction-following
- **Notes:** Prefer curated, domain-relevant French data. Avoid mixing in noisy web text without filtering.
